________________________________________________________________________

# СОДЕРЖАНИЕ #

- > **[КРАТКАЯ ТЕОРИЯ](#anchor_theory)**
    1. > **[ОБЩЕАЛГОРИТМИЧЕСКОЕ](#anchor_theory_alg)**
    1. > **[МАТВЫКЛАДКИ](#anchor_theory_math)**
        - > **[Формулы](#anchor_theory_math_formulas)**
        - > **[Методы](#anchor_theory_math_methods)**
    1. > **[СЛОЖНОСТЬ](#anchor_theory_dif)**
    1. > **[АЛГОРИТМИЧЕСКИЕ И МАТЕМАТИЧЕСКИЕ ФИЧИ](#anchor_theory_algmathfeats)**
- > **[PYTHON](#anchor_python)**
- > **[АЛГОРИТМЫ](#anchor_algorithm)**
    1. > **[ЛИНЕЙНЫЙ ПОИСК](#anchor_lin_search)**
    1. > **[СОРТИРОВКА](#anchor_sort)**
        - > **[Квадратичные сортировки](#anchor_sort_nsquared)**
        - > **[Сортировка подсчетом](#anchor_sort_count)**
        - > **[Устойчивая сортировка подсчетом](#anchor_sort_stablecount)**
        - > **[Поразрядная сортировка](#anchor_sort_radix)**
        - > **[Быстрая сортировка](#anchor_sort_quick)**
        - > **[Сортировка слиянием](#anchor_sort_merge)**
        - > **[Пирамидальная сортировка](#anchor_sort_heap)**
        - > **[Прочие алгоритмы сортировки](#anchor_sort_other)**
    1. > **[РАЗДЕЛЯЙ И ВЛАСТВУЙ](#anchor_divandcon)**
    1. > **[ПРЕФИКСНЫЕ СТРУКТУРЫ](#anchor_prefix)**
        - > **[Префиксный список (сумма)](#anchor_prefix_list)**
        - > **[Разреженная таблица](#anchor_prefix_sparse_table)**
        - > **[Дерево отрезков](#anchor_prefix_segtree)**
        - > **[Дерево Фенвика](#anchor_prefix_fenwick)**
    1. > **[ДВА УКАЗАТЕЛЯ](#anchor_2_pointers)**
    1. > **[СКОЛЬЗЯЩЕЕ ОКНО](#anchor_slidingwin)**
    1. > **[ПОИСК ДЕЛЕНИЕМ ОТРЕЗКА](#anchor_search_by_seg_div)**
        - > **[Бинарный поиск](#anchor_bin_search)**
        - > **[Тернарный поиск](#anchor_ternary_search)**
        - > **[Поиск методом золотого сечения](#anchor_golden_search)**
        - > **[Более экзотические методы](#anchor_exotic_search)**
    1. > **[СОРТИРОВКА СОБЫТИЙ](#anchor_eventsort)**
    1. > **[ДИНАМИЧЕСКОЕ ПРОГРАММИРОВАНИЕ](#anchor_dynprog)**
        - > **[С одним параметром](#anchor_dynprog_one_param)**
        - > **[С двумя параметрами](#anchor_dynprog_two_params)**
    1. > **[ЖАДНЫЙ АЛГОРИТМ](#anchor_greedy)**
        - > **[Задача о рюкзаке](#anchor_greedy_backpack)**
    1. > **[БИТОВЫЕ ОПЕРАЦИИ](#anchor_bitop)**
    1. > **[ХЕШИ ДЛЯ СТРОК](#anchor_strhash)**
        - > **[Сравнение полиномов](#anchor_strhash_poly)**
        - > **[Сравнение строк и подстрок](#anchor_strhash_str)**
        - > **[Задачи](#anchor_strhash_tasks)**
    1. > **[ПЕРЕБОР](#anchor_enum)**
        - > **[Поиск с возвратом (backtracking)](#anchor_enum_backtracking)**
        - > **[Методы оптимизации перебора](#anchor_enum_optimization)**
    1. > **[СПЕЦИАЛЬНЫЕ АЛГОРИТМЫ](#anchor_specalgs)**
        - > **[Алгоритм Хаффмана](#anchor_specalgs_haffman)**
        - > **[Исправляющие коды Хэмминга](#anchor_specalgs_hamming)**
        - > **[Алгоритм Лемпела-Зива-Велча](#anchor_specalgs_lzw)**
        - > **[Преобразование Барроуза-Уиллера](#anchor_specalgs_bwt)**
        - > **[Алгоритм А\*](#anchor_specalgs_astar)**
        - > **[Шум Перлина](#anchor_specalgs_perlin)**
        - > **[Метод Монте-Карло](#anchor_specalgs_montecarlo)**
- > **[СТРУКТУРЫ ДАННЫХ](#anchor_data_structures)**
    1. > **[МНОЖЕСТВО (ХЕШ-ТАБЛИЦА)](#anchor_set)**
    1. > **[СВЯЗНЫЕ СПИСКИ](#anchor_linked_list)**
        - > **[Особые использования](#anchor_linked_special)**
    1. > **[СТЕК](#anchor_stack)**
        - > **[Описание](#anchor_stack_desc)**
        - > **[Задачи](#anchor_stack_tasks)**
    1. > **[ОЧЕРЕДЬ](#anchor_queue)**
    1. > **[ДЕК](#anchor_deque)**
    1. > **[КУЧА](#anchor_heap)**
    1. > **[БИНАРНОЕ ДЕРЕВО (ПОИСКА)](#anchor_bintree)**
        - > **[Предварительная информация](#anchor_bintree_prelim)**
        - > **[Описание](#anchor_bintree_desc)**
        - > **[Основные операции](#anchor_bintree_operations)**
        - > **[Балансировка](#anchor_bintree_balance)**
        - > **[Дополнительно](#anchor_bintree_extra)**
    1. > **[ДРУГИЕ ДЕРЕВЬЯ](#anchor_other_trees)**
    1. > **[ГРАФ](#anchor_graph)**
        - > **[Описание](#anchor_graph_desc)**
        - > **[Обход в глубину](#anchor_graph_depth)**
        - > **[Обход в ширину](#anchor_graph_width)**
        - > **[Агоритм Дейкстры](#anchor_graph_dijkstra)**
        - > **[Граф состояний](#anchor_graph_states)**
    1. > **[ПЕРСИСТЕНТНЫЕ СТРУКТУРЫ](#anchor_persist)**
- > **[ИСТОЧНИКИ И ДОП. МАТЕРИАЛЫ](#anchor_materials)**
________________________________________________________________________

# КРАТКАЯ ТЕОРИЯ #
<a id="anchor_theory"></a>

### ОБЩЕАЛГОРИТМИЧЕСКОЕ ###
<a id="anchor_theory_alg"></a>

*Алгоритм* - набор конечного числа правил, задающих последовательность
выполнения операций для решения задач определенного типа. Помимо этого,
обладает 4 особенностями:

- *Конечность* - конечность числа шагов для выполнения алгоритма. В
    сущности же ужесточается сильнее разумностью и достаточной
    ограниченностью числа шагов. Хороший алгоритм = быстрый алгоритм.
- *Определенность* - каждый шаг алгоритма должен быть точно, четко и
    недвусмысленно определен.
- *Ввод и вывод* - имеет некоторое число (мб и 0) входных и некоторое
    число (1 и более) выходных данных.
- *Эффективность* - операторы алгоритма достаточно просты, чтобы можно
    было в течение конечного количества времени выполнить их вручную.
________________________________________________________________________

Для лучшего понимания алгоритмов советуется прогонять их выполнение на
нескольких примерах вручную, с отслеживанием происходящего с данными на
каждом этапе (см. матвыкладки, общий метод мат. индукции). Такой подход
позволяет лучше освоить логику работы алгоритма и смысл каждого шага в
частности, а для особо сложных примеров - и в целом назначение данного
алгоритма.
________________________________________________________________________

### МАТВЫКЛАДКИ ###
<a id="anchor_theory_math"></a>

### <u> Формулы </u> ###
<a id="anchor_theory_math_formulas"></a>

**Прогрессии**:

Арифметическая прогрессия:

- `a[n] = a[1] + d * (n - 1)`
- `S[n] = (a[1] + a[n]) * n / 2 = (2 * a[1] + d * (n - 1)) * n / 2`
- `a[n] = (a[n - 1] + a[n + 1]) / 2 = (a[n - 2] + a[n + 2]) / 2 = ...`

Геометрическая прогрессия:

- `b[n] = b[1] * q**(n - 1)`
- `S[n] = (b[n] * q - b[1]) / (q - 1) = b[1] * (q**n - 1) / (q - 1)`
- `b[n]**2 = b[n - 1] * b[n + 1] = b[n - 2] * b[n + 2] = ...`
________________________________________________________________________

**Свойства логарифмов**:

База из определения:

- `log_a(1) = 0`
- `log_a(a) = 1`
- `log_a(a**m) = m`
- `log_a(1 / a) = -1`
- `log_a**m(a) = 1 / m`

Свойства:

- Логарифм произведения: `log_c(a * b) = log_c(a) + log_c(b)`
- Логарифм частного: `log_c(a / b) = log_c(a) - log_c(b)`
- Логарифм степени: `log_c(a**k) = k * log_c(a)`
- Переход к новому основанию: `log_b(a) = (log_c(a) / log_c(b))`

Дополнительно:

- `log_a(b) = 1 / log_b(a)`
- `log_a**m(b**n) = (n / m) * log_a(b)`
- `log_n(b) * log_m(c) = log_n(c) * log_m(b)`
- `a**(log_n(b)) = b**(log_n(a))`
________________________________________________________________________

### <u> Методы </u> ###
<a id="anchor_theory_math_methods"></a>

*Доказательство методом математической индукции*:

1. Доказать, что утверждение P(1) верно.
2. Доказать, что если P(n) верно, то и P(n + 1) верно.

Этот метод применим и для алгоритмов, и получается *общий метод мат.*
*индукции*, который требует доказать для каждого блока на блок-схеме,
что если любое утверждение, которое соответствует стрелке, ведущей к
блоку, верно до выполнения операции из этого блока, то все утверждения,
которые соответствуют стрелкам, ведущим от блока, также верны после
выполнения операции.
________________________________________________________________________

### СЛОЖНОСТЬ ###
<a id="anchor_theory_dif"></a>

*Сложность алгоритма* - порядок кол-ва действий, которые выполняет
алгоритм. Например, если в программе 2 вложенных цикла, то сложность
составляет O(N\*\*2). В случае кол-ва действий 0 \* N пишется, что
сложность есть O(1).

> **[ВАЖНО!]** 100 \* N по сложности равно 10 \* N, которая составляет
O(N), т.к. сложность есть *порядок*, а не точное значение.

Также существует *пространственная сложность* - кол-во использованной
памяти.
________________________________________________________________________

Для иллюстрации множественности решений задачи и разных способов
улучшения алгоритмической сложности рассмотрим пример: *найти самый*
*часто встречающийся символ в строке*.

- *Решение 1*: перебрать все позиции в строке, и для каждой позиции еще
    раз переберем все позиции и посчитаем счетчиком в случае совпадения.
    - *Число действий*: N для каждого из N, N \* N.
    - *Алгоритмическая сложность*: O(N\*\*2).
    - *Пространственная сложность*: O(N) - храним только нач. строку.

- *Решение 2*: выделить отдельно уникальные символы из строки, перебрать
    все позиции новой строки, и для каждой позиции перебрать все
    позиции начальной строки и посчитать счетчиком в случае совпадения.
    - *Число действий*: N для каждого из K, N \* K.
    - *Алгоритмическая сложность*: O(N \* K), где K \<= N.
    - *Пространственная сложность*: O(N + K) = O(N) - храним нач. строку
        и новую строку.
        
- *Решение 3*: Заполнение словаря, где ключ - символ, а значение -
    счетчик. Всего одна пробежка по строке, потом поиск максимума.
    - *Число действий*: N + K.
    - *Алгоритмическая сложность*: O(N + K) = O(N).
    - *Пространственная сложность*: O(K) - хранить достаточно
        только словарь.
________________________________________________________________________

Тем не менее, оптимизация по алгоритмической сложности не всегда нужна.

Возвращаясь к тому, что O(100 \* N) = O(10 \* N) = O(N), что лучше:
1000\*N или 2 \* N \* logN? По алгоритмической сложности: 1000 \* N, но
если рассматривать эту задачу с константами, то 1000 \* N будет лучше
2 \* N \* logN при N >= 2\*\*500, что нереалистично большое число. Таким
образом, порой важно учитывать константы и прочее, а не только
сложность. Но такая ситуация редка.

Также в реалиях работы важнее все-таки стоят работоспособность и сроки
выполнения, поэтому важно в условиях дедлайнов не перемудрить с
оптимизацией в целом.

Таким образом, на самом деле у алгоритмов есть множество других
различных критериев оценивания, например:

- Пространственная сложность
- Время на реализацию
- Сложность поддержки
- Возможность распараллеливания этапов алгоритма
- Необходимая квалификация сотрудника
- Стоимость оборудования и ПО
________________________________________________________________________

### АЛГОРИТМИЧЕСКИЕ И МАТЕМАТИЧЕСКИЕ ФИЧИ ###
<a id="anchor_theory_algmathfeats"></a>

- Получать цифры некоторого числа можно как посредством преобразования
    числа в список цифр, так и с помощью последовательных `% 10` и
    `// 10` (как бы "откусывая" по цифре с конца). Такой подход возможен
    только в числах без ведущих нулей.

- Если не придумывается решение - попробуй отсортировать начальные
    данные.
________________________________________________________________________

# PYTHON #
<a id="anchor_python"></a>

Модули:

- **collections** - для некоторых усовершенствований по коду, содержит
    некоторые дополнительные типы данных. Подробнее см. конспект по
    Python -> Полезные библиотеки -> Стандартные -> collections.

- **algorithms** - содержит в себе ряд алгоритмов, см. документацию
    python-algorithms. Есть 2 вариации, какой по pip придет - не
    проверял.
________________________________________________________________________

Полезные функции для алгоритмов и для понимания дальнейших выкладок:

- `set(<smth>)` - сделать множество уникальных элементов из другого
    списка smth, строки smth или пустое. Можно почитать про эту функцию
    и множества в Python при желании.
- `'<delimiter>'.join(<list>)` - собрать строку из элементов списка
    list с разделителем delimiter.
- `<var> = [<smth> for <item> in <set>]` - конструктор списков.
- `<var1>, <var2> = <var2>, <var1>` - свапнуть значения переменных var1
    и var2.
- `<list_sorted> = sorted(<list>)` - сортировка списка или строки.
    Возвращает список, отсортрованный за N logN алгоритмом Timsort.
________________________________________________________________________

# АЛГОРИТМЫ #
<a id="anchor_algorithm"></a>

### ЛИНЕЙНЫЙ ПОИСК ###
<a id="anchor_lin_search"></a>

*Линейный поиск* - поиск, когда перебираются все элементы. Обычно ищем
подходящий/наиболее подходящий элемент. Сложность: O(N).

Далее рассмотрим вариации классических задач. Также в них на примерах
и пояснениях содержатся важные заметки, на которые советую обратить
внимание.
________________________________________________________________________

> **Задача 1**. Дана последовательность чисел длиной N. Найти первое
левое вхождение (другой вариант задачи - первое правое вхождение)
положительного числа X в нее или вывести -1, если число X не
встречалось. 

**Решение**:

Ответ = -1. Перебрать все элементы, если текущий эл-т равен X и ответ
равен -1, то запишем в ответ текущую позицию (индекс).

Проверка на -1 нужна лишь для того, чтобы проверить, впервые ли ответ
перезаписывается, чтобы как раз отследить первое вхождение. Таким
образом более хорошим решением для более общего случая задачи будет
отслеживать "первичность" вхождения через флаг.

(Для второй вариации задачи проверки на равенство -1 не нужно, либо
для сведения к первой вариации можно перебирать с конца в начало).

> **ЗАМЕТКА!** Вообще в общем случае даже если просят что-то вывести в
ответ в каком-то случае (например, -1, если нет подходящего), лучше
использовать флаг для избежания неприятных казусов, когда -1 входит в
потенциальные ответы или мешает их нахождению (см. эту задачу для
случая не только положительного X и вариации 2ой задачи).

**Код**:

```python
def findx(seq, x):
    ans = -1
    for i in range(len(seq)):
        if ans == -1 and seq[i] == x:  # для 2ого варианта - убрать ans == -1
            ans = i
    return ans
```
________________________________________________________________________

> **Задача 2**. Дана последовательность чисел длиной N (N > 0). Найти
максимальное число в последовательности.

> **ЗАМЕТКА!** Есть некоторые вариации. Например, найти минимальное.
Еще вариация - с определенной характеристикой, например, четное, и
тогда добавляется условие, например, "вывести -1, если такого нет". Для
такой вариации будет крайне актуальна заметка в задаче 1.

**Решение**: 

Сначала положим в ответ нулевой элемент пос-ти. Переберем все элементы,
кроме первого, если текущий элемент > ответа, перезапишем ответ на
текущий элемент.

> **ЗАМЕТКА!** С такой реализацией во многих языках программирования
может возникнуть проблема: постоянная перезапись. Это занимает память и
замедляет исполнение программы в случае, если сравниваются большие
объекты. Для избежания этого следует сохранять и перезаписывать индексы.
Но с другой стороны, сохранение индекса требует постоянного обращения к
последовательности для получения значения, так что это палка о двух
концах.

**Код**:

```python
def findmax(seq):
    ans = seq[0]
    for i in range(1, len(seq)):
        if seq[i] > ans:
            ans = seq[i]
    return ans
```
________________________________________________________________________

> **Задача 3**. Дана пос-ть чисел длиной N (N > 1). Найти два самых
больших числа в последовательности (могут быть одинаковы).

**Решение**:

Первые 2 числа пос-ти впишем в максимум-1 и максимум-2 (максимум-1 > 
максимум-2). Проходка по всей пос-ти, кроме первых 2 чисел. Если текущее
число > максимум-1, то максимум-2 = максимум-1, максимум-1 = текущее.
Иначе если текущее > максимум-2, то максимум-2 = текущее.

**Код**:

```python
def findmax2(seq):
    max1 = max(seq[0], seq[1])
    max2 = max(seq[0], seq[1])
    for i in range(2, len(seq)):
        if seq[i] > max1:
            max2 = max1
            max1 = seq[i]
        elif seq[i] > max2:
            max2 = seq[i]
    return max1, max2
```
________________________________________________________________________

> **Задача 4**. Дана пос-ть слов. Вывести все самые короткие слова
через пробел.

**Решение**:

Разбить на 2 проходки: найти минимальную длину слова и набрать в список
слова нужной длины. Затем вывести через пробел.

Можно в одну пробежку, с единовременной проверкой на минимум длины и
заполнением списка при соответствии, при этом обнуляя список при новом
минимуме и заполняя его заново.

Первый вариант читаемее, а второй может занимать как меньше операций,
так и больше, так как приходится обнулять.

> **ЗАМЕТКА!** Можно было бы набирать не в список, а сразу в строку, но
это плохая идея, так как пришлось бы делать через конкатенацию, что
времязатратная операция в Python из-за неизменности строк. Считай, из
O(N) может стать O(N\*\*2).

**Код**:

```python
def shortwords(words):
    minlen = len(words[0])
    for word in words:
        if len(word) < minlen:
            minlen = len(word)
    ans = []
    for word in words:
        if len(word) == minlen:
            ans.append(word)
    return ' '.join(ans)
```
________________________________________________________________________

> **Задача 5**. *(Задача про сжатие RLE)* Дана строка, состоящая из букв
A-Z. Нужно написать функцию RLE, которая из заданной строки (например,
ABBCCCDDDDEEEFFG) сделает сжатую строку но принципу RLE (отсылаясь к
примеру, AB2C3D4E3F2G). Т.е. если символ встречается 1 раз подряд, то
остается без изменений; если больше, то к нему добавляется число его
повторений.

**Решение**:

Записать первый символ, установить счетчик на 1. Пробежка по строке.
Пока текущий символ равен сохраненному - добавлять к счетчику 1. Если
другой символ - записать в список элемент по формату RLE, сменить
сохраненный символ и установить счетчик на 1. После выполнения пробежки
записать последнее вхождение. Скомпоновать в строку из списка без
пробелов.

**Код**:

```python
def rle(s):
    def pack(ch, cnt):
        if cnt > 1:
            return ch + str(cnt)
        return ch
    
    lastsym = s[0]
    cnt = 1
    ans = []
    for i in range(1, len(s)):
        if s[i] != lastsym:
            ans.append(pack(lastsym, cnt))
            cnt = 1
            lastsym = s[i]
        else:
            cnt += 1
    ans.append(lastsym, cnt)
    return ''.join(ans)
```
________________________________________________________________________

### СОРТИРОВКА ###
<a id="anchor_sort"></a>

Начнем с того, что у сортировок есть как некоторые отдельные по своей
сути сортировки, так и относящиеся по заложенным в них принципам к
определенным семействам (квадратичные, O(N logN)). Обычно на
собеседованиях как раз про сортировки этих семейств и спросят, т.к. к
ним относятся самые известные и популярные методы сортировки.

Квадратичные на практике не используются из-за их малой скорости, но
популярны как вводная тема в сортировки и способы улучшения других
методов, в то время как семейство O(N logN) - самое используемое.
Например, стандартная сортировка в C++ - быстрая, а в Python - timsort,
также относящаяся к O(N logN).

Исходя из популярности O(N logN) стоит вынести также то, что для них
лучшей средней скорости добиться нельзя. Это выводится из теории
информации и том, что данные сортировки основаны на сравнении 2 эл-тов.
Полное док-во можно как посмотреть в Интернете, так и в Тренировках по
алгоритмам 4.0 от Яндекса.

Кроме того, стоит обратить внимание на сортировки за O(N) - пусть они
могут иметь ограниченные условия применения для лучшего результата, в
пределах данных условий, несмотря на плохую константу, за счет своей
алгоритмической сложности имеют в разы лучшие результаты на больших
объемах данных.
________________________________________________________________________

Важной хар-кой сортировок является устойчивость. Устойчивость
показывает, сохраняют ли взаимный порядок одинаковые по ключу эл-ты в
сортируемом массиве или нет.

Например:

```
Начальный массив:
[(1, 'item_1'), (2, 'item_2'), (1, 'item_3'), (2, 'item_4')]
Сортировка сугубо по ключу. Тогда:

Результат устойчивой сортировки:
[(1, 'item_1'), (1, 'item_3'), (2, 'item_2'), (2, 'item_4')]

Возможные результаты неустойчивой сортировки:
[(1, 'item_3'), (1, 'item_1'), (2, 'item_2'), (2, 'item_4')]
[(1, 'item_1'), (1, 'item_3'), (2, 'item_4'), (2, 'item_2')]
[(1, 'item_3'), (1, 'item_1'), (2, 'item_4'), (2, 'item_2')]
```

Как видно, непосредственно сортировка произведена верно во всех случаях,
но устойчивостью обладает только 1 описанный результат - тот, в котором
если один эл-т с ключом x в начальной пос-ти встречается раньше другого
эл-та с тем же ключом, то и в отсортированной пос-ти данный порядок
сохраняется.

По поводу устойчивости для алгоритмов сортировки есть следующие
утверждения:

- Любой алгоритм сортировки можно написать так, что он не будет
    устойчивым.
- Любой алгоритм сортировки можно сделать устойчивым за O(N) доп.
    памяти, добавив к ключу сравнения номер в исходной пос-ти, но это
    также повлияет и на скорость исполнения, немного ухудшая константу.
    В частных случаях метóда может отличаться для ускорения процесса
    или в целом для работоспособности метода (см. Устойчивая сортировка
    подсчетом). Но в общем случае такой подход практически универсален.
________________________________________________________________________

### <u> Квадратичные сортировки </u> ###
<a id="anchor_sort_nsquared"></a>

Общая информация:

- *Сложность в среднем*: O(N\*\*2).
- *Сложность в худшем*: O(N\*\*2).
- *Доп. память*: O(1).
- *Устойчивость*: да.

Доп. информация:

- Не используются на практике в чистом виде.
________________________________________________________________________

*Квадратичные сортировки* - ряд сортировок за O(N\*\*2) действий. В
каноническом виде - самые простые, но самые медленные сортировки,
объединенные по причине простоты в одном разделе. Тем не менее, могут
пригодиться для разгонки в теме сортировок (так сказать, "база" в
изучении сортировок и их первые темы) и для собеседования.

**ВАЖНО!** В реальных проектах использовать не рекомендуется даже в
самом крайнем случае, т.к. у них есть более быстрые аналоги, ничем им не
уступающие.
________________________________________________________________________

*Сортировка пузырьком* (bubble sort, сортировка методом простого обмена)
\- сортировка, в основе которой лежит свап между соседями при выполнении
условия.

Будем идти по массиву слева направо. Если текущий элемент больше
следующего, меняем их местами. Делаем так, пока массив не будет
отсортирован. Заметим, что после первой итерации самый большой элемент
будет находиться в конце массива, на правильном месте. После двух
итераций на правильном месте будут стоять два наибольших элемента, и так
далее. Очевидно, не более чем после n итераций массив будет
отсортирован.

Асимптотика в худшем и среднем случае - O(N\*\*2), в лучшем случае -
O(N).
________________________________________________________________________

*Сортировка выбором* (selection sort) - сортировка выбором минимума.

На i-ой итерации ищем минимум на отрезке от i до конца массива и
свапаем его со значением на i-ой позиции. Т.о. после i-ой операции на
отрезке массива с 0-ого по i-ый эл-т будет располагаться отсортированная
часть массива.

Асимптотика: O(N\*\*2) в лучшем, среднем и худшем случае.
________________________________________________________________________

*Сортировка вставками* (insertion sort) - сортировка выбором места в
отсортированной части массива для очередного элемента с помощью простого
обмена.

На i-ой итерации берем i-ый эл-т массива и обмениваем его с левым
соседом до тех пор, пока эл-т не встанет на свое место в отсортированной
части массива, как бы "просеивая" его.

Асимптотика в среднем и худшем случае – O(N\*\*2), в лучшем – O(N).
________________________________________________________________________

Идеи этих сортировок могут использоваться в других сортировках для
получения новых методов, да и имеются некоторые методы на основе этих
трех базовых квадратичных методов, закрывающих их некоторые слабые
стороны. Для больших подробностей при наличии интереса или необх-ти см.
источник: [ссылка](https://habr.com/ru/articles/335920/) (сортировки:
шейкерная, расческой, Шелла, гномья).
________________________________________________________________________

### <u> Сортировка подсчетом </u> ###
<a id="anchor_sort_count"></a>

Общая информация:

- *Сложность в среднем*: O(N + K).
- *Сложность в худшем*: O(N + K).
- *Доп. память*: O(K).
- *Устойчивость*: нет.
________________________________________________________________________

Сортировка подсчетом актуальна в следующем случае: пусть необходимо
отсортировать массив из N целых чисел, каждое из которых от 0 до K (или
от min до max в общем случае, базовый пример - оценки в школе).
Подразумевается, что возможных значений относительно мало.

Обычная сортировка занимает не менее O(N logN).

Есть вариант для случая, описанного выше, сделать это за O(N) - 
сортировкой подсчетом. Для этого будем считать кол-во вхождений каждого
числа от 0 до K (список со счетчиками), а затем выводить каждое число
столько раз, сколько оно было насчитано.

Доп. память таким образом - O(K) и O(N + K): за счет создания и вывода
элементов.

**Код**:

```python
# изменяет непосредственно передаваемую пос-ть в ее начальной ячейке
# памяти, поэтому нет return. По необходимости - переписать, чтобы
# создавала и возвращала новый отсортированный список

def countsort(seq):
    minval = min(seq)
    maxval = max(seq)
    k = maxval - minval + 1
    count = [0] * k
    for now in seq:
        count[now - minval] += 1
    nowpos = 0
    for val in range(k):
        for i in range(count[val]):
            seq[nowpos] = val + minval
            nowpos += 1
```
________________________________________________________________________

Есть вариант использовать словари.

Константа в сложности словарей значительно больше, чем у массивов,
поэтому, где это возможно, лучше использовать обычную сортировку
подсчетом. Но сортировку подсчетом на списке неразумно использовать,
если данные разреженные.
________________________________________________________________________

> **Задача 1**. Дано 2 числа X и Y без ведущих нулей. Необходимо
проверить, можно ли получить первое из второго перестановкой цифр.

**Решение**:

Посчитать вхождение каждой цифры в каждом из чисел X и Y и сравнить
полученные подсчеты поэлементно.

> **ЗАМЕТКА!** Получать цифры можно как посредством преобразования
числа в список цифр, так и с помощью последовательных `% 10` и `// 10`
(как бы "откусывая" по цифре с конца). Такой подход возможен только в
числах без ведущих нулей.

**Код**:

```python
def isdigitpermutation(x, y):
    def countdigits(num):
        digitcount = [0] * 10
        while num > 0:
            lastdigit = num % 10
            digitcount[lastdigit] += 1
            num //= 10
        return digitcount
    
    digitsx = countdigits(x)
    digitsy = countdigits(y)
    for digit in range(10):
        if digitsx[digit] != digitsy[digit]:
            return False
    return True
```
________________________________________________________________________

> **Задача 2.1**. На шахматной доске N x N находятся M ладей. Ладья бьет
клетки на той же горизонтали или вертикали до ближайшей занятой
включительно. Определите, сколько пар ладей бьют друг друга. Ладьи
задаются парой чисел I и J (координаты клетки).
1 \<= N \<= 10\*\*9, 0 \<= M \<= 2 \* 10\*\*5.

**Решение**:

Для каждой занятой горизонтали и вертикали будем хранить кол-во ладей на
них. Кол-во пар в горизонтали (вертикали) равно кол-во ладей минус 1.
Суммируем это кол-во пар для всех горизонталей и вертикалей.

> **ЗАМЕТКА!** Создавать 2 списка со счетчиками на горизонтали и
вертикали - будут слишком большими из условия задачи, при этом ладьи
могут находиться крайне разрозненно друг относительно друга. Но ладей
меньше, т.е. можно хранить не все горизонтали и вертикали, а только
\<= M занятых горизонталей и вертикалей (отсюда приписка "занятой" в
решении), что в данном случае будет значительно лучше. Тогда используем
словари.

**Код**:

```python
def countbeatingrooks(rookcoords):
    def addrook(roworcol, key):
        if key not in roworcol.keys():
            roworcol[key] = 0
        roworcol[key] += 1

    def countpairs(roworcol):
        pairs = 0
        for key in roworcol.keys():
            pairs += roworcol[key] - 1
        return pairs
    
    rooksinrow = {}
    rooksincol = {}
    for row, col in rookcoords:
        addrook(rooksinrow, row)
        addrook(rooksincol, col)
    return countpairs(rooksinrow) + countpairs(rooksincol)
```
________________________________________________________________________

> **Задача 2.2**. Задача 2.1, но не для ладей, а для ферзей. Ферзи ходят
как по вертикали/горизонтали, так и по диагонали.

**Решение**:

То же самое, но еще и хранить занятые диагонали, которые единственным
образом определяются разницей координат (просто вместо 2 словарей
получится 4). Тогда:

Для каждой занятой горизонтали, вертикали и дмагонали будем хранить
кол-во ферзей на них. Кол-во пар в горизонтали (вертикали, диагонали)
равно кол-во ферзей минус 1. Суммируем это кол-во пар для всех
горизонталей, вертикалей и диагоналей.
________________________________________________________________________

> **Задача 3**. Дана строка S. Выведите гистограмму как в примере (коды
символов отсортированы):

```
S = 'Hello, world!'

      #
      ##
##########
 !,Hdelorw
```

**Решение**:

Заводим словарь, ключи - символы, значения - счетчики. Проходим по S,
считаем. Для вывода - смотрим максимальное значение счетчика и от него
до 1 переберем. Для каждого этого числа проверяем для каждого символа,
больше ли его счетчик, а затем выводим #, если да, и пробел, если нет.

Алгоритмическая сложность у этой задачи высокая из-за вывода -
O(N\*\*2).

> **ЗАМЕТКА!** Словарь здесь актуален, т.к. символы могут быть любые, а
их кол-во за все языки мира и разные символы большое.

**Код**:

```python
def printchart(s):
    symcount = {}
    maxsymcount = 0
    for sym in s:
        if sym not in symcount.keys():
            symcount[sym] = 0
        symcount[sym] += 1
        maxsymcount = max(maxsymcount, symcount[sym])
        # максимум можно посчитать после по max(symcount.values())
    sorteduniqsyms = sorted(symcount.keys())
    for row in range(maxsymcount, 0, -1):
        for sym in sorteduniqsyms:
            # не самый оптимальный способ, т.к. слишком много вызовов
            # функции print для ускорения лучше класть символы в список,
            # а затем выводить
            if symcount[sym] >= row:
                print('#', end='')
            else:
                print(' ', end='')
        print()
    print(''.join(sorteduniqsyms))
```
________________________________________________________________________

> **Задача 4**. Сгруппировать слова по общим буквам. Например: инпут:
`['eat', 'tea', 'tan', 'ate', 'nat', 'bat']`, аутпут:
`[['ate', 'eat', 'tea'], ['nat', 'tan'], ['bat']]`.

**Решение**:

Отсортируем в каждом слове буквы и это будет ключом в словаре, а
значением будет список слов.

**Код**:

```python
def groupwords(words):
    groups = {}
    for word in words:
        sortedword = ''.join(sorted(word))
        if sortedword not in groups.keys():
            groups[sortedword] = []
        groups[sortedword].append(word)
    ans = []
    for sortedword in groups.keys():
        ans.append(groups[sortedword])
    return ans
```
________________________________________________________________________

### <u> Устойчивая сортировка подсчетом </u> ###
<a id="anchor_sort_stablecount"></a>

Общая информация:

- *Сложность в среднем*: O(N + K).
- *Сложность в худшем*: O(N + K).
- *Доп. память*: O(N + K).
- *Устойчивость*: да.
________________________________________________________________________

Для устойчивой сортировки подсчетом, как описано выше, понадобится
завести дополнительны массив с O(N) памяти, но не в том виде, как все
делается с остальными алгоритмами сортировки.

Имея начальный массив, заведем 3 дополнительных:

- count - для счетчиков.
- pos - для итоговых позиций.
- res - для результирующей отсортированной пос-ти.

pos заполняется после проведения стандартных для данного алгоритма
сортировки подсчетов, записываемых в count. `pos[0] = 0`, а далее
`pos[i] = pos[i - 1] + count[i - 1]`. Т.о. pos[i] показывает, по какому
индексу вставлять очередной эл-т из начальной пос-ти, равный i.

При заполнении res: смотрим в начальную пос-ть, пусть очередной эл-т
равен x. Тогда проводим операции `res[pos[x]] = x` и `pos[x] += 1`.
Так и получаем отсортированную пос-ть, причем устойчивую.
________________________________________________________________________

### <u> Поразрядная сортировка </u> ###
<a id="anchor_sort_radix"></a>

Общая информация:

- *Сложность в среднем*: O(M \* (N + K)).
- *Сложность в худшем*: O(M \* (N + K)).
- *Доп. память*: O(N + K).
- *Устойчивость*: да.
________________________________________________________________________

Идея:

- Сведем числа к одному кол-ву цифр.
- Поразрядно от меньшего разряда к большему будем сортировать их
    устойчивой сортировкой подсчетом. За счет устойчивости после
    сортировки по i-ому разряду будет порядок не только непосредственно
    по i-ому разряду, но и по i - 1, ..., 1, 0 разрядам.

> **ВАЖНО!** Поразрядная сортировка подразумевает сравнение по одному
разряду, а не по числам, получаемым выцеплением всех разрядов до
текущего. Например, сравнивая поразрядно 607, 517 и 406, мы сначала
сравниваем 7, 7 и 6, потом 0, 1 и 0, а потом 6, 5 и 4. Тогда после
первой итерации получаем 406, 607, 517, после второй 406, 607, 517, а
после третьей 406, 517, 607.
________________________________________________________________________

Сравнение от меньшего разряда к большему называется *radix LSD sort*
(least significant digit), от большего разряда к меньшему - *radix MSD*
*sort* (most significant digit). Но MSD версия имеет свои аспекты, с
которыми стоит быть осторожным, и по сути своей является абсолютно
другим алгоритмом.
________________________________________________________________________

### <u> Быстрая сортировка </u> ###
<a id="anchor_sort_quick"></a>

Общая информация:

- *Сложность в среднем*: O(N logN).
- *Сложность в худшем*: O(N\*\*2).
- *Доп. память*: O(logN).
- *Устойчивость*: нет.

Доп. информация:

- Лучшая константа среди семейства сортировок за O(N logN).
________________________________________________________________________

Идея следующая:

1. Выбрать опорный эл-т (pivot, обозначим за P).
2. Разбить массив относительно P так, чтобы слева были числа строго
    меньше, а справа - большие либо равные (partition).
3. Рекурсивно применить это к полученным частям.

Простейшая схема кодовой реализации:

```python
def quicksort(l, r):
    x = a[random(0, n - 1)]
    p = partition(l, r, x)
    quicksort(l, p)
    quicksort(p + 1, r)
```

Ф-ция `partition` здесь производит разбиение и возвращает индекс, где
теперь лежит опорный эл-т, он же - первый эл-т половины, большей либо
равной P.
________________________________________________________________________

Выбор P осуществляется либо случайно, либо по медиане, либо каким-то
другим методом. Чаще всего используется случайное (или псевдослучайное)
число, но ф-ция генерации случайного числа медленная, поэтому не всегда.

Вообще случайность приводит к тому, что можем прийти к худшей ситуации
с сложностью O(N\*\*2), когда в качестве P выбирается все время либо
минимум, либо максимум, что приводит к разбиению на массивы из N - 1 и 1
эл-тов. Но вероятность этого крайне мала на большом кол-ве эл-тов в
массиве, поэтому в рассуждениях такого не учитываем.

Основная проблема данного метода - разбиение массива. Для этого есть
разные схемы, рассмотрим парочку из них.
________________________________________________________________________

*Схема Хоара* - использование 2 указателей, изначальное положение: левый
на первом, правый на последнем. Двигаем левый указатель вглубь массива,
пока очередной эл-т не станет больше или равен P; потом двигаем правый
указатель вглубь массива, пока очередной эл-т не станет меньше P; свап
значений по левому и правому указателю, сдвиг вглубь массива обоих
указателей на 1. Так действовать по кругу, пока указатели не встретятся
или левый не станет правее правого (такое возможно после свапа).

Есть проблемы: приходится отдельно обрабатывать разные случаи, например,
массив из одинаковых (или почти всех одинаковых) эл-тов; неясно, где
находится сам опорный эл-т.

В целом часто используется, самый базовый пример разбиения массива для
быстрой стортировки, если правильно реализовать, кроме того самый
понятный по концепции (но не по реализации из-за краевых кейсов). Тем не
менее, не самый эффективный по константе.
________________________________________________________________________

*Три указателя* - по концепции чуть сложнее, но в остальном (константа,
простота реализации, читаемость кода) заметно лучше схемы Хоара.

Суть: использовать указатели E (на первый эл-т, равный P), G (на первый
эл-т, больше P) и N (на первый необработанный эл-т).

Если эл-т в N (очередной эл-т):

- Больше P, то сдвигаем N на 1 вправо.
- Равен P, то очередной эл-т переписываем в G, старый эл-т из G
    переписываем в N, а G и N смещаем на 1 вправо.
- Меньше P, то очередной эл-т -> E, старый из E -> G, старый из G -> N,
    а E, G, N смещаем на 1 вправо.

```
Пример: (заключим в () очередной эл-т, а в [] - подвергнувшиеся
перемещению)

Состояние где-то в процессе выполнения:
         E        G        N
<P <P <P =P =P =P >P >P >P ?? ?? ?? ??

Вскрываем эл-т (>P):
         E        G        N
<P <P <P =P =P =P >P >P >P (>P) ?? ?? ??

После операции:
         E        G           N
<P <P <P =P =P =P >P >P >P >P ?? ?? ??

Вскрываем эл-т (=P):
         E        G           N
<P <P <P =P =P =P >P >P >P >P (=P) ?? ??

После операции:
         E        G                  N
<P <P <P =P =P =P (=P) >P >P >P [>P] ?? ??
```

Как видно, такой алгоритм неустойчивый (устойчивость сохраняется только
для эл-тов меньше P).
________________________________________________________________________

Небольшая подтема, проистекающая из быстрой сортировки - *k-ая*
*порядковая статистика*. Оформим это в виде задачи.

> **Задача 0**. Узнать, какой эл-т будет стоять после сортировки на k-ом
месте.

> **ЗАМЕТКА!** Медиана - частный пример k-ой порядковой статистики, где
`k = len(<list>) // 2`. Кроме того, в целом в анализе данных k-ая
порядковая статистика - довольно полезная вещь. Например, если нужно
узнать, с какого значения некоторой величины (зарплата, ежемесячные
траты и т.п.) начинается топ-10% или топ-50% людей (например, чтобы
понять, сможет ли хотя бы половина людей позволить себе услугу на
сервисе). Кроме того, беря, например, k-ую порядковую статистику от
`k = len(<list>) // 10` с таким же шагом, можно посмотреть общее
распределение по топ-90% - топ-10% для более точной оценки описанных
выше вещей.

**Решение**: За O(N) неполной быстрой сортировкой. Для этого применяем
partition и далее рекурсивно проходим не в оба подотрезка, а в тот, в
котором оказалось k (k > p (положение P) => правый, ищем (k - p)-ую
статистику; k < p => в левый, ищем k-ую статистику; k == p => нашли эл-т
на k-ой позиции).

> **ЗАМЕТКА!** После такой неполной сортировки, кроме того, на k-ом
месте окажется то же число, что было бы на k-ом месте после полной
сортировки. При этом справа будут числа >= числа на k-ом месте, а слева
\- <= числа на k-ом месте. Т.о. можно найти все k наименьших чисел или
N - k наибольших чисел.
________________________________________________________________________

### <u> Сортировка слиянием </u> ###
<a id="anchor_sort_merge"></a>

Общая информация:

- *Сложность в среднем*: O(N logN).
- *Сложность в худшем*: O(N logN).
- *Доп. память*: O(N).
- *Устойчивость*: да.
________________________________________________________________________

Перво-наперво оговоримся о ф-ции merge - ф-ции для слияния двух
отсортированных пос-тей в одну. На основе данной ф-ции и реализуется
сортировка слиянием. Пример реализации ф-ции merge можно привести из
Задачи 2 темы "Два указателя". Код решения приведен ниже:

```python
def merge(nums1, nums2):
    merged = [0] * (len(nums1) + len(nums2))
    first1 = first2 = 0
    for k in range(len(nums1) + len(nums2)):
        if first1 != len(nums1) and (first2 == len(nums2) or \
                nums1[first1] < nums2[first2]):
            merged[k] = nums1[first1]
            first1 += 1
        else:
            merged[k] = nums2[first2]
            first2 += 1
    return merged
```
________________________________________________________________________

Идея сортировки:

- Если в массиве 1 эл-т - вернуть его.
- Иначе разбить сортируемый массив пополам. Рекурсивно вызвать для
    каждой из половинок сортировку слиянием, а затем слить результаты
    половинок, вернуть отсортированный массив.
________________________________________________________________________

Подводный камень в памяти - не надо делать N logN дополнительных эл-тов,
лучше использовать, наример, кольцевой буфер или дополнительный 1 массив
для дополнительной памяти не более O(N).
________________________________________________________________________

### <u> Пирамидальная сортировка </u> ###
<a id="anchor_sort_heap"></a>

Общая информация:

- *Сложность в среднем*: O(N logN).
- *Сложность в худшем*: O(N logN).
- *Доп. память*: O(1).
- *Устойчивость*: нет.
________________________________________________________________________

С помощью кучи можно добиться сортировки за O(N logN). Если делать это
аккуратно, можно будет обойтись без использования доп. памяти.

Будем поддерживать на одном массиве кучу максимумов, а отсортированная
часть массива будет формироваться в правой половине массива, уже
освобожденной от кучи.

1. Превратить массив в кучу - операция *heapify*. Для этого:
    - Бездетных объявим одноэлементными кучами.
    - Поднимаемся вверх по эл-там с детьми и делаем из них кучи,
        рассеивая вниз.

> **ЗАМЕТКА!** Сложность - O(N), т.к. если считать число действий для
    каждой категории значений (без детей (N/2 шт.), без внуков
    (N/4 шт.), без правнуков (N/8 шт.) и т.д.), то получится, что будет
    совершено действий N/2 * 0 + N/4 * 1 + N/8 * 2 + ... = N/2.

2. Извлекаем максимум, помещаем его в конец, кучей считаем теперь
    срез до предпоследнего эл-та включительно. Повторить п.2 до полной
    сортировки.
________________________________________________________________________

Хорош тем, что не требует больше, чем O(1) доп. памяти, но по сравнению
с остальными методами сортировки за O(N logN) хуже константа => самый
медленный из стандартных представителей этого семейства.
________________________________________________________________________

### <u> Прочие алгоритмы сортировки </u> ###
<a id="anchor_sort_other"></a>

Вообще алгоритмов сортировки огромное кол-во. Описанные выше - самые
полезные или распространенные в обучении. Но есть ряд других алгоритмов
сортировки, которые при наличии желания, интереса или необх-ти можно
изучить.

- **Timsort** - используется как стандартный в Python. См.
    [ссылка](https://habr.com/ru/companies/infopulse/articles/133303/).
    Также тут есть табличка с разными сортировками.

- Сортировка расческой и Шелла могут быть интересны в ознакомительных
    целях.

- Bucket sort, radix MSD sort, bitonic sort - также интереса ради.

- А смеха и развлечения ради - bogosort. Это уже чисто развлекательный
    или фановый алгоритм, работающий в среднем за O(N * N!), а в худшем
    \- бесконечно долго. Также можно почитать про непрактичные алгоритмы
    сортировки с теми же развлекательными целями или интереса ради, см.
    [ссылка](https://habr.com/ru/articles/198114/), а также алгоритм
    Лас-Вегас, частным случаем которого является bogosort, см.
    [сслыка](https://ru.wikipedia.org/wiki/Лас-Вегас_(алгоритм)).
    Последний можно рассмотреть чуть серьезнее, чем абсолютно
    несерьезно, а также почитать про метод Монте-Карло, с которым они
    коррелируют.
________________________________________________________________________

### РАЗДЕЛЯЙ И ВЛАСТВУЙ ###
<a id="anchor_divandcon"></a>

Алгоритм "Разделяй и Властвуй" (Divide and Conquer) представляет собой
способ по ускорению алгоритма. 

Идея:

1. Разделить входные данные на меньшие подмн-ва.
2. Решить рекурсивно задачу для них.
3. Объединить результат.

Базовый пример использования данной идеи - переход от квадратичной
сортировки к сортировке слиянием. Но еще более базовым примером можно
привести бинарный поиск, который по сути является частным примером
данного подхода.
________________________________________________________________________

> **Задача 1**. Дан неупорядоченный массив из n эл-тов, где n является
степенью двойки. Требуется предоставить алгоритм, который находит второй
по величине элемент массива, осуществляя не более n + log(n) - 2
операций сравнения.

> **ЗАМЕТКА!** Cама по себе простая задача на линейный поиск. Но в таком
решении совершается 2N действий сравнения, что не соответствует условию.
В задаче поиска второго максимума, конечно, "Разделяй и Властвуй" скорее
оверинжиниринг, чем что-то действительно полезное, но пример наглядный.

**Решение**:

Попробуем искать максимум путём разбиения доступных элементов на две
части и последующего поиска наибольших значений в них. В этом случае
количество сравнений для поиска максимума равно сумме:
`n / 2 + n / 4 + n / 8 + ... + 1 = n - 1`. Чтобы найти второй максимум,
потребуется рассмотреть все эл-ты, с которыми сравнивался максимум.
Поиск максимального среди них потребует `log(n) - 1` операцию, поскольку
элементов в этом маленьком списке не больше, чем глубина дерева минус
один.

**Код**:

```python
def second_largest(arr):
    # функция find_max_and_comp выполняет поиск максимума в массиве,
    # по принципу на диаграмме
    # кроме этого, в ней осуществляется поддержка списка элементов,
    # с которыми максимум сравнивался
    def find_max_and_comp(low, high, arr):
            if low >= high:
                return arr[low], []
            mid = (high + low) // 2
            x, lst_x = find_max_and_comp(low, mid, arr)
            y, lst_y = find_max_and_comp(mid + 1, high, arr)
            if x > y:
                lst_x.append(y)
                return x, lst_x
            else:
                lst_y.append(x)
                return y, lst_y
    
    # для определения второго по величине элемента, 
    # требуется вычислить список рассмотренных с наибольшим элементов,
    # а затем найти максимум среди них
    comparisons = find_max_and_comp(0, len(arr) - 1, arr)[1]
    return find_max_and_comp(0, len(comparisons) - 1, comparisons)[0]
```
________________________________________________________________________

### ПРЕФИКСНЫЕ СТРУКТУРЫ ###
<a id="anchor_prefix"></a>

Под *префиксными структурами* в данном случае подразумевается расчет
вспомогательной структуры с данными перед выполнением основной
программы.
________________________________________________________________________

### <u> Префиксный список (сумма) </u> ###
<a id="anchor_prefix_list"></a>

*Префиксные списки* обычно описываются как *префиксные суммы*, хотя
имеют в своем арсенале куда больше возможных реализаций и применений,
чем предподсчет сумм на отрезках. Тем не менее, проще всего префиксные
списки объяснить на примере именно с префиксной суммой, а затем показать
примеры прочих применений.
________________________________________________________________________

> **Задача 0**. Есть массив nums из N элементов и есть необходимость
отвечать на частые запросы о сумме элементов в полуинтервале [L, R).

**Решение 0**:

Можно было бы решить задачу наивно: просто за O(N) каждый раз считать
сумму элементов от L до R. Но есть условие частоты, и тогда такие
запросы в сумме будут занимать K \* O(N), где K - количество запросов.

**Решение 1**:

Можно заранее посчитать префиксную сумму: список prefixsum длиной N + 1,
где prefixsum[k] будет хранить сумму всех чисел nums в полуинтервале
[0, k - 1). Такая сборка массива займет O(N):
`prefixsum[i] = prefixsum[i - 1] + nums[i - 1]`. \
Тогда можно будет за O(1) получать сумму в заданном полуинтервале:
`semiinterval_sum(L, R) = prefixsum[R] - prefixsum[L]`. \
Общая сложность такого решения O(N) + K \* O(1), что в условиях большого
K значительно выгоднее Решения 0.

> **ЗАМЕТКА!** Важно помнить некоторые вещи. Во многих языках важно
следить за переполнением типа данных в префиксной сумме. Но что важно
помнить во всех языках - это различие размеров начального массива и
префиксной суммы. Важно помнить и об области применения, т.к. если
после последнего изменения массива запросов на сумму интервалов
относительно мало, то это может быть менее эффективно наивного решения.

**Код**:

```python
def makeprefixsum(nums):
    prefixsum = [0] * (len(nums) + 1)
    for i in range(1, len(nums) + 1):
        prefixsum[i] = prefixsum[i - 1] + nums[i - 1]
    return prefixsum

# RSQ - range sum value
def rsq(prefixsum, l, r):
    return prefixsum[r] - prefixsum[l]
```
________________________________________________________________________

> **Задача 1**. Дана пос-ть чисел длиной N и M запросов. Запросы:
сколько нулей в полуинтервале [L, R).

**Решение**:

Посчитать префиксный список количества нулей - prefixzeroes. Тогда ответ
на запрос будет `prefixzeroes[R] - prefixzeroes[L]`.

> **ЗАМЕТКА!** Получающаяся сложность наивного решения - O(NM), в то
время как префиксного - O(N + M).

**Код**:

```python
def makeprefixzeroes(nums):
    prefixzeroes = [0] * (len(nums) + 1)
    for i in range(1, len(nums) + 1):
        if nums[i - 1] == 0:
            prefixzeroes[i] = prefixzeroes[i - 1] + 1
        else:
            prefixzeroes[i] = prefixzeroes[i - 1]
    return prefixzeroes

def countzeroes(prefixzeroes, l, r):
    return prefixzeroes[r] - prefixzeroes[l]
```
________________________________________________________________________

> **Задача 2**. Дана пос-ть чисел длиной N. Необходимо найти число
отрезков с нулевой суммой (вариация - со стоимостью акций, в какие
интервалы вышел в ноль).

**Решения**:

- O(N\*\*3): Перебрать начало и конец отрезка + суммирование элементов
    между ними.
- O(N\*\*2): Перебрать начало и двигаем конец, единовременно с этим
    прибавляя добавляющиеся в отрезок элементы (как бы объединение
    перебора конца и суммирования).
- O(N): Посчитать префиксные суммы. Одинаковые префиксные суммы -
    сумма на отрезке с началом и концом в этих позициях равна нулю.
    Т.е. встречая повторяющуюся сумму, нужно посчитать, сколько было
    таких сумм ранее и в итоге столько отрезков добавится к результату.
    Тут можно использовать словарь для подсчета каждой префиксной
    суммы, что в данном решении префиксная структура и есть.

> **ЗАМЕТКА!** Как видно из этого примера, иногда задачи на префиксные
структуры большое количество запросов маскируют за количеством
подсчетов и изменяющихся величин, что в итоге отражается на сложности
наивного решения. Таким образом префиксы помогают решать не только
"задачи с большим кол-вом последующих запросов", но и оптимизировать
такие случаи.

**Код**:

```python
def countprefixsums(nums):
    # префиксный словарь счетчика сумм по значемнию суммы
    prefixsumbyvalue = {0: 1}
    nowsum = 0
    for now in nums:
        nowsum += now
        if nowsum not in prefixsumbyvalue:
            prefixsumbyvalue[nowsum] = 0
        prefixsumbyvalue[nowsum] += 1
    return prefixsumbyvalue

def countzerosumranges(prefixsumbyvalue):
    cntranges = 0
    for nowsum in prefixsumbyvalue.keys():
        cntsum = prefixsumbyvalue[nowsum]
        # сумма арифметической прогрессии
        cntranges += cntsum * (cntsum - 1) // 2
    return cntranges
```
________________________________________________________________________

### <u> Разреженная таблица </u> ###
<a id="anchor_prefix_sparse_table"></a>

*Разреженная таблица* - sparse table - развитие идеи префиксных
подсчетов. Например, префиксный список, каким бы он ни был, не сможет
решить проблему поиска максимума на отрезке. В таких случаях как раз и
используют разреженные таблицы.

Разреженная таблица - структура N x logN, строящегося из оригинального
списка размером N. 0-ую строку занимает оригинальный список, i-ую строку
занимает предпосчитанная величина для отрезка длиной 2\*\*i, причем
j-ый эл-т этой строки отвечает за отрезок `[j, j + 2**i - 1]`.

Используется: когда выгодно посчитать что-то заранее, а потом к этому
сделать много запросов, чем считать каждый раз с запросом. Кроме того,
используется в таких случаях тогда, когда префиксный список не работает,
ибо иначе префиксы выгоднее. Вдобавок, начальные данные не должны
меняться, иначе это становится невыгодно.

> **ЗАМЕТКА!** Важно понимать, что большое кол-во запросов после
потенциального предподсчета может маскироваться в кол-ве последующих
расчетов. Для большего понимания: см. задачи Префиксов.
________________________________________________________________________

Алгоритм заполнения на примере поиска максимума:

- `sptable[0] = <orig_data>`, т.е. двумерный список, пока что с одной
    строкой.
- `sptable[i][j] = max(sptable[i - 1][j], sptable[i - 1][j + 2**(i - 1)])`
    \- этой строкой мы получаем максимум среди двух отрезков длиной
    2\*\*(i - 1), составляющих данный j-ый отрезок длиной 2\*\*i. Такое
    заполнение i-ой строки происходит, пока находится эл-т
    `sptable[i - 1][j + 2**(i - 1)])`, иначе это будет уже не отрезок
    длиной 2\*\*i, а меньше.

Например:

```
0: [7, 1, 2, 4, 2, 3, 1], len = 7
1: [7, 2, 4, 4, 3, 3],    len = 6
2: [7, 4, 4, 4],          len = 4
3: Уже не хватает эл-тов.
```
________________________________________________________________________

Имея такую структуру, можно посчитать максимум на любом отрезке почти за
O(1) (см. следующий блок, как этого добиться). Алгоритм:

- Запрос: найти максимум на отрезке [L, R].
- Найти такое максимальное j, что `2**j <= len([L, R]) = R - L + 1`.
- Тогда максимум на отрезке [L, R] будет наибольшим из максимумов на
    двух отрезках [L, L + 2\*\*j], [R - 2\*\*j, R], даже если они
    пересекаются. Для этого на j-ой строке ищем эл-ты с индексами L и
    R - 2\*\*j.

Ссылаясь на предыдущий пример, максимум на отрезке [1, 5]. Длина 5,
2\*\*2 <= 5. Тогда смотрим в строке с индексом 2 элементы с идексами 1 и
2: максимум из 4 и 4 равен 4. Ответ: 4.
________________________________________________________________________

Т.о. разреженная таблица: предподсчет за O(N logN), но затем запросы за
O(1). Последнее утверждение условно, т.к. надо искать 2\*\*j <= len.
Поиск логарифма тут не подходит, т.к. это очень ресурсоемкая функция.
Наивный перебор тоже работает плохо, т.к. перебор всех степеней 2 в
худшем случае занимают O(log(len)).

Для работы за O(1) надо предпосчитать для каждого len степень двойки.
Т.о. заведется дополнительный список + предподсчеты займут на O(N)
больше времени, зато запрос и вправду займет O(1).
________________________________________________________________________

### <u> Дерево отрезков </u> ###
<a id="anchor_prefix_segtree"></a>

*Дерево отрезков* - развитие идеи разреженных таблиц, реализованное в
виде бинарного дерева и поддерживающее функции изменения начальных
данных.

Позволяет то же, что и разреженные таблицы и префиксные суммы, но, кроме
того, поддерживает различные изменения оригинального набора данных как
в одном эл-те, так и в отрезке. Может использоваться для поиска на
отрезке суммы, максимума, минимума, кол-ва эл-тов.

Строится за O(N). Ответ на запрос за O(logN). Как видно, поиск
медленнее, чем в разреженной таблице, т.е. там, где возможно, лучше
использовать префиксные списки или разреженную таблицу. Да и кроме того,
константы довольно большие.

Можно переписать действия снизу и убрать рекурсию, переписав все,
например, с помощью динамического программирования, и тогда константа
станет значительно лучше. Тем не менее, в пределах данной подтемы
конспекта такие усложнения рассматриваться не будут.

> **ЗАМЕТКА!** В данной подтеме все рассматривается в отрезках, а не
интервалах или полуинтервалах. Отрезки включают свои края, и, например,
отрезки [1, 10] и [10, 20] пересекаются в эл-те 10. Во избежание ошибок
по невнимательности или инерции после изучения предыдущих тем стоит
держать данный факт в голове. 
________________________________________________________________________

Хранение - по аналогии с кучей (см. Куча), т.е. в виде одномерного
списка размером 2N - 1, где N - размер дополненного до степени двойки
оригинального списка. Тут для i-ого эл-та родитель находится на индексе
(i - 1) // 2, а дочерние - на индексах 2i + 1, 2i + 2. Получится
сквозная нумерация по слоям, если дерево вырисовывать.

Оргинальная пос-ть тогда хранится от эл-та с индексом N - 1 до конца.

Заполнение на одномерном списке происходит с копирования назад всего
дополненного оригинального списка, а затем по индексу дочерних эл-тов
заполняются справа налево остальные эл-ты.
________________________________________________________________________

Алгоритм построения на примере поиска максимума на отрезке:

- Дополним оригинальную пос-ть по длине до степени двойки нейтральными
    для задачи эл-тами (-inf, не влияющая на поиск максимума). Это будет
    нижний слой дерева, его листами.
- Для каждых двух элементов родитель есть максимум этих двух элементов.
    Так заполняется дерево до корня.

Полученный результат: нижний слой соответствует отрезкам единичной
длины([0, 0], [1, 1], ...), далее - длины 2 ([0, 1], [2, 3], ...), и
т.д., корень - всему отрезку ([0, N]). Назовем это условно
*зоной ответственности* для соответствующего узла дерева.

Зону ответственности для дальнейших действий необязательно хранить в
узле, а можно передавать от родителя в рекурсии: левому левую половину,
правому - правую (`[L, (L + R) // 2]`, `[(L + R) // 2 + 1, R]`).
________________________________________________________________________

Алгоритм поиска на примере поиска максимума на отрезке [L, R]:

- Рекурсивно идем от корня и отвечаем на вопросы:
    - [L, R] покрывает зону ответственности узла полностью? Если да, то
        возвращаем родителю значение в себе.
    - [L, R] не имеет пересечение с зоной ответственности? Если да, то
        возвращаем родителю нейтральный эл-т (-inf).
    - Иначе передаем запрос "максимум на отрезке [L, R]" дочерним узлам,
        выбираем максимум из них, возвращаем родителю.

Сложность - O(logN), объяснение по необх-ти пересмотреть (Яндекс
Тренировки по алгоритмам 7.0 Лекция 2). Но кратко говоря - путь
разветвится лишь 1 раз, а в остальных случаях по крайней мере один из
детей гарантированно возвращает либо себя, либо нейтральный эл-т, а
второй в худшем случае продолжит движение в глубину. Т.о. глубина дерева
logN, в каждом узле совершается 2 действия ("простой" ребенок возвращает
за O(1), "передача дальнейшего углубления" другому ребенку за O(1)),
кроме одного узла, где ветвимся: там происходит ветвление на 2 таких
поиска. Итого 2\*2\*logN, т.е. O(logN).
________________________________________________________________________

Алгоритм изменения эл-та на примере дерева для поиска максимума:

- Изменить эл-т.
- За O(logN) пройтись по родителям до самого корня и пересчитать для них
    максимумы.
________________________________________________________________________

Алгоритм изменения отрезка на примере прибавления числа к эл-там отрезка
на примере дерева для поиска максимума:

- Пробегаем рекурсивно по аналогии с поиском и вопросы:
    - [L, R] покрывает зону ответственности узла полностью? Если да, то
        изменяем значение в себе, даем *обещание*, что дети выполнят эту
        операцию на себе и сразу возвращаем родителю значение в себе.
    - [L, R] имеет пересечение с зоной ответственности? Если нет, то
        возвращаем себя родителю без изменений.
    - Иначе передаем запрос на изменение детям, пересматриваем максимум
        по их значениям, отдаем себя родителю.

Обещание - это предписание на будущее. Если у узла есть обещание, что
его дети что-то выполнят, то при обращении к нему по какому-либо запросу
(поиск, изменение, проч.) узел "вспоминает", что у него есть обещание, и
заставляет детей выполнить его, а дети в свою очередь дают обещание
выполнить это и для своих детей. Обещание хранится в узле или отдельном
списке и постепенно агрегируется, если обещаний дается много. Например,
если обещалось "+1", "=10", "+4", то итоговое обещание - "=14".

Обещание выполняется за O(1). Нужно для того, чтобы не перестраивать все
при каждом изменении отрезка, что было бы долго, а выполнять оптом все
обещания по мере их накопления, что срезает сложность изменения на
отрезке с O(N) до O(logN).

Таким образом можно прибавлять, присваивать, умножать или делать еще
какие-либо операции.
________________________________________________________________________

Изменение на отрезке для дерева поиска суммы чуть интереснее в том
плане, что при полном покрытии надо не прибавить значение изменения, а
учесть, что это должно было произойти и для детей, и для их детей, и
т.д., т.е. надо умножить величину, которую надо прибавить, на длину зоны
ответственности узла и уже это значение прибавить к значению узла. При
выполнении обещания также не забывать об этом.
________________________________________________________________________

Следующие задачи характеризуют разные модификации и условия, которые
могут применяться в дереве, и являются не столько задачами, сколько
продолжением теории.
________________________________________________________________________

> **Задача 0.1**. Кол-во минимумов на отрезке (в условиях применимости
дерева).

**Решение**:

При заполнении дерева в узле будет храниться значение минимума в зоне
ответственности и кол-во этих минимумов. Тогда значение узла есть
минимум из детей и его кол-во, если разные дети, и значение в детях и
сумма кол-в минимумов в них, если одинаковые.

Поиск в отрезке будет аналогичен поиску, описанному выше.
________________________________________________________________________

> **Задача 0.2**. Кол-во нулей на отрезке (в условиях применимости
дерева).

**Решение**:

Решаем Задачу 0.1 и делаем надстройку: если минимум при запросе 0, то
возвращаем его кол-во, а если не 0, то возвращаем 0.
________________________________________________________________________

> **Задача 0.3.1**. Найти K-ый ноль на префиксе (K-ый ноль с начала; в
условиях применимости дерева). Счет K начинается с 0.

**Решение**:

Заполняем дерево идентично поиску кол-ва минимумов. Если в минимуме не 0
\- возвращаем None или что-то в этом духе. Если нулей в целом
посчитанных меньше K + 1, тоже. Иначе алгоритм:

- Сравниваем K с кол-вом нулей (пускай n) в 1-ом ребенке. Если он должен
    быть там, отдаем ему. Если нет - отдаем правому запрос на поиск
    (K - n)-ого нуля.
________________________________________________________________________

> **Задача 0.3.2**. Найти K-ый ноль на отрезке (K-ый ноль с начала
отрезка; в условиях применимости дерева). Счет K начинается с 0. Отрезок
[L, R].

**Решение**:

Решаем Задачу 0.3.1. Ищем число нулей на отрезке [0, L - 1] (пускай их
k), и тогда все сводится к поиску (K + k)-ого нуля на префиксе. Если он
попал в отрезок [L, R] (т.е. тут проверка, не ушел ли он за R), тогда он
и будет ответом. Нет - None.
________________________________________________________________________

> **Задача 0.4**. Найти самое левое число, большее X (в условиях
применимости дерева).

**Решение**:

Дерево отрезков для поиска максимума. Смотрим в корень, если там число
меньше X - возвращаем None. Иначе смотрим на левого сына, если там
больше X - отдаем запрос ему. Иначе - отдаем запрос правому сыну.
Рекурсивно идем до конца.
________________________________________________________________________

> **Задача 0.5**. Найти самый длинный отрезок из 0 на отрезке [L, R] (в
условиях применимости дерева).

**Решение**:

По аналогии с подсчетом кол-ва минимумов, но:

- Сохраняем 3 параметра: максимальное число нулей, префикс из нулей и
    суффикс из нулей.
- Максимальное число нулей равно максимуму из максимальных чисел нулей
    сыновей и суффикса левого + префикса правого.
- Префикс равен либо префиксу левого сына, либо, если он состоит сугубо
    из нулей (длина зоны ответсвенности = макс. кол-ву нулей), префиксу
    левого сына + префиксу правого сына.
- Суффикс аналогично префиксу.

Поиск значения в отрезке аналогично предыдущим задачам, выдавая все 3
параметра родителям при соответсвующей ситуации (накрылись полностью
или результат из возвращенных сыновьями значений).
________________________________________________________________________

> **Задача 0.6**. Кол-во чисел < X на отрезке [L, R] (X передается при
запросе; в условиях применимости дерева).

**Решение**:

Храним в узле отсортированную пос-ть из эл-тов пос-тей сыновей (ф-ция
merge из темы Два указателя для слияния пос-тей). Например, в сыновьях
[1, 3] и [2, 4], тогда в родителе будет [1, 2, 3, 4]. Говоря иначе,
каждый узел хранит полностью отсортированную пос-ть чисел в его зоне
ответственности. Такая структура займет N logN пространства. Сборка
займет O(N logN).

Тут все так же, как всегда, но при полном накрытии ищем бинпоиском в
узле соответствующее кол-во.

Сложность поиска (примерная): O((logN)\*\*2).

Для того, чтобы изменялось хорошо, нужно хранить не отсорченные списки,
а сбалансированные бинарные деревья.
________________________________________________________________________

### <u> Дерево Фенвика </u> ###
<a id="anchor_prefix_fenwick"></a>

> **ЗАМЕТКА!** Данная структура данных уже где-то на границе со
специальными алгоритмами, так что стоит обратить на нее внимание сугубо
при повышенном интересе или необходимости.

Для общего понимания происходящего прежде см. Битовые операции.

Позволяет с помощью предподсчета получить структуру, считающую сумму на
префиксе, при этом поддерживающую операцию изменения эл-та.

Хуже, чем в префиксной сумме, поиск суммы, но, опять же, поддерживает
операцию изменения эл-та. Константа по сравнению с деревом отрезков
лучше, но не поддерживает операции на отрезке. По сложности аналогично
дереву отрезков по всем операциям.
________________________________________________________________________

Пусть задан массив a, нуль-нумерация. Определим ф-цию F(i) как "заменить
на 0 из числа i все единицы из младших разрядов до ближайшего нуля".
Формулярно:

`F(i) = i & (i + 1)`

Заведем массив t размером массива a, где t[i] есть сумма эл-тов массива
a индексами от F(i) до i включительно.

Тогда сумма на префиксе считается как сумма набора эл-тов массива t.

Например:

```
F[0:7] = [0, 0, 2, 0, 4, 4, 6]

Тогда:
sum(6) = t[6] + t[5] + t[3]
```

Такой набор полностью покрывает сумму на префиксе до 6-ого эл-та
включительно, т.к. t[6] отвечает за эл-ты от 6-ого до 6-ого, t[5] - от
4-ого до 5-ого, t[3] - от 0-ого до 3-его. В таком порядке и находим
подходящие t с помощью F(i), беря за следующую верхнюю границу
(следующий i) число F(i) - 1.
________________________________________________________________________

Изменение элемента делается так:

- Пусть к i-ому эл-ту я хочу прибавить X.

- В какие t был включен i-ый эл-т? Говоря чисто теоретическими
    рассуждениями, во все числа, которые получаются поочередной заменой
    0 на 1 в битовой записи слева направо. Например, для 4-ого эл-та
    (100) это 101 (5-ый) и 111 (7-ой) в пределах данной степени 2, а
    также 1111, 11111 и т.д. до длины массива.

    Переходя к битовым операциям, для получения следующего числа
    достаточно проводить операцию `j | (j + 1)`, пока j <= len(a).

    В сам t[i] и эти найденные индексы надо добавить X.
________________________________________________________________________

Еще полезная фича дерева Фенвика - возм-ть делать многомерное дерево
Фенвика. Например, чтобы считать суммы на прямоугольниках в матрице,
будем использовать двумерное дерево Фенвика, где в каждой ячейке
двумерного дерева Фенвика будет лежать одномерное дерево Фенвика.
________________________________________________________________________

### ДВА УКАЗАТЕЛЯ ###
<a id="anchor_2_pointers"></a>

Понятие пришло из жаргона спортивных программистов. Методику опять же
проще объяснить на примере.
________________________________________________________________________

> **Задача 0**. Дана отсортированная пос-ть чисел длиной N и число K.
Найти кол-во пар чисел A, B, таких что B - A > K.

**Решение 0**:

За O(N\*\*2): перебираем все пары чисел и для каждой проверим условие,
при этом перебирать второе число в паре сугубо правее левого.

**Решение 1**:

За O(N): возьмем наименьшее число и найдем для него первое подходящее
большее. Тогда все числа еще больше полученного правого числа также
подходят. Посчитаем их. Теперь берем в качестве левого числа следующее,
а поиск первого подходящего большего продолжим оттуда, где закончили
поиск онного для предыдущего числа. \
Таким образом, каждый из указателей пробежит N чисел, что и вытекает в
меньшую сложность.

**Код**:

```python
def cntpairswithdiffgtk(sortednums, k):
    cntpairs = 0
    last = 0
    for first in range(len(sortednums)):
        while last < len(sortednums) and \
                sortednums[last] - sortednums[first] <= k:
            last += 1
        cntpairs += len(sortednums) - last
    return cntpairs
```
________________________________________________________________________

Таким образом, идея двух указателей сводится к разворачиванию движения
этих самых указателей из цикла в цикле в один цикл, где перемещения
указателей сводятся к одноразовой пробежке.

> **НО!** Есть нюанс: такая метода требует отсортированности списка
или, если в дано список не отсортирован, проведения сортировки, которая
реализуется обычно за O(N logN). Тем не менее, итоговая сложность
O(N + NlogN) все равно лучше, чем O(N\*\*2).
________________________________________________________________________

> **Задача 1**. Игрок в футбол обладает одной числовой хар-кой -
профессионализмом. Команда называется сплоченной, если профессионализм
любого игрока не превосходит суммарный профессионализм любых двух
других игроков в команде. Команда может состоять из любого кол-ва
игроков. Дана отсортированная пос-ть чисел длиной N - профессионализм
игроков. Найти максимальный суммарный профессонализм сплоченной команды.
(Вариация задачи - даны также номера игроков, и надо кроме того сообщить
номера игроков результирующей команды.)

**Решение**:

В первую очередь - идея о том, что для проверки достаточно сравнивать
максимально сильного игрока в команде и двух слабейших. Тогда для
остальных условие сплоченности также работает.

Возьмем во внимание также и то, что нет смысла не брать кого-то
промежуточного между слабейшим и сильнейшим игроком в условиях
сплоченной команды, т.к. так суммарный профессионализм только
уменьшится. Таким образом не надо перебирать все команды, ибо она
описывается слабейшим и сильнейшим игроком в условиях сплоченности, а
все остальные игроки между ними автоматически подходят.

Перебираем сильнейшего игрока с максимального (правого) до минимального.
За это отвечает правый указатель. Для сильнейшего находим минимального
слабейшего игрока с сохранением условия сплоченности, двигая левый
указатель по принципу двух указателей. Условием минимума слабейшего
игрока будет провал проверки подходящести суммы левого игрока и игрока
слабее него (левый указатель минус 1).

Можно искать решение и наоборот, с фиксированием слабого игрока (слева
направо) по аналогичному принципу. Такое решение и представлено далее.

**Код**:

```python
def bestteamsum(players):
    bestsum = 0
    nowsum = 0
    last = 0
    for first in range(len(players)):
        while last < len(players) and (last == first or \
                players[first] + players[first + 1] >= players[last]):
            nowsum += players[last]
            last += 1
        bestsum = max(bestsum, nowsum)
        nowsum -= players[first]
    return bestsum
```
________________________________________________________________________

> **Задача 2**. Даны две отсортированные пос-ти чисел (длиной N и M
соответственно). Слить их в одну отсортированную пос-ть. (Это так
называемая функция merge, т.е. слияние.)

**Решение**:

Поставим по 1 указателю на начало каждой из пос-тей. Выберем тот,
который указывает на меньшее число, запишем это число в результат и
сдвинем указатель. Когда одна из пос-тей заканчивается, остаток другой
сливаем в результат.

**Код**:

```python
def merge(nums1, nums2):
    merged = [0] * (len(nums1) + len(nums2))
    first1 = first2 = 0
    for k in range(len(nums1) + len(nums2)):
        if first1 != len(nums1) and (first2 == len(nums2) or \
                nums1[first1] < nums2[first2]):
            merged[k] = nums1[first1]
            first1 += 1
        else:
            merged[k] = nums2[first2]
            first2 += 1
    return merged
```
________________________________________________________________________

> **Задача 3**. Найти максимальную по длине подстроку данной строки,
такую, что каждый символ встречается в ней не более k раз.

**Решение**:

Перебираем по 2 указателям, заполняем словарь с эл-тами строки как
ключи, а значения - счетчики. Условие проверки - не тупая проверка
каждого эл-та словаря, т.к. словарь мб большим, а только последнего
эл-та, который изменился, т.к. если для всех остальных ранее все было
хорошо, то с добавлением нового эл-та условие могло нарушиться только в
нем.

**Код**:

```python
n, k = map(int, input().split())
s = input()
d = dict()
l = r = bestl = bestr = 0
while r < n:
    if d.get(s[r], 0) <= k:
        if r - l > bestr - bestl:
            bestr, bestl = r, l
        d[s[r]] = d.get(s[r], 0) + 1
        r += 1
    else:
        while l < n and d.get(s[r], 0) > k:
            d[s[l]] -= 1
            l += 1
print(bestr - bestl + 1, bestl + 1)
```
________________________________________________________________________

Иногда вместо сортировки можно использовать префиксные суммы и работать
с этим. Тогда сложность останется O(N), но применимость узкая под
определенные задачи. Например, следующая задача.
________________________________________________________________________

> **Задача 4**. Вася очень любит везде искать своё счастливое число K.
Каждый день он ходит в школу по улице, вдоль которой припарковано N
машин. Он заинтересовался вопросом, сколько существует наборов машин,
стоящих подряд на местах с L до R, что сумма их номеров равна K.
Помогите Васе узнать ответ на его вопрос.

**Код (мой)**:

```python
N, K = map(int, input().split())
nums = list(map(int, input().split()))

prefixsum = [0] * (N + 1)
for i in range(1, N + 1):
    prefixsum[i] = prefixsum[i - 1] + nums[i - 1]

cnt = 0
right = 1
for left in range(N + 1):
    while right < N and prefixsum[right] - prefixsum[left] < K:
        right += 1
    if prefixsum[right] - prefixsum[left] == K:
        cnt += 1

print(cnt)
```
________________________________________________________________________

### СКОЛЬЗЯЩЕЕ ОКНО ###
<a id="anchor_slidingwin"></a>

Алгоритм "скользящее окно" (sliding window) — это техника оптимизации,
которая используется для решения задач, связанных с обработкой
подмассивов или подстрок фиксированной длины в массиве или строке. Его
можно представить как просмотр фрагмента данных фиксированного размера -
"окна", - который движется вдоль всего массива или строки. И на каждой
итерации производится необходимый расчет.

Основная идея метода, помимо самой концепции движущегося окна,
заключается в том, как реализуется процесс движения окна. А именно
каждый раз не копируется весь набор эл-тов нового окна, а удаляется 1
старый эл-т и добавляется 1 новый.

Основные этапы:

1. Инициализация - выбор размера окна, расчет первичного значения окна
    для самого первого из них.
2. Циклический сдвиг окна путем удаления одного эл-та и добавления
    одного эл-та, а также соответствующий перерасчет величины. Где
    возможно - не полный пробег по окну и повторный перерасчет, а
    изменение величины исходя из удаленного и добавленного эл-та.

Если интересно использование и история метода, можно посмотреть по
ссылкам в Материалах. Кроме того, там можно почитать подробнее в целом.
Но в общем стоит подметить из этих материалов и из leetcode, что
скользящее окно - довольно важный алгоритм, особенно для собеседований.
________________________________________________________________________

> **Задача 1**. Найти максимальную сумму подмассива длины k в массиве
чисел.

**Решение**:

Используем скользящее окно. При смещении вычитаем удаляемый эл-т и
прибавляем добавляемый эл-т. В процессе отслеживаем максимальное
значение.

**Код**:

```python
windowSum = sum(arr[:k])
maxSum = windowSum

for i in range(k, len(arr)):
    windowSum += arr[i] - arr[i - k]
    maxSum = max(maxSum, windowSum)
```
________________________________________________________________________

### ПОИСК ДЕЛЕНИЕМ ОТРЕЗКА ###
<a id="anchor_search_by_seg_div"></a>

### <u> Бинарный поиск </u> ###
<a id="anchor_bin_search"></a>

*Бинарный (двоичный) поиск* - поиск посредством разделения отрезка
пополам до тех пор, пока не будет выполнено условие нахождения нужного
элемента.

> **ВАЖНО!** Работает только для отсортированного списка или монотонной
ф-ции на непрерывном отрезке.

Для условия вводится параметр или функция, которые ведут себя как
ступенька: либо сначала не подходят значения ("все плохо"), а потом
подходят ("все хорошо"), либо наоборот. Тогда в первом случае искомым
будет первое подходящее значение, а во втором - последнее. Такие два
случая условно (не общеупотребимое разделение, просто условность) можно
назвать "левым" и "правым" бинпоиском.

Например, поиск слова в словаре. Функция: искомое слово <= текущему.
Открываем на половине, смотрим. Если "хорошо": смотрим между началом и
серединой. Если "плохо": смотрим между серединой и концом. Полученный
отрезок снова делим пополам и т.д. Условие остановки: правый и левый
конец отрезка совпали.

Может быть и в недискретном случае (например, для приближенного поиска
экстремума в численных методах (метод бисекции)), тогда условием
остановки будет длина отрезка <= некоторого эпсилон, отвечающего за
точность.

*Итоговая сложность*: O(logN).

Для "левого", "правого" бинпоиска и на непрерывном отрезке код
следующий:

```python
# check здесь - некоторая функция проверки, передаваемая в функции
# поисков. В то же время, checkparams - параметры для функции проверки,
# если необходимы.
def lbinsearch(l, r, check, checkparams):
    while l < r:
        m = (l + r) // 2
        if check(m, checkparams):
            r = m
        else:
            l = m + 1
    return l

def rbinsearch(l, r, check, checkparams):
    while l < r:
        m = (l + r + 1) // 2
        if check(m, checkparams):
            l = m
        else:
            r = m - 1
    return l

def fbinsearch(l, r, eps, check, checkparams):
    while l + eps < r:
        m = (l + r) / 2
        if check(m, checkparams):
            r = m
        else:
            l = m
    return l
```

> **ВАЖНО!** Махинации с +- 1 нужны для избежания бесконечного цикла в
подходящем для этого случае, когда осталось 2 элемента, и избегания
ситуации, когда правый указатель меньше левого.
________________________________________________________________________

> **Задача 1**. В управляющий совет школы входят родители, учителя и
учащиеся школы, причем родителей должно быть не менее одной трети от
общего числа членов совета. В настоящий момент в совет входит N ч-к, из
них K родителей. Определить, сколько родителей (M) нужно дополнительно
ввести в совет, чтобы их число стало составлять не менее трети от числа
членов совета.

**Решение**:

Будем искать минимальное кол-во родителей, которых нужно добавить,
бинарным поиском. l = 0, r = N (т.к. при M = N доля родителей не менее
половины от совета). Не забываем, что новые родители прибавляются к
общему числу членов совета. Не используем деление из-за нецелости,
отчего выходим в вещественные числа => неточность, возможность
переполнения при больших кол-вах людей в совете и т.д.

> **ЗАМЕТКА!** Имеется простое математическое решение:
`(K + M) / (N + M) = 1/3`. В данном случае просто решаем программистски
для усвоения темы, но математическое решение, очевидно, быстрее. Далее
по задачам - аналогично.

**Код**:

```python
def lbinsearch(l, r, check, checkparams):
    while l < r:
        m = (l + r) // 2
        if check(m, checkparams):
            r = m
        else:
            l = m + 1
    return l

# эту ф-цию передаем в параметр check, а N, K - в checkparams
def checkendownment(m, params):
    n, k = params
    return (k + m) * 3 >= n + m  # остались в целых числах
```
________________________________________________________________________

> **Задача 2**. Юра решил подготовиться к собеседованию. Он выбрал N
задач. В первый день решил K задач, а каждый следующий раз решал на 1
задачу больше. Сколько дней уйдет у Юры на подготовку к собеседованию
(число решенных задач не менее N).

**Решение**:

Будем искать минимальное кол-во дней, достаточное для решения не менее
N задач, бинарным поиском. Нам понадобится ф-ла арифметической
прогрессии. l = 0, r = N + 1.

> **ЗАМЕТКА!** Есть математическое решение:
`(2 * K + M - 1) * M / 2 = N`.

**Код**:

```python
def lbinsearch(l, r, check, checkparams):...

# эту ф-цию передаем в параметр check, а N, K - в checkparams
def checkproblemcount(days, params):
    n, k = params
    return (k + (k + days - 1)) * days // 2 >= n
```
________________________________________________________________________

> **Задача 3**. Михаилу нужно разместить на доске W x H см N одинаковых
квадратных стикеров, сторона которых - целое число. Найти максимальную
длину стороны стикера, чтобы все стикеры поместились на доске. Стикеры
должны располагаться прямо, без поворотов.

**Решение**:

Ищем максимальную длину стороны стикера бинарным поиском, ища по пути,
сколько стикеров влезает в ряд и в столбец и перемножая их.

**Код**:

```python
def rbinsearch(l, r, check, checkparams):...

def checkstickers(size, params):
    n, w, h = params
    return (w // size) * (h // size) >= n
```
________________________________________________________________________

> **Задача 4**. Задана отсортированная по неубыванию пос-ть из N чисел и
число X. Определить индекс первого числа в пос-ти, которое больше или
равно X. если такого нет, вернуть число N.

> **ЗАМЕТКА!** Задача представляет собой классику объяснения бинпоиска.

**Решение**:

Бинпоиск первого подходящего числа. В случае, если бинпоиск сошелся к
числу, меньшему X, вернем N.

**Код**:

```python
def lbinsearch(l, r, check, checkparams):...

def checkisge(index, params):
    seq, x = params
    return seq[index] >= x

def findfirstge(seq, x):
    ans = lbinsearch(0, len(seq) - 1, checkisge, (seq, x))
    if seq[x] < x:
        return len(seq)
    return ans
```
________________________________________________________________________

> **Задача 5**. Задана отсортированная по неубыванию пос-ть из N чисел и
число X. Определить, сколько раз число X входит в пос-ть.

**Решение**:

Найдем одним бинпоиском первое число не меньшее X, а вторым бинпоиском -
число строго больше X. Разность индексов и будет кол-вом вхождений.
(Как эквивалентная альтернатива - искать строго меньше X и последнее
из меньше или равно X.)

**Код**:

```python
def lbinsearch(l, r, check, checkparams):...

def checkisgt(index, params):
    seq, x = params
    return seq[index] > x

def checkisge(index, params):
    seq, x = params
    return seq[index] >= x

def findfirst(seq. x. check):
    ans = lbinsearch(0, len(seq) - 1, check, (seq, x))
    if not check(ans, (seq, x)):
        return len(seq)
    return ans

def countx(seq, x):
    indexgt = findfirst(seq, x, checkisgt)
    indexge = findfirst(seq, x, checkisge)
    return indexgt - indexge
```

> **ЗАМЕТКА!** Есть решение чуточку быстрее - во втором бинпоиске
начинать не с 0, а с того, что получил первый. Тем не менее, это решение
выигрывает буквально одну пробежку цикла бинпоиска и почти не влияет на
результат, но при этом становится больше кода и страдает его
читабельность. Опять же, тезис о разумности оптимизации из раздела
Сложность данной шпаргалки.
________________________________________________________________________

> **Задача 6**. Задана процентная ставка по кредиту X% годовых, срок
кредитования N месяцев и сумма кредита M рублей. Необходимо рассчитать
размер аннуитетного ежемесячного платежа.

> **ЗАМЕТКА!** Аннуитетный ежемесячный платеж - выплата одинаковых сумм
каждый месяц, причем первое время в основном это деньги процентов, а
потом - самого долга.

**Решение**:

Подзадача о ежемесячном проценте: ежемесячный процент не равен X / 12.
Подберем его бинпоиском. \
Сама задача: будем перебирать сумму платежа бинпоиском, а в качестве
проверки моделировать процесс ежемесячной выплаты, уменьшая тело кредита
на разницу между суммой платежа и ежемесячным платежом.

> **ЗАМЕТКА!** Есть математическое решение.

**Код**:

```python
def fbinsearch(l, r, eps, check, checkparams):...

# подзадача о ежемесячном проценте
def checkmonthlyperc(mperc, yperc):
    msum = 1 + mperc / 100
    ysum = 1 + yperc / 100
    return msum**12 >= ysum

def getmontlyperc(yperc, eps):
    return fbinsearch(0, yperc, eps, checkmonthlyperc, yperc)

# сама задача
def checkcredit(mpay, params):
    periods, creditsum, mperc = params
    for i in range(periods):
        percpay = creditsum * (mperc / 100)
        creditsum -= mpay - percpay
    return creditsum <= 0

def getmonthlypay(n, m, eps, mperc):
    return fbinsearch(0, m, eps, checkcredit, (n, m, mperc))
```
________________________________________________________________________

> **Задача 7**. n велосипедистов, участвующих в шоссейной гонке, в
некоторый начальный момент времени оказались в точках, удаленных от
места старта на x[1] ... x[n] метров. Каждый велосипедист двигается со
своей постоянной скоростью v[1] ... v[n] м/с. Все велосипедисты
двигаются в одну и ту же сторону. Необходимо найти момент времени, когда
расстояние между лидирующим и последним велосипедистом минимально.

> **ЗАМЕТКА!** Из-за обгонов первым и последним велосипедистами могут
стать другие велосипедисты с течением времени, нежели в начале.

**Решение**:

Определим функцию `dist(t)`, которая будет за O(N) определять расстояние
между лидером и замыкающим в момент времени t. У этой ф-ции 1 минимум,
т.к. скорость первого может только увеличиваться, а последнего только
уменьшаться, представляя кусочно-линейную ф-цию. Если
`dist(t + eps) > dist(t)`, то ф-ция растет и надо сдвинуть левую границу
поиска, иначе - правую.

> **ЗАМЕТКА!** Тут должен был быть тернарный поиск, но в итоге
использовали бинпоиск по производной.

**Код**:

```python
def fbinsearch(l, r, eps, check, checkparams):...

def dist(t, params):
    x, v = params
    minpos = maxpos = x[0] + v[0] * t
    for i in range(1, len(x)):
        nowpos = x[i] + v[i] * t
        minpos = min(minpos, nowpos)
        maxpos = max(maxpos, nowpos)
    return maxpos - minpos

def checkasc(t, eps, params):
    return dist(t + eps, params) >= dist(t, params)
```
________________________________________________________________________

### <u> Тернарный поиск </u> ###
<a id="anchor_ternary_search"></a>

*Тернарный (троичный) поиск* - поиск, применяемый для нахождения
максимума или минимума унимодальной ф-ции или пос-ти. Сложность:
O(logN).

> **ЗАМЕТКА!** *Унимодальная ф-ция* - это ф-ция, имеющая только один
экстремум на данном отрезке.

> **ЗАМЕТКА!** В более конкретном смысле сложность не logN, а log3/2 N.
А еще более конкретно - с константами. Тем не менее, по свойствам
логарифма можно утверждать, что log3/2 N = C \* logN, что есть сложность
O(logN). Тем не менее, более конкретная сложность понадобится при
сравнении разных методов на основе деления отрезка.

Рассмотрим на примере поиска максимума, минимум симметричен.
Алгоритм троичного поиска максимума последовательности:

1. Разбить диапазон поиска на 3 части, сравнить значения на границах
    этих частей.
1. Если значения возрастают, изменить левую границу диапазона на меньшую
    границу разбиения. Если значения убывают, изменить правую границу
    диапазона на большую границу разбиения.
1. Продолжать, пока не останется 3 элемента. Затем возвращаем максимум
    из них.

**Код**:

```python
def ternarysearch_seqmax(seq):
    l, r = 0, len(seq)

    while l < r - 3:
        left_third = (2 * l + r) // 3
        right_third = (l + 2 * r) // 3
        
        if seq[left_third] < seq[right_third]:
            l = left_third
        else:
            r = right_third

    return max(s[l], s[l + 1], s[l + 2])
```

Алгоритм троичного поиска точки максимума функции:

1. Разбить диапазон поиска на 3 части, сравнить значения на границах
    этих частей.
1. Если значения возрастают, изменить левую границу диапазона на меньшую
    границу разбиения. Если значения убывают, изменить правую границу
    диапазона на большую границу разбиения.
1. Продолжать, пока не достигнем желаемой точности. Максимум функции
    всегда находится между границ разбиения.

**Код**:

```python
def ternarysearch_funcmax(func, l, r, eps):
    while r - l >= eps:
        x1 = l + (r - l) / 3
        x2 = r - (r - l) / 3
        
        if func(x1) < func(x2):
            l = x1
        else:
            r = x2

    return (l + r) / 2
```
________________________________________________________________________

В общем виде тернарный поиск может применяться и по тем же задачам, что
и бинарный: поиск подходящего значения по первому или последнему
вхождению, подходящему по функции проверки. Тем не менее, в общем случае
бинарный поиск с этими задачами справляется быстрее примерно в 1.26 раз,
т.к. его сложность меньше, рассматривая конкретику (см. Материалы).

Но в случае поиска экстремума унимодальной ф-ции все меняется, т.к. для
бинарного поиска требуется дополнительное действие на каждом шаге -
подсчет производной (напомим, что бинпоиск рассчитан на монотонную ф-цию
или пос-ть, а не унимодальную). Таким образом получается, что тернарный
поиск затратит меньше времени, т.к. его сложность меньше.
________________________________________________________________________

### <u> Поиск методом золотого сечения </u> ###
<a id="anchor_golden_search"></a>

*Метод золотого сечения*, или "золотой" поиск - поиск, применяемый для
нахождения максимума или минимума унимодальной ф-ции или пос-ти.
Представляет собой модификацию идеи тернарного поиска, и относительно
него позволяет уменьшить число операций за итерацию с 2 до 1.

Применимо только для ф-ций, для пос-тей - метод Фибоначчи (см. Более
экзотические методы).

Сложность: O(logN).

> **ЗАМЕТКА!** В более конкретном смысле сложность не logN, а log_phi N.
А еще более конкретно - с константами. Тем не менее, по свойствам
логарифма можно утверждать, что log_phi N = C \* logN, что есть
сложность O(logN). Тем не менее, более конкретная сложность понадобится
при сравнении разных методов на основе деления отрезка.

Идея состоит в делении отрезка на 3 части так, чтобы на следующей
итерации одна из точек нового разбиения совпала с одной из точек
текущего разбиения, что позволит на каждом шаге делать на одно
вычисление меньше. Определяя нехитрыми математическими действиями
(подробнее см. Материалы) подходящие соотношения, получим, что такое
разбиение возможно при расстояниях по золотому сечению.

Алгоритм тот же, что и в тернарном поиске, с различием в расположении
точек разбиения и сохранением уже вычисленных значений.

**Код**:

```python
def goldensearch_funcmax(func, l, r, eps):
    phi = (1 + 5**(1 / 2)) / 2
    x1 = l + (2 - phi) * (r - l)
    x2 = r - (2 - phi) * (r - l)
    f1, f2 = func(x1), func(x2)

    while r - l >= eps:
        if f1 < f2:
            l, x1 = x1, x2
            f1 = f2
            x2 = r - (2 - phi) * (r - l)
            f2 = func(x2)
        else:
            r, x2 = x2, x1
            f2 = f1
            x1 = l + (2 - phi) * (r - l)
            f1 = func(x1)
    
    return (l + r) / 2
```
________________________________________________________________________

Несмотря на результирующую сложность, в реальности на смену
дополнительным подсчетам пришло большее число записей в переменные, что
вызывает спорную ситуацию о том, что лучше: тернарный или "золотой"
поиск. Но если это опустить, то "золотой" поиск лучше по сложности
подсчетов примерно в 2.37 раз (см. Материалы).
________________________________________________________________________

### <u> Более экзотические методы </u> ###
<a id="anchor_exotic_search"></a>

Здесь представлены довольно редко встречающиеся методы поиска,
основанные на делении отрезка. Они могут быть быстрее своих популярных
собратьев выше или на том же уровне, но при этом по тем или иным
причинам используются реже. Для собеседования будет плюсом просто знать
их, но задач на них не будет. В жизни тоже маловероятно пригодятся, но
тем не менее, для общего ознакомления все же было решено представить их.
________________________________________________________________________

<u>*Квадратный поиск*</u> - продолжение идеи тернарного поиска, которое
разбивает отрезок не на 3, а на 4 части; при этом с использованием идей
"золотого" поиска с сохранением одного из значений для будущих итераций.

Рассмотрим рекурсивную версию реализации. Алгоритм следующий:
1. Как и в тернарном поиске, рекурсивно вычисляем минимум функции на
    промежутке L, R, но в трёх точках: в A = (3L + R) / 4,
    B = (L + R) / 2 и C = (L + 3R) / 4.
1. Посмотрим, какое из этих значений в этих трёх точках самое маленькое.
    При этом, надо заметить, что если f(A) <= f(B), то это уже означает,
    что левое значение - самое маленькое, если f(С) <= f(B) - то правое;
    в остальных случаях - среднее.
1. Если самое маленькое - левое, то запускаемся рекурсивно на отрезке
    [L, B], если правое - на отрезке [B, R], а если среднее - то на
    отрезке [A, C]. Длина отрезка всегда уменьшается в два раза. 

Для оптимизации заметим одну вещь: когда мы запустимся от одного из трёх
отрезков, нам понадобится знать три значения на этом отрезке. Но одно из
них - среднее - мы уже вычисляли на предыдущем шаге. Поэтому его не надо
вычислять ещё раз: его можно просто передать. Значит, на каждом шаге мы
вычисляем уже не 3, а 2 значения.

А теперь для еще большей оптимизации заметим ещё одну вещь: для того,
чтобы знать, что надо перейти в левый отрезок, нам надо узнать только
значения в точках A и B. Поэтому значение в точке C можно пока не
вычислять: оно может и не пригодится.

**Код**:

```python
def quadsearch_funcmin(func, L, R, eps, midVal):
    if R - L < eps:
        return (R + L) / 2

    leftVal = func((3 * L + R) / 4)
    if leftVal < midVal:
        return quadsearch_funcmin(func, L, (L + R) / 2,
                                  eps, leftVal)
    else
        rightVal = func((L + 3 * R) / 4)
        if rightVal < midVal:
            return quadsearch_funcmin(func, (L + R) / 2, R,
                                      eps, rightVal)
        else:
            return quadsearch_funcmin(func, (3 * L + R)/4, (L + 3 * R) / 4,
                                      eps, midVal)
```

Таким образом, количество требуемых итераций в 1.71 раз меньше, а
количество вычисляемых значений за итерацию в среднем меньше, чем в
тернарном поиске.

Несмотря на все перечисленные улучшения относительно тернарного поиска,
по сравнению с "золотым" поиском квадратный все же медленнее:
- по верхней оценке (O) - за 2 вычисления ф-ции квадратный поиск
    сокращает длину отрезка в 2 раза, а "золотой" - в 2.62.
- по средней оценке (сигма) квадратного поиска - в 2.4 раза против тех
    же 2.62.

Поэтому данный метод практически не используется.
________________________________________________________________________

<u>*Метод Фибоначчи*</u> - небольшая модификация "золотого" поиска,
применяемая для пос-тей, а не ф-ций. Использует числа Фибоначчи
(которые, напомним, связаны с золотым сечением отношением
`lim F[n + 1] / F[n] = phi`) и по ним и делит отрезок пос-ти следующим
образом: если длина отрезка равна F[n], то следует разбить его на
отрезки F[n - 2], F[n - 3], F[n - 2]. Что делать, если длина
последовательности не является числом Фибоначчи? Взять первое число
Фибоначчи, которое не меньше длины последовательности, и первой
операцией отрезать лишний хвост. Для этого придется в начале
дополнительно дважды получить элемент последовательности.
________________________________________________________________________

### СОРТИРОВКА СОБЫТИЙ ###
<a id="anchor_eventsort"></a>

Это не столько алгоритм, сколько подход к решению задач. Суть
заключается в отношении к полученным данным как к событиям, где это
уместно, и их последующая обработка.

Пусть есть некоторые отрезки времени, когда происходило что-то
длительное (например, пользователь находился на сайте). Известно начало
и конец этого отрезка времени, и на самом деле интересны только эти
моменты времени, т.к. в них и происходит событие (например, вход и выход
с сайта). Надо что-то посчитать (например, какое максимальное кол-во
людей было на сайте одновременно или суммарное время, когда на сайте
был хотя бы один человек). В таких случаях и используется данный метод.

Важно обратить внимание на одновременные события и их приоритет
(например, что происходит первее: вход одного пользователя или выход
другого).

Тогда можно, отсортировав список событий, сделать по нему проход и за
O(N) узнать необходимые данные. Общая сложность таким образом -
O(N logN).
________________________________________________________________________

> **Задача 1.1**. Сайт посетило N человек, для каждого известно время
входа на сайт In и время выхода с сайта Out. Считается, что ч-к был на
сайте с In по Out включительно. Определите, какое максимальное кол-во
ч-к было на сайте одновременно.

**Решение**:

Создадим для каждого ч-ка 2 события: "вход" и "выход". Каждое событие -
пара, в которой первое число - время, второе - тип. При этом из условия
событие "вход" должно происходить раньше события "выход". Для этого
тип события, который будем выражать числом, для "входа" должен быть
меньше.

Сортируем события, проходим по ним, и каждый раз исходя из типа события,
увеличиваем или уменьшаем счетчик. Записываем в максимум, если оно
больше текущего максимума.

> **ЗАМЕТКА!** Коды событий в программе ниже заданы хардово (-1 и 1).
Для расширяемости и читабельности лучше задавать их в отдельных
константах.

> **ЗАМЕТКА!** Здесь реализация обработки событий через if-else. В
реальном случае чаще всего возможных событий и их кодов множество, в том
числе обработка случая, когда прилетел неизвестный код события, поэтому
куда лучше использовать конструкцию if-elif-else, где else для
неизвестных кодов, или match-case, где _ для неизвестных кодов.

**Код**:

```python
def maxvisitorsonline(n, tin, tout):
    events = []
    for i in range(n):
        events.append((tin[i], -1))
        events.append((tout[i], 1))
    # отсортирует по времени, а среди одинаковых времен - по типу
    events.sort()
    online = 0
    maxonline = 0
    for event in events:
        if event[1] == -1:
            online += 1
        else:
            online -= 1
        maxonline = max(online, maxonline)
    return maxonline
```
________________________________________________________________________

> **Задача 1.2**. Те же условия. Определите, какое суммарное время на
сайте был хотя бы 1 ч-к.

**Решение**:

Создаем события, сортируем, проходим по ним, и каждый раз исходя из типа
события, увеличиваем или уменьшаем счетчик. Перед изменением счетчика
смотрим, больше ли счетчик, чем 0, и если да, то добавляем к результату
отрезок времени от предыдущего события до этого.

**Код**:

```python
def getnotemptytime(n, tin, tout):
    events = []
    for i in range(n):
        events.append((tin[i], -1))
        events.append((tout[i], 1))
    events.sort()
    online = 0
    notemptytime = 0
    for i in range(len(events)):
        if online > 0:
            notemptytime += events[i][0] - events[i - 1][0]
        if events[i][1] == -1:
            online += 1
        else:
            online -= 1
    return notemptytime
```
________________________________________________________________________

> **Задача 1.3**. Те же условия. Начальник заходил на сайт M раз в
моменты времени Boss и смотрел, сколько людей сейчас онлайн. Какие
показания счетчика людей онлайн увидел начальник?

**Решение**:

Создадим третий тип события - "вход начальника", который обозначим за 0,
чтобы, из условия задачи, он считал людей тогда, когда все события входа
обработан, а события выхода еще нет. При наступлении события "вход
начальника" сохраним значение счетчика посетителей.

**Код**:

```python
def bosscounters(n, tin, tout, m, tboss):
    events = []
    for i in range(n):
        events.append((tin[i], -1))
        events.append((tout[i], 1))
    for i in range(m):
        events.append((tboss[i], 0))
    events.sort()
    online = 0
    bossans = []
    for i in range(len(events)):
        if events[i][1] == -1:
            online += 1
        elif events[i][1] == 1::
            online -= 1
        else:
            bossans.append(online)
    return bossans
```
________________________________________________________________________

> **Задача 2.1**. На парковке N мест (занумерованы от 1 до N). За день
на парковку приезжало M автомобилей, при этом некоторые из них занимали
несколько подряд идущих парковочных мест. Для каждого автомобиля
известно время приезда и отъезда, а также 2 числа: с какого по какое
парковочные места он занимал. Если в какой-то момент времени один
автомобиль уехал с парковочного места, то место считается освободившимся
и в тот же момент на это место может заехать другой. Был ли момент, в
который были заняты все парковочные места?

**Решение**:

События - отъезд и приезд авто (отъезд раньше приезда). Будем считать
кол-во занятых мест, и если после очередного события счетчик равен N, то
такие моменты были.

**Код**:

```python
def isparkingfull(cars, n):
    events = []
    for car in cars:
        timein, timeout, placefrom, placeto = car
        events.append((timein, 1, placeto - placefrom + 1))
        events.append((timeout, -1, placeto - placefrom + 1))
    events.sort()
    occupied = 0
    for i in range(len(events)):
        if events[i][1] == -1:
            occupied -= events[i][2]
        elif events[i][1] == 1:
            occupied += events[i][2]
        if occupied == n:
            return True
    return False
```
________________________________________________________________________

> **Задача 2.2**. Те же условия, но определить, был ли такой момент, что
были заняты все парковочные места, и определить минимальное кол-во авто,
которое заняло все места. Если такого момента не было - вернуть M + 1.

**Решение**:

Добавим еще один счетчик на кол-во автомобилей и будем обновлять
минимальное число авто, когда заняты все места.

**Код**:

```python
def mincarsonfullparking(cars, n):
    events = []
    for car in cars:
        timein, timeout, placefrom, placeto = car
        events.append((timein, 1, placeto - placefrom + 1))
        events.append((timeout, -1, placeto - placefrom + 1))
    events.sort()
    occupied = 0
    nowcars = 0
    mincars = len(cars) + 1
    for i in range(len(events)):
        if events[i][1] == -1:
            occupied -= events[i][2]
            nowcars -= 1
        elif events[i][1] == 1:
            occupied += events[i][2]
            nowcars += 1
        if occupied == n:
            mincars = min(mincars, nowcars)
    return mincars
```
________________________________________________________________________

*События на круге* - подвид задач на события, в которых события
происходят на круговой оси времени (например, ежедневно, где круг - это
сутки). Проблема относительно обычных задач на события - это то, что
событие начала может произойти в предыдущий круг (предыдущие сутки), а
событие конца - в текущий. Тогда, пробегаясь как обычно, будет неясно
до самого конца, сколько событий началось до пробежки.

Есть варианты решения такой ситуации. Например, *разрезать отрезки*,
проходящие через полночь, на 2 на этапе заполнения списка событий. Но
приходится быть аккуратным на этом разделении, чтобы появившиеся
фантомные события не повлияли на результат и его точность.

Другой вариант - *два прохода* по кругу. Для этого нужно нумеровать
отрезки и отслеживать те, с которыми произошло начальное событие, но не
произошло оканчивающее, и если произошло окончание отрезка, но его нет в
отрезке, то просто его игнорировать, а в ином случае - поддержание
отслеживания + счетчик. Тогда к концу первой пробежки получаем список
отрезков, проходящих через полночь, и счетчик на кол-ве этих отрезков.

> **ЗАМЕТКА!** Решение разрезать отрезки не ультимативно правильное,
т.к. опять же появляются нагромождения с тем, как делить отрезки и как
затем все это обрабатывать, чтобы не возникало ошибки или слишом большой
погрешности. Плюс по тем же причинами два прохода универсальнее, т.к.
разделение отрезков не везде применимо. Также два прохода в целом
применимы как способ мышления для более эффективного решения задачи, что
показано далее.
________________________________________________________________________

> **Задача 2.3**. Те же условия, но определить, был ли такой момент, что
были заняты все парковочные места, и определить минимальное кол-во авто,
которое заняло все места, а также номера этих авто по списку. Если
никогда такого не было, вернуть пустой список.

**Решение 1 (неэффективное)**:

Добавим в событие номер авто в списке. Сохраняем список с текущими
номерами авто. При обновлении минимума копируем текущее состояние в
ответ.

> **НО!** Можно "завалить" решение: существуют начальные данные,
вызывающие частое обновление минимума. Тогда копирование одного массива
в другой будет в среднем занимать N / 2 каждые ~ N / 3 событий,
уведичивая сложность до N\*\*2.

**Код**:

```python
def mincarsonfullparking(cars, n):
    events = []
    for i in range(len(cars)):
        timein, timeout, placefrom, placeto = cars[i]
        events.append((timein, 1, placeto - placefrom + 1, i))
        events.append((timeout, -1, placeto - placefrom + 1, i))
    events.sort()

    occupied = 0
    nowcars = 0
    mincars = len(cars) + 1
    carnums = set()
    bestcarnums = set()

    for i in range(len(events)):
        if events[i][1] == -1:
            occupied -= events[i][2]
            nowcars -= 1
            carnums.remove(events[i][3])
        elif events[i][1] == 1:
            occupied += events[i][2]
            nowcars += 1
            carnums.add(events[i][3])
        if occupied == n and nowcars < mincars:
            mincars = nowcars
            bestcarnums = carnums.copy()
    return bestcarnums
```

**Решение 2**:

Решить двумя проходами: сначала определить минимальное, а затем выявить
номера машин в таком случае. Тогда мн-ва не копируются и решение не
заваливается, как предыдущее.

> **ЗАМЕТКА!** Сложность: O(M logM).

**Код**:

```python
def mincarsonfullparking(cars, n):
    events = []
    for car in cars:
        timein, timeout, placefrom, placeto = car
        events.append((timein, 1, placeto - placefrom + 1))
        events.append((timeout, -1, placeto - placefrom + 1))
    events.sort()

    occupied = 0
    nowcars = 0
    mincars = len(cars) + 1
    for i in range(len(events)):
        if events[i][1] == -1:
            occupied -= events[i][2]
            nowcars -= 1
        elif events[i][1] == 1:
            occupied += events[i][2]
            nowcars += 1
        if occupied == n and nowcars < mincars:
            mincars = nowcars

    carnums = set()
    nowcars = 0
    for i in range(len(events)):
        if events[i][1] == -1:
            occupied -= events[i][2]
            nowcars -= 1
            carnums.remove(events[i][3])
        elif events[i][1] == 1:
            occupied += events[i][2]
            nowcars += 1
            carnums.add(events[i][3])
        if occupied == n and nowcars == mincars:
            return carnums
    return set()
```
________________________________________________________________________

### ДИНАМИЧЕСКОЕ ПРОГРАММИРОВАНИЕ ###
<a id="anchor_dynprog"></a>

*Динамическое программирование* — это способ решения сложных задач путём
разбиения их на более простые подзадачи. Метод сводит к минимуму лишние
вычисления и оптимизирует производительность, потому что разбивает
большую задачу на более мелкие подзадачи, решает каждую из них и
сохраняет результаты.

По сути говоря данный подход представляет собой математическую индукцию
с базой (начальные значения) и переходом (от i-ого шага к (i + 1)-ому).

В основном предназначено для решения задач подсчета вариантов или
максимумов/минимумов.
________________________________________________________________________

### <u> С одним параметром </u> ###
<a id="anchor_dynprog_one_param"></a>

> **Задача 1**. Посчитать n-ое число Фибоначчи.

**База-переход**:

*База*:
- `F(0) = 1`.
- `F(1) = 1`.

*Переход*:
- `F(n) = F(n - 1) + F(n - 2)`.

**Решение 1**:

Рекурсивное. Такое решение может быть оптимизировано, т.к. часто
приходится пересчитывать те же самые конструкции: например,
F(10) = F(9) + F(8), а F(9) = F(8) + F(7), и т.к. рекурсивно все
вызывается, то расчет F(8) будет произведен дважды, а это целое дерево
вызовов.

**Решение 2**:

Подтянуть кэширование в рекурсию - *рекурсия с мемоизацией*. На жаргоне
называется *ленивое динамическое программирование*.

**Код**:

```python
def fib(n, dp):
    if dp[n] == -1:
        dp[n] = fib(n - 1, dp) + fib(n - 2, dp)
    return dp[n]

n = <some_int>
dp = [-1] * (n + 1)
dp[0] = dp[1] = 1
print(fib(n, dp))
```

**Решение 3**:

Лучшим решением, впрочем, будет решать без рекурсии, т.к. вызов ф-ции -
затратная операция. Тут решается циклом с заполнением массива длиной
n + 1 и заданными 0-ым и 1-ым значением от 2-ого эл-та и до n-ого, если
нужно запомнить предыдущие значения, и перекладыванием значений в пару
переменных, если запомнинать не нужно.
________________________________________________________________________

> **Задача 2.1**. Иван стоит перед лестницей. Он может подниматься на 1,
2 или 3 ступеньки за шаг. Сколькими способами Иван может попасть на
ступеньку номер n?

**Решение**:

*База*:
- На 0ую ступеньку мы можем попасть 1 способом.
- На 1ую ступеньку мы можем попасть 1 способом.
- На 2ую ступеньку мы можем попасть 2 способами.

*Переход*:
- На n-ую ступеньку мы можем попасть с n - 1, n - 2, n - 3 ступенек, на
    которые можем попасть A, B, C способами. Тогда на n ступеньку мы
    можем попасть A + B + C способами.

Таким образом, получаем мат.индукцию, по которой начиная с 3ей ступеньки
считаем до необходимой n-ой.
________________________________________________________________________

> **Задача 2.2**. Иван стоит перед лестницей. Он может подниматься на 1
или 2 ступеньки за шаг. Ступеньки со стоимостью, получает ее, если
наступает на ступеньку (мб отрицательной). Максимум полученной суммы?

**Решение**:

Пусть `dp[i]` - максимальная прибыль за посещение i-ой ступеньки с
учетом ее самой. Пусть `cost` - список стоимостей ступенек,
`cost[0] = 0`.

*База*:
- `dp[0] = cost[0]`.
- `dp[1] = cost[1]`.

*Переход*:
- Мы можем попасть на n-ую ступеньку с n - 1 и n - 2. Тогда: 
`dp[n] = max(dp[n - 1], dp[n - 2]) + cost[n]`.
________________________________________________________________________

> **Задача 2.3**. Задача 2.2 + в ответе кроме того вывести номера
ступенек, с помощью которых получен данный результат.

**Решение**:

Помимо dp запоминаем для каждой супеньки ту, с которой пришли. Тогда в
результате получится восстановить в конце путь по ступенькам.
________________________________________________________________________

> **Задача 3**. Найти наибольшую возрастающую подпоследовательность.
Для получения подпос-ти - вычеркунуть некоторые числа в пос-ти (т.е.
не обязательно подряд идущие эл-ты).

> **ЗАМЕТКА!** Есть вариант задачи с восстановлением данной подпос-ти.
Решается аналогично Задаче 2.3.

**Решение**:

Для каждой позции запоминаем длину самой большой подпос-ти, которая
заканчивается в ней. Для этого для каждой позиции перебираем предыдущие,
среди подходящих ищем максимум и прибавляем к нему 1. Если ранее
подходящих нет, запишем 1. Затем найдем максимум.

И да, сложность O(N\*\*2). И это нормально. Задачу можно решить за
O(N logN), но в контексте данной темы только за O(N\*\*2).
________________________________________________________________________

> **Задача 4**. В кассу выстроилась очередь из N ч-к. i-ый ч-к может
купить билет: себе за A[i] времени; себе и следующему за B[i] времени;
себе и двум следующим за C[i] времени. Обилетить всех как можно быстрее.

**Решение**:

dp[i] - минимальное время на обилечивание людей от 0-ого до i-ого
включительно.

*База*:
- `dp[0] = A[0]`.
- `dp[1] = min(A[0] + A[1], B[1])`.
- `dp[2] = min(A[0] + A[1] + A[2], B[0] + A[2], A[0] + B[1], C[2])`.

*Переход*:
- `dp[i] = min(dp[i - 1] + A[i], dp[i - 2] + B[i - 1], dp[i - 3] + C[i - 2])`.

> **ЗАМЕТКА!** В случае необходимости (например, наличие списка D, E и
т.д.) может быть нерационально считать базу вручную, и тогда можно
добавить виртуальных людей на отрицательные индексы, расширив нулями
dp и бесконечностями начальные данные.
________________________________________________________________________

> **Задача 5**. Представить число N (до 10000) в виде арифметического
выражения с наименьшим кол-вом символов, в котором используются числа
до K, операции сложения, умножения и скобки.

**Решение**:

Число i может быть получено как:
- `i = j + (i - j)`.
- `i = j * (i // j)`, если i кратно j. Но если j или i // j оптимально
представляется в виде суммы, то нужно его заключить в скобки.

Таким образом, оптимальнее всего будет вести 2 оптимальных аналога dp -
S[i] и M[i] - оптимальное представление числа i в виде суммы и
произведения соответственно.

Кроме того, для получения результата оптимальнее таскать с собой список
строку ans[i] с выражением в ней для i-ого.

*База*:
- ans[0] ... ans[K] - строковое представление чисел 0 ... K.
- S[0] ... S[K], M[0] ... M[K] заполняем длиной в символах чисел 0 ... K
    соответственно.

*Переход*:
- `S[i] = min(min(S[j], M[j]) + min(S[i - j], M[i - j]) + 1)` по всем j
    от 0 до i // 2 + 1.
- `M[i] = min(min(M[j], S[j] + 2) + min(M[i // j], S[i // j] + 2) + 1)`
    по всем j, которые являются делителем i.
- С ans больше сложностей, т.к. конкатенация, перезапись строки и проч.
    операции могут потребовать времени порядка O(N), что превратит
    сложность алгоритма в O(N\*\*3). Тут надо особеннее, мб не таская
    строку, а запоминая, из чего мы получаем самый оптимальный вариант.
________________________________________________________________________

### <u> С двумя параметрами </u> ###
<a id="anchor_dynprog_two_params"></a>

Двумерный случай. Имеет 2 параметра, к которым мы динамически подходим.
Бывают как похожими на одномерный случай - параметры одной природы, -
так и далекими друг от друга или особенными случаями - параметры разной
природы, динамика по подстрокам.

Вычисляется в двумерном массиве, по сравнению с одномерным случаем.

Рассмотрим параметры одной природы.
________________________________________________________________________

> **Задача 1.1**. Задача про черепашку. В каждой клетке п/у таблицы
записано положительное число монеток. Черепашка движется из левого
верхнего в правый нижний угол и собирает монетки. Она может двигаться
только вправо или вниз. Определить максимальное число монеток, которое
соберет черепашка по пути в правый нижний угол.

**Решение**:

Для каждой клетки будем считать макс. кол-во монеток, которое черепашка
будет иметь, когда придет в эту клетку. Т.е. выбирать максимум из левой
и верхней клетки и прибавлять к ней значение в текущей. Идем построчно.
База - нули в нулевой строке и столбце.

Ответ - в правом нижнем углу.
________________________________________________________________________

> **Задача 1.2**. Задача про черепашку без долгов. В клетках мб
отрицательное число монеток. Черепашка не должна уходить в долг.
Определить минимальное число монеток, которое должно быть у черепашки
изначально, чтобы дойти.

**Решение**:

Смешение бинпоиска и динамики. Кол-во необходимых монет ищем по
бинпоиску, а функцией-критерием для бинпоиска будет то, сможет ли
черепашка пройти, не залезая в долги, реализованную динамически как в
Задаче 1.1.

Поиск тут, храня 2 параметра - максимум денег и минимум долгов на пути -
не выйдет, т.к. выравнивая динамику по максимуму денег мы можем прийти в
ситуацию где-то посреди процесса, что денег-то много получилось, но и
был момент, когда долг был не минимальный. И наоборот, выравниваясь по
минимуму долга, мы можем прийти в момент, что не запасли достаточно,
хотя могли, пусть и с чуть большим долгом, и в итоге следующим ходом
влезли в еще большие долги, чем могли.

Тут не получается смотреть эти параметры раздельно, нужна общая функция,
и вот тут помогает объединение через бинпоиск, введение критерия
"прошла/не прошла" и введения правила, что в долги входить нельзя.
________________________________________________________________________

> **Задача 2**. Найти наибольшую общую подпос-ть двух пос-тей.

> **ПРИМЕР:** НОП(АБВАБ, ГВАВВБ) = АВБ.

**Решение**:

Как бы собираем таблицу с символами одной пос-ти `pc` в тайтлах
столбцов, а другой пос-ти `pr` - строк.

dp[i][j] хранит наибольшую общую подпос-ть pc[0:i + 1] и pr[0:j + 1].

*База*:
- Верхняя строка и первый столбец.

*Переход*:
- `dp[i][j] = dp[i - 1][j - 1] + 1`, если символы совпали.
- `dp[i][j] = max(dp[i - 1][j], dp[i][j - 1])`, если символы не совпали.

Заметна аналогия с задачей про черепашку.
________________________________________________________________________

> **Задача 3**. Редакционное расстояние - минимальное кол-во операций
вставки, удаления и изменения символа, необходимое для преобразования
одной строки в другую. Найти его для 2 пос-тей.

> **ПРИМЕР:** ВОЛЫНКА и ВАЛЕНОК требуют 4 операции: инд1 - замена О на
А, инд3 - замена Ы на Е, инд5 - вставка О, инд8 - удаление А.

**Решение**:

Строим по аналогии с Задачей 2 таблицу. В целом это похожие задачи,
только теперь мы минимизируем кол-во замен.

Если буквы в dp[i][j] совпали, то пришли с 0 доп.замен из
dp[i - 1][j - 1]. Если не совпали - мы могли прийти из левой, верхней
или лево-верхней клетки, если соответствующие операции пригодны
(последняя есть замена, она пригодна всегда). Среди пригодных выбираем
минимум проведенных операций, прибавляем 1 и записываем.
________________________________________________________________________

Теперь рассмотрим параметры разной природы.
________________________________________________________________________

> **Задача 4**. Васе известны цены на обед в столовой на ближайшие N
дней вперед. Если Вася заплатил за обед больше 100 рублей, то он
получает купон на бесплатный обед в будущем, который может использовать
в любой день независимо от цены обеда в нем. Вася обедает ежедневно.
Минимизировать траты, а если способов несколько, то среди них выбрать
тот, в котором сохранится максимальное число купонов.

**Решение**:

Строим таблицу, по одной оси кол-во дней, которое Вася ел, а по другой -
кол-во купонов, которое есть у Васи. Тогда dp[i][j] - состояние, когда
Вася ел i дней и имеет после этого j купонов, и содержит в себе
минимальное число рублей, за которое можно в это состояние попасть.

В dp[i][j] можно попасть сугубо из (i - 1)-ого дня, а вот с купонами:

- Из j + 1 купонов, если Вася поел за купон.
- Из j купонов, если Вася поел за деньги и стоило это не больше 100
    рублей.
- Из j - 1 купонов, если Вася поел за деньги и стоило это больше 100
    рублей.

*База*:

- `dp[0] = [0, inf, inf, ...]`

*Переход*:

- Идем по дню dp[i] по всем значениям j от 0 до максимума.
- Выбираем в dp[i][j] минимальное значение из ячеек, соответствующих
    подходящим предыдущим состояниям в зав-ти от цены обеда в этот день.

В конце среди минимальных значений последнего дня выбираем тот, что
имеет большее j - большее число купонов.
________________________________________________________________________

> **Задача 5**. Васе нужно как можно дешевле купить не меньше N
кирпичей. в городе есть K магазинов, и для каждого из них известно:
розничная цена кирпича; число кирпичей для классификации покупки как
оптовой; оптовая цена кирпича; сколько всего кирпичей в магазине.

**Решение**:

Предварительно заведем ф-цию f, которая для k-ого магазина считает
стоимость n кирпичей, где k и n передаются в ф-цию. Возвращает inf, если
такого кол-ва кирпичей в магазине нет.

Заводим таблицу dp[i][j], где j - число кирпичей, i - магазины (в
скольких первых магазинах мы покупаем j кирпичей оптимальным образом
(где оптимальность подразумевает возм-ть купить в некоторых из них 0
кирпичей)). Тогда dp[i][j] есть минимальная сумма, которая понадобится
для покупки j кирпичей в i первых магазинов.

*База*:

- `dp[1] = [f(1, j) for j in range(0, N + 1)]`

*Переход*:

- `dp[i][j] = min([f(i, b) + dp[i - 1][b] for b in range(j + 1)])` -
    выбор минимального способа выбрать j - b кирпичей в первых i - 1
    магазинах и b кирпичей в i-ом перебором b от 0 до j и выбором
    минимума среди всех этих значений.

Выбор ответа есть выбор минимума в dp[K][N:], т.е. в dp[K] для числа
кирпичей, не меньше N, т.к. за счет разницы между розничной и оптовой
ценой может быть дешевле купить больше (и даже значительно больше, в
разы больше, порядка от N до N + максимальное число среди всех хар-к
магазинов, отвечающих за число кирпичей, необх. для оптовой закупки
вместо розничной) кирпичей, чем необходимо.
________________________________________________________________________

Теперь рассмотрим динамику по подстрокам (подотрезкам). Подстрока -
набор подряд идущих символов с L по R (отрезок).
________________________________________________________________________

> **Задача 6**. Дана строка из круглых, квадратных и фигурных скобок.
Удалить наименьшее кол-во скобок, чтобы строка стала правильной
скобочной пос-тью.

**Решение**:

Выписываем в тайтлы строк и столбцов строку посимвольно (или индексируем
столбцы и строки соответствующе). dp[L][R] - минимальное число скобок в
подстроке с L до R включительно, которое надо удалить, чтобы получить
правильную скобочную пос-ть.

*База*:

- На диагонали все 1 (`dp[L][R] = 1` для всех L = R).
- Ниже диагонали 0, т.к. по сути тогда отвечают за подстроки, где левая
    граница правее правой, т.е. подстроки длиной 0.

*Переход*:

- Если на L - открывающая скобка одного вида, на R - закрывающая скобка
    того же вида, то `dp[L][R] = dp[L + 1][R - 1]`. Тут возможна
    ситуация, когда L + 1 > R - 1, но они как раз покрываются
    заполнением нулями значений ниже диагонали.

- После этого смотрим все разбиения отрезка [L, R] и ищем минимум среди
    соответствующих сумм dp. Это работает, т.к. любая правильная
    скобочная пос-ть есть либо пустое мн-во, либо две подряд идущие
    правильные скобочные пос-ти, либо скобочная пос-ть внутри открытой и
    закрытой скобок одного типа в правильном порядке. По сути говоря
    предыдущей проверкой мы проверили один тип правильной скобочной
    пос-ти, а поиском минимума проверим другой тип. Запись:

    `dp[L][R] = min([dp[L][i] + dp[i + 1][R] for i in range(L, R)])`

- Если первая проверка была правдива, то выбираем минимум из результата
    после действий первой проверки и второго действия. Несмотря на то,
    что вроде как бы это 2 случая проверки на правильную скобочную
    пос-ть, есть контрпримеры, которые требуют в итоге проверки на оба
    случая и выделения минимума среди них, например, `()()`. Если
    выделять отдельно случаи, то ответ будет равен 2, что неверно, т.к.
    ответ 0. А с проверкой на оба выяснится, что ответ 0.

- Отдельно важно упомянуть, что проходка не по строкам или столбцам, а
    по диагоналям, начиная от главной.
________________________________________________________________________

> **Задача 7**. Упаковка символов вида более модернизированного RLE
сжатия. Дана строка латинских букв. Одинаковые подстроки, идущие подряд,
можно упаковать (в том числе упакованные). Упаковать в наименьшее кол-во
символов.

> **ПРИМЕР:** Для понимания синтаксиса результата сжатия: \
`AAAAAAAAAABABABCCD -> 10(A)2(BA)B2(C)D` \
`NEERCYESYESYESNEERCYESYESYES -> 2(NEERC3(YES))` \
Как видно из элементов примера, это не самое оптимальное сжатие, но для
общего синтаксиса показано так. В решении будет оптимальнее.

**Решение**:

dp[L][R] - число символов в оптимальной упаковке символов с L по R.
На главной диагонали 1, под ней - 0.

dp[L][R] заполняется выбором минимума среди:

1. Пробежки посимвольно с разбиением на 2 части и суммой минимального
    числа символов в разбиении левой и правой части.
2. Пробежки по делителям числа R - L + 1 и сравнение разбиения подстроки
    на таковое число подстрок с целью выделения таких случаев, как в
    примере YESYESYES -> 3(YES).
________________________________________________________________________

### ЖАДНЫЙ АЛГОРИТМ ###
<a id="anchor_greedy"></a>

*Жадный алгоритм* - действуем наилучшим образом на данный момент, не
задумываясь о будущем.

Может быть лучшим решением в задачах оптимизации, максимализации или
минимизации. Прост по своей концепции. Если он не подходит - чаще всего
довольно просто придумать контрпример и доказать, что он здесь не
приводит к минимуму или максимуму. Но если подходит - чаще всего
довольно сложно доказать, что он и вправду корректен, приходится
обращаться к сложным мат.выкладкам.
________________________________________________________________________

> **Задача 1**. Известна стоимость проезда одного км для N такси и
сколько ехать N людям. Рассадить людей по такси так, чтобы общая сумма
была наименьшей.

**Решение**:

Людям, которым ехать больше, лучше тратить меньше за км. Поэтому
отсортируем людей по возрастанию, а такси - по убыванию, это и будет
ответ.

Проблема именно в док-ве, что алгоритм и вправду справляется. Лектор в
Тренировках 7.0 приводит док-во, приведу его для примера образа мышления
при док-ве, в дальнейших задачах док-ва приводить не буду.

Допустим, мы нашли более оптимальную расстановку для такси (массив людей
для удобства оставим отсортированным по возрастанию расстояния). Найдем
первого ч-ка, для которого такси отличается от решения "жадиной" X.
Пусть в "жадине" ему приставлено такси с P руб./км, а теперь приставлено
с Q руб./км. P не может быть меньше Q, т.к. по условиям это первое
различие, а значит большие значения стоимости уже отобраны ранее.
Тогда P > Q. Кроме того, P перешло какому-то ч-ку Y, который заведомо
правее X, т.к. Y > X.

Для новой расстановки сумма затраченных денег для этих двух людей:
`X * Q + Y * P`. При этом `P > Q, Y > X`. Тогда эта сумма не минимальна,
т.к. `X * P + Y * Q` меньше. Тогда новое решение не оптимально, т.е.
неправильное.
________________________________________________________________________

> **Задача 2**. У каждого участника соревнований есть число,
обозначающее скилл. Есть 2 типа бонусов: P, увеличивающий скилл на
процент (массив); и A, увеличивающий скилл на число (массив).
Распределить бонусы так, чтобы суммарный скилл был максимальный.

**Решение**:

Сортируем по убыванию скилла S, а также по убыванию P и A. Применим все
P, которые есть и помещаются к S (больший к большему). Если в S остались
люди без бонуса, применим столько, сколько вместистся, бонусов A. Если
все P и A закончились, то хорошо. Если имеются бонусы A, то максимальный
из оставшихся бонусов сравним с минимально примененным P бонусом, и
если прирост от P меньше, чем от A, то заменим на A. Так до тех пор,
пока прирост от P не станет вновь больше очередного бонуса A. Это и есть
ответ.

Можно оптимизировать в коде этот процесс, но суть алгоритма такова.
________________________________________________________________________

> **Задача 3**. Есть N сломанных агрегатов. Слесарь Вася может починить
i-ый агрегат за a[i] времени, после чего агрегат будет работать b[i]
время и снова сломается. Определить, можно ли сделать так, чтобы все
агрегаты работали одновременно.

**Решение**:

Переставить по убыванию суммы a и b. Если так получится - тогда можно.
Если нет - тогда нельзя.

Решения через сортировку чисто по a или b имеют контрпримеры (где равны
a или b соответственно и сильно разные вторые параметры, там в зав-ти
от расстановки внутри равенства сортируемого пар-ра может быть разный
ответ).
________________________________________________________________________

> **Задача 4**. Песок в рюкзаке (переходная к задаче о рюкзаке). Есть
рюкзак грузоподъемностью S. В наличии есть N типов песка, каждый из
которых описывается W[i] весом и C[i] ценностью за ед.массы. Надо
заполнить рюкзак так, чтобы ценность была максимальной.

**Решение**:

По убыванию ценности за ед.массы и заполнять, пока не закончится место.

Песок делим, поэтому можно брать не весь песок одной ценности, в отличие
от задачи о рюкзаке.
________________________________________________________________________

### <u> Задача о рюкзаке </u> ###
<a id="anchor_greedy_backpack"></a>

Стоит несколько особняком от "жадины", т.к. иной подход, образ мышления
и области применения ("рюкзак" работает только для дискретных значений),
но тем не менее есть общие черты. Подход, используемый в "рюкзаке",
проще всего описать на классической задаче о рюкзаке, представленной
далее.

В общем случае задача относится к NP-задачам - задачам, которые не имеют
полиноминального решения и решаются чистым перебором. В частных же
случаях имеет место быть оптимизация.
________________________________________________________________________

> **Задача 1**. Есть рюкзак грузоподъемностью S и набор предметов с
весами W[i]. Можно ли заполнить рюкзак ими полностью?

**Решение**:

Создадим список булей длиной S + 1, в 0 ставим True, в остальные -
False. Он олицетворяет, какой вес мы можем собрать из предметов. Для
каждого предмета пробегаем список булей справа налево, и каждый раз,
когда для i-ого предмета встречаем True на j-ом месте, по индексу
j + W[i] ставим True. Ответ будет по индексу S.

> **ЗАМЕТКА!** Справа налево пробегаем, чтобы не научиться собирать
что-то несколькими экземплярами одного предмета. Если так можно и
предметов каждого веса безграничное кол-во, тогда пробегаем слева
направо.

> **ЗАМЕТКА!** Можно оптимизировать, идя не с самого конца, а с S - W[i]
эл-та в списке булей, чтобы не обрабатывать случаи переполнения рюкзака.

Если нужно восстановить ответ, то вместо списка булей создать список
целых, где в 0 - число 0, а в остальных - -1. Пробегаея справа налево,
если встретили не -1, запишем в j + W[i] число i, если в j + W[i] не -1.
Т.е. сохраняем не тот факт, что можем собрать такой вес, а первый
предмет, с помощью которого мы можем туда попасть.

При окончании работы можем по содержимому обратно восстановить ответ,
идя с конца в начало. Если в на j-ом весе написан предмет i, то
предыдущий предмет записан в j - W[i] ячейке списка весов, и так до
индекса 0.
________________________________________________________________________

> **Задача 2**. Есть рюкзак грузоподъемностью S и набор предметов с
весами W[i] и стоимостями за предмет C[i]. Какую максимальную суммарную
стоимость могут иметь предметы в рюкзаке?

**Решение**:

Логика решения аналогична Задаче 1 с восстановлением ответа, но теперь
будем сохранять максимальную суммарную стоимость в ячейке, а не первый
предмет, с помощью которого можно такой вес получить. Затем ищем
максимум по всему списку.

> **ЗАМЕТКА!** Решение через удельную стоимость не покатит, как в Задаче
4 про рюкзак с песком в Жадном алгоритме. На это есть контрпример:
S = 10, предметы (6, 9), (5, 5), (5, 5).

Если нужно восстановить, придется уже составлять матрицу, где по
горизонтали все те же веса от 0 до S включительно, а по вертикали номера
предметов от 0 (чтобы отметить 0 как начальное) до последнего. На каждом
шаге по предметам сначала копируется строчка выше, затем заполняются
ячейки максимумом суммы и номером предмета, с помощью которого он
получен.

Когда восстанавливаем, идем с последней строки матрицы, ищем там
максимум по сумме, видим, что получили его с помощью i-ого предмета на
весе j, восстанавливаем ответ в (i - 1)-ой строке, предыдущий предмет
записан в j - W[i] ячейке, и так до верхней строки.
________________________________________________________________________

> **Задача 3**. У покупателя есть набор монеток B[1] ... B[N], у
продавца - S[1] ... S[M]. Определите, может ли покупатель купить товар
стоимостью ровно X и, при необх-ти, получить сдачу.

**Решение (неоптимальное)**:

2 рюкзака - для покупателя и продавца. Потом, если у покупателя и
продавца есть конфигурация монеток для i и i - X соответсвенно, то
можно. Но, как видно, долговато получается, особенно если рюкзаки
большие, придется много перебирать в конце.

**Решение**:

Построим условный список булей длиной sum(S) + sum(B) + 1 с
отрицательными индексами до sum(S) и положительными до sum(B). Заполним,
сколько можем получить монетками покупателя, заполняя справа налево. Для
продавца же заполним слева направо, отнимая из имеющихся позиций. Т.о.
мы как бы вводим отрицательную стоимость монетки, реализуя сдачу от
продавца. Если в индексе X True - можем купить.

> **ЗАМЕТКА!** Считать сугубо в плюсе или до X не получится, есть
контрпримеры.

> **ЗАМЕТКА!** Запомнить идею предметов отрицательного веса.
________________________________________________________________________

### БИТОВЫЕ ОПЕРАЦИИ ###
<a id="anchor_bitop"></a>

Битовые операции как алгоритмическая тема позволяет ускорить работу кода
или привести к меньшей пространственной сложности там, где это
необходимо. Используется в ряде специальных алгоритмов (см. Специальные
алгоритмы -> Исправляющие коды Хэмминга, алгоритм Лэмпела-Зива-Велча, а
также Префиксные структуры -> дерево Фенвика как тренировку
использования битовых операций в алгоритмической стезе).
________________________________________________________________________

Битовые операции в Python:

- `a & b` - побитовое AND.
- `a | b` - OR.
- `a ^ b` - XOR.
- `~a` - NOT - переворачивает биты, превращая a в -a - 1.
- `a << n` - сдвиг влево на n.
- `a >> n` - сдвиг вправо на n.

Для ограниченных типов данных из C: библиотека `ctypes`.
________________________________________________________________________

Мн-во можно реализовать с помощью массива булевых элементов длиной
N + 1, и если новое число, меньшее N + 1, попадает в мн-во, мы отмечаем
булеан на соответствующем индексе как True, а при удалении - как False.

Такая реализация быстрее стандартного мн-ва, но есть ограничение.

И есть проблема: каждый булеан занимает целый байт, хотя ему достаточно
одного бита. Такое мн-во можно сжать, храня не булеаны, а целочисленные
переменные, и используя в них каждый бит. Для этого берем массив из
`ceil(N / 32)` эл-тов типа int32 и на нем реализуем следующие операции:

- Определение i и k - номера эл-та в массиве и номер бита в нуль
    нумерации соответственно.

    `i = num // 32`, или `i = num >> 5`, что быстрее.

    `k = num % 32`, или `k = (num << 27) >> 27`, что быстрее, но
    работает только на int32.

- *Добавление* эл-та в мн-во: присвоение битовыми операциями значения 1
    соответствующему биту в соответствующем числе. Пусть число лежит в
    мн-ве под идексом i, а нужный бит в нем k. Тогда добавление есть:
    
    `set[i] |= 1 << k`

    1 << k дает число, в битовом представлении состоящее из 0, кроме
    k-ого бита в нуль-нумерации.

- *Удаление* эл-та из мн-ва: присвоение битовыми операциями значения 0
    соответствующему биту в соответствующем числе. Пусть число лежит в
    мн-ве под идексом i, а нужный бит в нем k. Тогда удаление есть:

    `set[i] &= ~(1 << k)`

-  *Проверка наличия* числа в мн-ве: посмотреть на k-ый бит в i-ом
    числе. Должно возвращать True/False. Тогда:

    `set[i] & (1 << k) != 0`

> **ВАЖНО!** Помнить, что нумерация чисел в массиве идет слева направо,
но внутри числа нумерация битов идет справа налево.

Эта структура данных называется *bitset*.
________________________________________________________________________

### ХЕШИ ДЛЯ СТРОК ###
<a id="anchor_strhash"></a>

### <u> Сравнение полиномов </u> ###
<a id="anchor_strhash_poly"></a>

Сравнение полиномов - сравнение всех соответствующих коэффициентов двух
полиномов, и они считаются равными, если `a[i] == b[i]` для всех i от 0
до N - 1, где a, b - наборы коэффициентов первого, второго полинома
соответственно, N - длина обоих наборов (если длина у наборов разная, то
и полиномы разные).

Но покоэффициентно сравнивать два полинома - это долго, O(N). Тогда
можно решить данную проблему следующим образом: подставить конкретное
x в полиномы и получить ответ. Если ответы разные - полиномы разные.
Если ответы одинаковые - полиномы с высокой вер-тью также одинаковые.

Одинаковость в методе подстановки x не гарантирована, т.к. можно было
попасть в такой x, что оба полинома, пускай и разных, дают один ответ -
т.е. происходит коллизия. Таких x может быть не более, чем высшая
степень полинома (назовем это число K). Т.о., чтобы гарантировать
верность сравнения, надо посчитать полиномы для K + 1 разных x.

> **ВАЖНО!** x не должен равняться 0. Также плохими значениями являются
1 и -1.

В чистом виде такой подсчет на самом деле много медленнее попарного
сравнения коэффициентов, если считать для K + 1 разных x. Но в случае,
когда нас устраивает, что метод будет иногда давать ложно-положительные
срабатывания (например, когда полином огромный и вер-ть совпадения
крайне мала), то подсчет для одного удачного x позволяет в некоторых
случаях сравнивать полиномы немного быстрее попарного подхода. Но на
самом деле незначительно быстрее, а часто - даже медленнее.

Кроме того, можно считать не сразу для K + 1 разных значений x, а для
небольшого кол-ва, если точность срабатывания требуется повыше, но это
уже медленнее попарного подхода.

Т.о. для сравнения двух полиномов этот подход мало того, что не быстрее,
так еще и можно допустить ложно-положительное срабатывание. Тем не
менее, у этого подхода есть применение, описанное далее, а также он
является подводкой к основной теме - хеши для строк.
________________________________________________________________________

Есть еще подводные камни в получении данных результатов вычислений
полинома.

1. Во-первых, возведение x в степень, особенно в большую - дело крайне
    затратное по времени. Чтобы этого избежать, можно считать
    итерационно. Например,
    `ax**3 + bx**2 + cx + d = ((ax + b)x + c)x + d`, т.е. можно
    посчитать сначала `res = a * x + b`, потом `res = res * x + c`, а
    затем `res = res * x + d`. Решение за O(N).

2. Во-вторых, может быть переполнение в одних языках и длинная
    арифметика в других. Решается тем, что на каждом этапе из п.1 будем
    производить поиск остатка от деления на некоторое p. Т.е. не
    `res = a * x + b`, а `res = (a * x + b) % p`. Т.о. получается
    своеобразное хеширование поиском остатка от деления (см. Множества в
    случае возникновения трудностей с пониманием данного аспекта), или
    из математики - *кольцо вычетов по модулю*.

    Тут можно уже привести и код.

    ```python
    res = 0
    for i in range(n):
        res = (res * x + a[i]) % p
    ```

    > **ВАЖНО!** Хеширование производить именно что в итерациях, а не
    после честного подсчета всего полинома, т.к., очевидно, переполнение
    и длинная арифметика могут наступить раньше, чем в конце подсчета.

    > **ВАЖНО!** Счет по модулю сохраняет легитимность дальнейшего
    сложения, вычитания и умножения, но не сохраняет легитимности
    деления, т.к. результат деления хешей не отображает реального
    остатка от деления на p отношения чисел, которые этими хешами
    представлены.

3. В-третьих, используя п.2, понимаем, что вер-ть коллизии становится
    еще выше, и чтобы ее минимизировать в данных условиях, важно
    правильно подбирать x и p.
    
    Например, x и p следует делать взаимно простыми.

    x важно брать не слишком большим для ускорения расчетов, но не
    слишком маленьким, чтобы минимизировать шанс коллизии. Хорошим
    ориентиром будет ближайшее простое число, большее длины алфавита,
    или и вовсе длина алфавита + 1. Например, для ASCII это 257.

    p стоит брать достаточно большим, чтобы минимизировать шанс
    коллизии, но так, чтобы это все еще не вызвало проблем с
    переполнением или длинной арифметикой (не более, чем максимальное
    число в данном типе данных // 2). Хороший пример для int64 (и для
    Python до наступления длинной арифметики): p = 10\*\*9 + 7.

    Для отладки может быть хорошо не использовать p вовсе, а x взять
    равным 10.
________________________________________________________________________

Используя информацию из предыдущего подблока, можно раскрыть этот подход
с его сильной стороны. А именно сравнение не двух, а нескольких
полиномов.

> **Задача 0.1**. Пусть дано K полиномов степени N и надо для каждого
ответить, сколько у него совпадающих полиномов среди этих K штук.

**Решение 0**:

Попарное сравнение коэффициентов полиномов, что даст сложность
O(N \* K\*\*2).

**Решение 1**:

Подсчитываем значение полиномов для x. Затем с помощью словаря набираем
кол-ва тех или иных значений полиномов и раскидываем ответ по полиномам,
соотнося ключ словаря и полученное значение полинома при подстановке x.
Получаем сложность O(NK). Но помним про коллизии и переполнение или
длинную арифметику.

**Решение 2**:

Решение 1, но с применением вычета по модулю. Тогда действительно
сложность будет O(NK), а помнить надо сугубо про коллизии.
________________________________________________________________________

### <u> Сравнение строк и подстрок </u> ###
<a id="anchor_strhash_str"></a>

Возьмем ту же Задачу 0.1, но для строк.

> **Задача 0.2**. Пусть дано K строк длины N и надо для каждой ответить,
сколько у нее совпадающих строк среди этих K штук.

**Решение**:

Идея решения та же, только теперь вместо коэффициентов полинома - коды
символов в ASCII или UTF-8, или номер символа в алфавите или словаре.
________________________________________________________________________

Такая комбинация сравнение полиномов по хешу и использование кодов
символов и подводят к хешам для строк.

Данная тема прежде всего интересна сравнением подстрок, т.к. такое
действие при правильном предподсчете некоторого списка хешей за O(N)
может позволить сравнивать подстроки за O(1).
________________________________________________________________________

Представим строку в виде полинома. Тогда совпадающие подстроки - это
совпадающие подряд идущие коэффициенты.

Подсчитаем хеши для префиксов - т.е. h[i] есть хеш для подстроки длиной
i. Например:

```
Строка: abacababa. Смотрим по номеру символа в алфавите. Также обозначим
x**i как xi для удобства чтения.

Полином: 1*x8 + 2*x7 + 1*x6 + 3*x5 + 1*x4 + 2*x3 + 1*x2 + 2*x1 + 1

Тогда хеши: h = [0,
                 1,
                 1*x1 + 2,
                 1*x2 + 2*x1 + 1
                 1*x3 + 2*x2 + 1*x1 + 3,
                 ...]
```

Выше показана просто схема, в то время как на самом деле хеши считаются
итерационно и по модулю p, чтобы учесть переполнение и считать за O(N).
Т.е. `h[i] = (h[i - 1] * x + a[i]) % p`, где a - массив кодов символов
изначальной строки.

Теперь подстроку характеризует тот хеш, который свободным членом
полинома имеет последнюю букву подстроки. Но также он содержит и члены
полинома, которые относятся ко всем символам, идущим до этой подстроки.
Для вытаскивания чистого хеша подстроки можно заметить, что если L -
длина подстроки, H - искомый хеш подстроки, а i - номер хеша в списке
хешей, то `h[i] = H + h[i - L] * x**L`. Или:
`H = h[i] - h[i - L] * x**L`.

```
Продолжная пример выше, хотим достать в abac[aba]ba выделенную
подстроку. Начинается она на позиции 5 в единица-нумерации и
заканчивается на позиции 7, имея длину 3. Тогда она описывается хешом:

h[7] = 1*x6 + 2*x5 + 1*x4 + 3*x3 + 1*x2 + 2*x1 + 1

Также подпишем хеш номер 7 - 3 = 4:

h[4] = 1*x3 + 2*x2 + 1*x1 + 3

Тогда заметим:

h[7] = H + h[4] * x3, или H = h[7] - h[4] * x3
```

Тут всплывают некоторые нюансы.

1. Это действие надо считать по модулю p, не забывая про переполнение.
    Т.о. прафильная формула: `H = (h[i] - h[i - L] * x**L) % p`.
2. Тут может возникнуть проблема с отрицательной разницей, но модуль p
    самостоятельно решает проблему в таких ситуациях. Но тем не менее,
    это не всегда есть хорошо. Исправление такой ситуации возможно
    при сравнении двух хешей, см. далее.
3. Самая большая проблема - это x\*\*L. Считать честно такую вещь не
    стоит, т.к. это долго. Решение - итерационный предподсчет списка
    степеней x в некоторый список: `powx[0] = 1` и
    `powx[i] = (powx[i - 1] * x) % p`. Итого в предварительные действия
    добавляется предподсчет за O(N), что не ухудшает асимптотику.

Но с учетом этих нюансов, вырезая 2 подстроки, можно сравнивать их между
собой за O(1).
________________________________________________________________________

Исправление вычитания при сравнении исходит из следующей логики:

Пусть сравниваем `Hi = (h[i] - h[i - L] * x**L) % p` и
`Hj = (h[j] - h[j - L] * x**L) % p`. Вообще говоря, мы должны ответить
на вопрос, равны они или нет, т.е. проверить `Hi == Hj`. Если равенство
выполнятеся, то из простой математики:

```
Hi == Hj

(h[i] - h[i - L] * x**L) % p == (h[j] - h[j - L] * x**L) % p

(h[i] + h[j - L] * x**L) % p == (h[j] + h[i - L] * x**L) % p
```

Т.о. можно сравнивать не Hi и Hj, а немного "перемешанные" хеши, что
позволит избежать вычитания и ситуации отрицательных модулей.
________________________________________________________________________

Но в итоге, после всех этих размышлений и матвыкладок, получается
довольно небольшой и приятный код:

```python
L = len(s)
p, x = 10**9 + 7, 257
h, powsofx = [0] * (L + 1), [0] * (L + 1)
powsofx[0] = 1
s = ' ' + s
for i in range(1, L + 1):
    h[i] = (h[i - 1] * x + ord(s[i])) % p
    powsofx[i] = (powsofx[i - 1] * x) % p

def isequal(i, j, slen):
    return (h[i] + h[j - slen] * powsofx[slen]) % p == \
            (h[j] + h[i - slen] * powsofx[slen]) % p
```

Или, представляя ф-цию isequal через индекс первых символов подстрок:

```python
def isequal(from1, from2, slen):
    return (h[from1 + slen - 1] + h[from2 - 1] * powsofx[slen]) % p == \
            (h[from2 + slen - 1] + h[from1 - 1] * powsofx[slen]) % p
```
________________________________________________________________________

### <u> Задачи </u> ###
<a id="anchor_strhash_tasks"></a>

> **Задача 1**. Задана строка длины N и подстрока длины K. Найти все
вхождения подстроки в строку.

**Решение**:

Считаем хеши префиксов за O(N). Считаем хеш подстроки за O(K).
Перебираем все подстроки длиной K (N - K штук) и сравниваем хеши. Итого
сложность O(N + K).

По необходимости для уменьшения шанса коллизии считать по нескольким
разным x и p.
________________________________________________________________________

> **Задача 2**. Задана строка S. Найти минимальную строку, для которой
при бесконечном ее повторении префикс будет равен S.

> **ПРИМЕР**: S = abaabaab, тогда искомая строка aba, т.к. при
бесконечном ее повторении (abaabaabaabaaba...) префикс как раз будет
abaabaab. Меньше при этом не получится.

**Решение 0**:

Можно было бы считать и сравнивать хеши для подстрок длины 1, 2, 3 и
т.д., но сложность тогда O(N + (N - 1) + (N - 2) + ...) = O(N\*\*2) по
сумме арифметической прогрессии.

**Решение 1**:

Будем искать максимальные по длине совпадающие суффикс и префикс. Тогда
если N - длина строки S, а L - максимальная длина совпадающих суффикса и
префикса, то искомая минимальная строка для ее бесконечного повторения
будет первые N - L эл-тов строки S. Итоговая сложность: O(N).

Это работает, т.к. если строка S представляет собой префикс некоторой
строки из бесконечного повторения строки S2, то через len(S2) элементы
будут повторяться. При этом суффикс начинается ровно через N - L после
префикса, и т.о. при совпадении суффикса и префикса получаем, что через
N - L все символы повторяются, и ответ len(S2) = N - L, а сама строка -
первые len(S2) символов.

Пример:

```
Правильные суффикс и префикс:

S = abaabaab
    abaab
       abaab

Получается, что через N - L = 3 буквы полностью повторяются, и тогда
ответ - первые 3 буквы (aba).

Неправильные суффикс и префикс:

S = abaabaab
    abaaba
      aabaab

Получается, что через N - L = 2 буквы не повторяются, и поэтому искомая
строка не ab.
```
________________________________________________________________________

> **Задача 3**. Дана строка S и какое-то кол-во запросов вида (f1, f2),
где f1 и f2 - индексы, с которых начинаются суффиксы. Определить, какой
из них лексикографически меньше.

> **ПРИМЕР**: S = abacababa, запрос (2, 4). Ответ: второй, т.к. acababa
больше, чем ababa, по второму символу.

**Решение**:

Сравнение хешей не дают информации о сравнении строк. Поэтому используем
бинарный поиск для нахождения самого длинного совпадающего префикса у
рассматриваемых суффиксов, и следующий после такого префикса символ и
определяет лексикографический порядок суффиксов.
________________________________________________________________________

### ПЕРЕБОР ###
<a id="anchor_enum"></a>

Ряд задач не решается обычными способами за полиномиальное время, и
тогда не грех решить задачи с помощью полного перебора, пускай это и
будет неэффективно по времени. Кроме того, пребор используется для
тестирования при проверки верности алгоритма на разных наборах данных -
так называемое брутфорсовое решение.
________________________________________________________________________

### <u> Поиск с возвратом (backtracking) </u> ###
<a id="anchor_enum_backtracking"></a>

Алгоритм backtracking (возврат к исходным данным) — это метод решения
задачи перебора всех возможных вариантов с последующим выбором
оптимального решения. Данный подход широко применяется в области
разработки программного обеспечения, особенно в решении задач
комбинаторной оптимизации, где требуется найти наилучшее решение из
множества возможных комбинаций.

Одним из наиболее известных применений алгоритма backtracking является
задача о расстановке ферзей на шахматной доске так, чтобы они не били
друг друга, или другой завади - задачи коммивояжера (см. следующий
подраздел). Другие примеры включают задачи о путешествии волновго
алгоритма, о поиске пути в графе и о комбинаторной оптимизации.

Идея:

1. Выбор подходящего элемента или состояния, чтобы продолжить решение
    задачи.
2. Проверка, где текущий выбранный элемент или состояние проверяется на
    соответствие критериям или ограничениям задачи
    - Если проверка проходит, то на данном этапе см. п.1.
    - Если нет - возврат False и возвращение к выбору эл-та на
        предыдущем этапе - откат.
3. Если на этом этапе все дочерние эл-ты проверены и вернули False -
    откатиться еще выше.
4. Алгоритм заканчивается, если конечный эл-т прошел проверку или если
    все не прошло проверку.
________________________________________________________________________

### <u> Методы оптимизации перебора </u> ###
<a id="anchor_enum_optimization"></a>

Данная тема навряд ли будет полезна для прохождения собеседования, но
при этом может предоставить новые пути размышлений и станет полезна в
целом.

Здесь оговариваются задачи, которые невозможно решить за полиномиальную
сложность, и методы их оптимизации. Но такие методы применимы и на
практике в случаях, когда полиномиальное решение существует, но мы его
не придумали и в моменте пытаемся ускорить менее эффективное решение.

Кроме того, важно понимать, что в контексте перебора за неполиномиальное
время N будет порядка десятков, и в таком ключе уже становится важна
константа, т.к. O(1) может сравниться и даже стать хуже O(N). Поэтому
каждая оптимизация должна быть проверена более внимательно,
действительно ли оптимизация оптимизирует. Также это ведет к тому, что
подобные задачи для больших N неразрешимы в адекватные временные рамки
на данный момент, и поэтому для больших N приходится придумывать
полиномиальные или еще более быстрые решения, но допускающие ошибку.
Например, см. тему Хеши для строк.
________________________________________________________________________

> **Задача 1**. Посчитать все перестановки N ферзей на поле N x N, при
которых ферзи не бьют друг друга.

**Решение 1**:

Перебрать каждую ячейку поля через рекурсивную ф-цию, в которой
вызывается она же для следующей ячейки в состоянии, когда в текущую был
поставлен ферзь и для состояния, когда в текущую ферзь поставлен не был.
Не углубляться в рекурсию далее, если ячейка последняя. Если углубления
не происходит, проверяем случай на то, бьют ли попарно ферзи друг друга
или нет. Возвращает 1 или 0, а выше по рекурсии суммируется.

Скорость: O(N\*\*2 \* 2\*\*(N\*\*2)).

Это крайне медленно. Например, поле 8 на 8 обсчитывалось бы за
~ 10\*\*21 операций.

**Решение 2**:

Улучшаем Решение 1. Суть улучшений - как можно раньше обрубить ветвь
дерева рекурсивных вызовов без потери в точности ответа.

1. Отслеживаем кол-во оставшихся ферзей. Если счетчик стал равен 0 -
    не углубляемся в рекурсию.
2. Таскаем уже занятые столбцы, строки и диагонали и при обращении
    рекурсии в них возвращаемся выше по рекурсии.

Итого решение за O(N!).

Пример моего быстро написанного кода с красивым выводом в txt-файлы в
папке _test_results:

```python
from dataclasses import dataclass
from functools import partial

EMPTY, FILLED = '⬜', '⬛'
cached_poses = []

N = int(input())
FILE_NAME = f'_test_results/{N}.txt'

@dataclass
class FilledParts:
    rows: set
    cols: set
    dmain: set
    dsub: set

    def copy(self):
        return FilledParts(rows=self.rows.copy(),
                           cols=self.cols.copy(),
                           dmain=self.dmain.copy(),
                           dsub=self.dsub.copy())

def draw(poses, print_file):
    matrix = [[0] * N for _ in range(N)]
    for pos in poses:
        matrix[pos[0]][pos[1]] = 1
    print_file()
    print_file('*' * 30)
    print_file(poses, '\n')
    for line in matrix:
        print_file((''.join(map(str, line))).replace('0', EMPTY).replace('1', FILLED))
    print_file('*' * 30)

def rec(nowpos, count, poses: list, filled: FilledParts):
    if count == 0 or nowpos >= N**2:
        if len(poses) == N:
            cached_poses.append(poses)
        return 1
    else:
        a, b = nowpos % N, nowpos // N
        if a in filled.rows or b in filled.cols or \
                a + b in filled.dmain or a - b in filled.dsub:
            return rec(nowpos + 1, count, poses, filled)
        
        newfilled = filled.copy()
        newfilled.rows.add(a)
        newfilled.cols.add(b)
        newfilled.dmain.add(a + b)
        newfilled.dsub.add(a - b)
        return rec(nowpos + 1, count - 1, poses.copy() + [(a, b)], newfilled) + \
                rec(nowpos + 1, count, poses, filled)

def numofvars():
    return rec(0, N, [], FilledParts(set(), set(), set(), set()))

nvars = numofvars()
cnt = len(cached_poses)

with open(FILE_NAME, 'w', encoding='utf8') as f:
    print_file = partial(print, file=f)

    print_file(f'All variants: {nvars}')
    print_file(f'Variants with {N} figures: {cnt}')
    for item in cached_poses:
        draw(item, print_file)
```
________________________________________________________________________

> **Задача 2**. *Задача коммивояжера*, но в контексте нынешних реалий
назовем это задачей курьера. Есть курьер в начальной точке, есть ряд
мест, куда ему нужно доставить товары, и есть полный граф, описывающий
время в пути от каждой точки до каждой другой. Надо найти самый быстрый
маршрут, такой, чтобы доставить все товары и вернуться в начальную
точку.

**Решение 1**:

Из очевидного, алгоритм Дейкстры, как и DFS/BFS не подойдут. Чистый
жадный алгоритм также не подходит, т.к. есть контрпример при равных
расстояниях.

Самое банальное решение - перебрать все варианты маршрута, посчитать их
продолжительность и выбрать наименьший. Сложность - O(N!).

**Решение 2**:

Улучшим Решение 1.

1. Напишем рекурсию вместо отдельного подсчета времени маршрута всех
    вариантов. Тогда в случаях с одинаковым префиксом маршрута этот
    самый префикс не будет считаться несколько раз по раздельности, а
    посчитается единожды.
2. В рекурсии будем выявлять и вовне сохранять лучший вариант к текущему
    моменту. Тогда на каждом шаге рекурсии можно сравнивать уже
    насчитанную продолжительность маршрута на префиксе с лучшим
    результатом, и если префикс уже больше лучшего результата, то и весь
    маршрут будет больше => досчитывать эту ветвь дерева рекурсии не
    нужно.
3. К каждому узлу предварительно приписать длину самого маленького
    по длительности ребра из него. Тогда на каждом шаге рекурсии можно
    уже насчитанную продолжительность маршрута на префиксе + сумму
    минимальных ребер непосещенных узлов сравнивать с лучшим результатом
    по аналогии с п.2. Т.о. сравнивается не уже набранный путь, а
    предсказание минимально возможной длительности маршрута, оценка
    снизу оставшегося пути. Тогда обрубание веток дерева рекурсии будет
    происходить еще раньше.
4. Через жадный алгоритм предварительно определить первичный лучший
    путь. Тогда не будет глубоких погружений в рекурсию на первых (да и
    последующих) порах из-за еще не приближенного к ответу лучшего пути,
    что позволит еще сильнее срезать ветви рекурсии.

**Решение 3**:

Есть улучшение Решения 2 через динамическое программирование по
подмн-вам, направленное на отсеивание среди одинаковых подмн-в менее
хороших. Для больших подробностей см. Тренировки по алгоритмам 4.0 от
Яндекса, лекция 4.
________________________________________________________________________

### СПЕЦИАЛЬНЫЕ АЛГОРИТМЫ ###
<a id="anchor_specalgs"></a>

В этом разделе разговор пойдет про алгоритмы, направленные на какую-то
конкретную специальную задачу. Они не понадобятся на собеседовании почти
100%, но для общего интереса и общего пула задач и их возможных решений
можно рассмотреть.
________________________________________________________________________

### <u> Алгоритм Хаффмана </u> ###
<a id="anchor_specalgs_haffman"></a>

Алгоритм Хаффмана - жадный алгоритм оптимального префиксного кодирования
алфавита с минимальной избыточностью. Проще говоря, позволяет
сопоставить более часто встречающимся символам более короткий код,
причем вся кодировка букв должна быть такова, что по подряд записанным
кодам букв без разделителей можно было точно восстановить изначальное
сообщение.

Данный алгоритм интересен своей сериализацией с помощью бинарного
дерева. А именно:

1. Берем два самых редко встречающихся символа и объединяем их в один
    узел, самый дальний.
2. Строим бинарное дерево, кладем буквы в листья. Чем чаще встречается
    символ, тем ближе к корню он должен быть. Строится в итоге с конца в
    начало.
3. Переход в левого сына кодируем 0, а в правого - 1. Код символа - это
    все ребра на пути из корня до листа.

Например, пускай будет ключ кода "аааабббвг". Тогда дерево:

```
    0---None---1
    |          |
    а      0--None--1
           |        |
        0-None-1    б
        |      |
        в      г
```

> **ЗАМЕТКА!** Вместо None в построении используются веса для
продвижения, но для большей читабельности и наглядности сохранен такой
вид. На ребрах указаны 0 или 1 - биты кодирования.

В Python:

```python
[None,
    ['а', None, None],
    [None, 
        [None, 
            ['в', None, None],
            ['г', None, None]],
        ['б', None, None]]]
```

Тогда коды:

- а = 0
- б = 11
- в = 100
- г = 101
________________________________________________________________________

### <u> Исправляющие коды Хэмминга </u> ###
<a id="anchor_specalgs_hamming"></a>

Самая частая ошибка при передаче данных - инверсия какого-то кол-ва
битов. Рассмотрим инверсию одного бита.

Наивное решение - при передаче повторять трижды каждый бит, а при приеме
в каждой группе из 3 полученных находить наиболее часто встречающийся
эл-т - это и будет нужное значение бита. Проблема - длина увеличивается
втрое, что тянет за собой как проблемы со скоростью, так и с памятью.

Для этого существует более оптимальное решение в виде кодов Хэмминга.
________________________________________________________________________

Итоговое кол-во бит, которое нужно передать, составляет N + K + 1, где
N - начальное число бит, а K есть решение ур-я
`K = ceil(log(N + K + 1))` - из теории информации.

Далее резервируем место под двоичными номерами (в нумерации с единицы)
1, 10, 100 и т.д., их кол-во и будет K + 1. Обозначим, что i-ый эл-т
означает номер 2\*\*i. В остальные по очереди поместим значения битов
оригинальной пос-ти.

Для i-ого зарезервированного эл-та считаем сумму всех битов, номер
которых в i-ом бите (в нуль-нумерации) содержит 1, не считая сам
зарезервированный бит. В i-ый зарезервированный эл-т ставим 0 или 1 для
того, чтобы при добавлении в полученную сумму число получилось нечетным.

Пример:

```
Оригинал: 01010101
K = 4

До подсчета резервных эл-тов:
n     1  2  3  4  5  6  7  8  9 10 11 12
res   _  _  0  _  1  0  1  _  0  1  0  1

i = 0: 0 + 1 + 1 + 0 + 0 = 2; res = 1
    (эл-ты номерами: 3, 5, 7, 9, 11)
i = 1: 0 + 0 + 1 + 1 + 0 = 2; res = 1
    (эл-ты номерами: 3, 6, 7, 10, 11)
i = 2: 1 + 0 + 1 + 1 = 3; res = 0
    (эл-ты номерами: 5, 6, 7, 12)
i = 3: 0 + 1 + 0 + 1 = 2; res = 1
    (эл-ты номерами: 9, 10, 11, 12)

Итоговый передаваемый сигнал:

n     1  2  3  4  5  6  7  8  9 10 11 12
res   1  1  0  0  1  0  1  1  0  1  0  1
```

При расшифровке:

- Считаем для i-ого элемента (по аналогии с i при зашифровке) сумму
    эл-тов.
    - Если нечетная, то пропускаем.
    - Если четная, то среди чисел с 1 в i-ом бите произошла инверсия.
- В конце считаем результат: сумму 2\*\*j, где j - выделенные биты на
    прошлом шаге (лучше в битовом виде через ИЛИ). Полученное значение
    и есть номер бита с инверсией, либо 0, что сигнализирует об
    отсутствии ошибки.

Пример (прошлый сигнал, но с инверсией в 11-ом эл-те):

```
Получен сигнал:
n     1  2  3  4  5  6  7  8  9 10 11 12
res   1  1  0  0  1  0  1  1  0  1  1  1

i = 0: 1 + 0 + 1 + 1 + 0 + 1 = 4 - четный
    (эл-ты номерами: 1, 3, 5, 7, 9, 11)
i = 1: 1 + 0 + 0 + 1 + 1 + 1 = 4 - четный
    (эл-ты номерами: 2, 3, 6, 7, 10, 11)
i = 2: 0 + 1 + 0 + 1 + 1 = 3 - нечетный
    (эл-ты номерами: 4, 5, 6, 7, 12)
i = 3: 1 + 0 + 1 + 1 + 1 = 4 - четный
    (эл-ты номерами: 8, 9, 10, 11, 12)

Тогда четные получились в шаблонах:
0001, 0010, 1000

Сумма: 1011, что равно 11 в десятичной системе счисления.

Исправленный сигнал:
n     1  2  3  4  5  6  7  8  9 10 11 12
res   1  1  0  0  1  0  1  1  0  1  0  1
```
________________________________________________________________________

В чистом виде не работает, если может сломаться больше одного бита.
Решение - дробить информацию на маленькие отрезки, чтобы минимизировать
шанс 2 ошибок в одном отрезке + как-то обрабатывать ситуацию, когда
ошибки все-таки 2 и более в каких-то пакетах.
________________________________________________________________________

### <u> Алгоритм Лемпела-Зива-Велча </u> ###
<a id="anchor_specalgs_lzw"></a>

Этот алгоритм предназначен для сжатия данных. Например, zip-файлы
сжимаются алгоритмами из этого семейства (LZ).

Заполняем словарь (или бор) посимвольно из файла:

- Нулевой эл-т - пустая строка.
- Пусть на очередной раз мы накопили слово W и смотрим на символ K.
    - Если W + K есть в словаре: W = W + K, идем к следующему символу.
    - Если нет такого слова: добавляем W + K в словарь, W = '', слово
        W + K кодируем как номер слова W + добавленный символ K без
        пробелов.
    - Если конец файла: пишем номер слова W.

Пример: abacabacaabaac -> 0a0b1c1b3a4a1.

Распаковка также заполнением словаря обратными действиями поэлементно
слева направо.

Пример: 0a -> a, 0b -> b, 1c -> ac, и т.д.

В словаре: ключ - слово, значение - номер.
________________________________________________________________________

Для того, чтобы не переполнялось все большим кол-вом слов, производят
удаление по LRU.

Для этого словарь ограничивается по кол-ву слов, ведется массив (или
куча) для хранения и обновления времен использования, и при
заполненности словаря удаляется самый давно использованный эл-т. В
чистом виде это может привести к проблеме: если удалить слово, от
которого родились еще слова, то логика нарушится. Поэтому важно
отслеживать не все слова, а слова без дочерних слов.

Как вариант для решения этой проблемы - заполнять не словарь, а бор
(дерево, где ребра или вершины подписаны буквой).

Заполнение такого бора по принципу наследования, корень - пустой,
удаление сугубо листьев. По мере проходки по оригинальному тексту на
каждом новом символе шагаем в дочерний элемент с таким символом либо
создаем новый узел дерева, если такого символа нет, и убегаем в корень.

В узлах храним символ и номер слова.

Это эффективнее при проходке и удалении + проще отслеживать листья +
нагляднее.
________________________________________________________________________

Оптимизации:

- Хрань номер предыдущего слова минимальным кол-вом бит. Например, для
    маленьких чисел необязательно использовать int8, а ровно сколько
    нужно.

- Коды символов можно сжать с помощью кодирования Хаффмана (сериализация
    дерева Хаффмана - Яндекс Тренировки по алгоритмам 1.0, лекция 8).
________________________________________________________________________

Код Хаффмана:

Пусть встречались символы следующее число раз: A - 100, B - 20, C - 40,
D - 60.

Объединим самые редко встречающиеся в один узел с суммарным числом.
Тут это B, C, сумма - 60. Затем снова берем два наименьших узла (это
мб и образованный на предыдущем шаге) - и т.д. В итоге поход в левого
сына - 0, в правого - 1 (или наоборот), дошли до символа - получили его
код.

Гарантированно коды не пересекаются по префиксу.
________________________________________________________________________

### <u> Преобразование Барроуза-Уиллера </u> ###
<a id="anchor_specalgs_bwt"></a>

Данная тема относится к хешированию строк и архивации. Преобразование
Барроуза-Уиллера (BWT) сам по себе - преобразование строки особым
образом и сжатие ее с помощью RLE. В простом виде объяснено в
Тренировках по алгоритмам 4.0 от Яндекса, Лекция 2. В целом можно из
интереса почитать, т.к. BWT + MTF + Хаффман = Bzip2 - широко
используемый алгоритм архивации данных.
________________________________________________________________________

### <u> Алгоритм А\* </u> ###
<a id="anchor_specalgs_astar"></a>

Алгоритм А* ("А звезда", "А стар") используется для поиска кратчайшего
пути от одной начальной точки до одной конечной. Представляет собой
модификацию алгоритма Дейкстры, основанную на использовании идеи жадного
алгоритма, но в отличие от Дейкстры А\* не ищет кратчайшие пути до всех
точек, чем и ускоряет свою работу относительно прародителя. Широко
исп-ся в навигационных системах, робототехнике и разработке игр.

Основная идея алгоритма A\* - это определение двух значений для каждой
вершины в графе:

- g(n) - длина пути от начальной вершины до текущей вершины n.
- h(n) - эвристическая оценка длины от текущей вершины n до цели.

На каждом шаге алгоритм A* выбирает вершину с наименьшей суммой
`g(n) + h(n)` и исследует её соседей. Это продолжается до тех пор, пока
алгоритм не достигнет конечной цели.

**Статья на Хабре**:
[ссылка](https://habr.com/ru/articles/331192/).

**Более математическая статья + наглядная гифка**:
[ссылка](https://neerc.ifmo.ru/wiki/index.php?title=Алгоритм_A*&mobileaction=toggle_view_mobile).
________________________________________________________________________

### <u> Шум Перлина </u> ###
<a id="anchor_specalgs_perlin"></a>

Отдельно стоит почитать для личного интереса. Нужен в графике (генерация
дыма, огня, облаков и проч.) и геймдеве (генерация случайной карты, как,
например, в Minecraft). См. статью по ссылке для большей информации:

**Простая процедурная генерация мира, или Шумы Перлина на Python**:
[ссылка](https://habr.com/ru/companies/selectel/articles/731506/).
________________________________________________________________________

### <u> Метод Монте-Карло </u> ###
<a id="anchor_specalgs_montecarlo"></a>

*Метод Монте-Карло* - численный метод решения математических задач при
помощи моделирования случайных величин. В ряде специальностей является
незаменимым.

Рассмотрим на примере: моделирование источника частиц в виде
материальной точки и детектора в виде куба на расстоянии. Запуская
частицы в случайном направлении из источника и проверяя коллизию с
детектором, можно посчитать, сколько частиц попало в детектор. Метод, из
очевидного, не абсолютно точный, но позволяет получать оценки величин
или модельно-эмпирические значения, где это уместно.

Крупное из личного опыта - использование пакета Geant4 для моделирования
облучения защиты от радиоактивного излучения. Ценность такого подхода в
том, что защита имеет сложную геометрическую конфигурацию, что приводит
к упрощению расчетов по формулам или крайне сложным расчетам, в то время
как с помощью метода Монте-Карло это становится лишь вопросом времени на
моделирование.

В целом же используется много где для получения описанных выше величин.
В экономике (для оценки риска и неопределенности), в физике (для
моделирования сложных систем на атомном уровне), в инженерии (при
проектировании сложных систем и анализе их надежности).

Ради интереса или по необх-ти. См. интернет или следующие источники.

**Метод Монте-Карло**: [ссылка](https://thecode.media/monte-carlo/).

**Метод Монте-Карло и его точность**:
[ссылка](https://habr.com/ru/articles/274975/).
________________________________________________________________________

# СТРУКТУРЫ ДАННЫХ #
<a id="anchor_data_structures"></a>

### МНОЖЕСТВО (ХЕШ-ТАБЛИЦА) ###
<a id="anchor_set"></a>

*Множество* - математическая структура, содержащая в себе некоторое
число (\>\=0) элементов. *Мультимножество* - множество, куда один эл-т
может входить несколько раз.

Множество должно уметь:

- Добавлять эл-т.
- Находить эл-т/проверять наличие эл-та.
- Удалять эт-т.

В простейшем виде для алгоритмов означает следующий принцип:

1. Организовать ф-цию, сопоставляющую каждый элемент с малым числом.
    Эта ф-ция называется *хеш-функцией*.
2. Вычислить ф-цию от элемента.
3. Положить элемент в список с номером (индексом), равным значению
ф-ции. Список списков с элементами называется *хеш-таблицей*.

> **НО!** Появляется такое, когда одному номеру (результату функции)
соответсвует несколько начальных элементов. Т.е. множество есть список
списков, связанный с входными данными через хеш-функцию. Когда для
нескольких входных величин одинаково значение хеш-функции, то возникает
*коллизия*.

Действия:

- Добавление в хеш-таблицу: понятно.
- Проверка наличия элемента в хеш-таблице: вычислить хеш-функцию и
    поискать в этом списке.
- Получение всех элементов хеш-таблицы имеет сложность O(N + K).
- Удаление элемента из хеш-таблицы:
    - Как из обычного списка, если порядок важен, и тогда сложность есть
        O(N), где N - число элементов списка. Это происходит из-за
        поочередного копирования элементов из i + 1 в i, а затем
        удаления последнего элемента.
    - Заменой удаляемого элемента на последний элемент, а затем удаление
        последнего элемента. Тогда сложность O(1), но нарушается
        порядок. В хеш-таблицах порядок не важен, так что такой способ
        приоритетнее.
________________________________________________________________________

Простой пример для понимания множеств, хеш-функций и т.п.:

- хеш-функция - вычисление остатка от деления на 10.
- хеш-таблица - список длиной 10 со списками, изначально пустыми.
- Входные данные: 12, 17, 25, 127. Тогда хеш-таблица будет вида:
    [[], [], [12], [], [], [25], [], [17, 127], [], []].

Реализация такого примера в коде:

```python
setsize = 10
myset = [[] for _ in range(setsize)]

def add(x):
    # тут условие для уникальности значений в хеш-таблице
    # для мультимножества условие убрать
    if not find(x):
        myset[x % setsize].append(x)

def find(x):
    for now in myset[x % setsize]:
        if now == x:
            return True
    return False

def delete(x):
    xlist = myset[x % setsize]
    for i in range(len(xlist)):
        if xlist[i] == x:
            xlist[i] = xlist[-1]
            xlist.pop()  # удаляет последний эл-т списка
            return
```
________________________________________________________________________

Что эффективно хранить в множестве:

- Вообще говоря, что угодно, т.к. все состоит из чисел.
- Но эффективно - только неизменяемые объекты, т.к. тогда хеш-функцию к
    ним можно посчитать при их создании.
- хеш-функция должна давать равномерное распределение.

Проблемы с хеш-таблицей:

- Если слишком большой размер - ест много памяти - O(N).
- Если слишком маленький размер - большой коэффициент заполнения и
    медленный поиск и удаление - O(K / N).

Таким образом хочется иметь разумный баланс. Обычно хочется, чтобы
коэффициент заполнения не больше единицы (K / N \<= 1, или K \<= N).
Тогда все операции будут занимать в среднем O(1).

Для такого решения у хеш-таблицы должна быть расширяемость по факту
заполнения, например, вдвое, и последующая перестройка таблицы. Тогда
сложность перестройки: O(N).
________________________________________________________________________

> **Задача 1**. Дана пос-ть положительных чисел длиной N и число X.
Нужно найти два различных числа A и B из пос-ти, таких что A + B = X,
или вернуть пару 0, 0, если такой пары чисел нет.

**Решение**:

Будем хранить все уже обработанные числа в множестве. Если очередное
число nownum таково, что (X - nownum) есть в множестве, то мы нашли
ответ.

> **ЗАМЕТКА!** Решается за O(N), но это неточно из-за in в проверке (мб
сложность больше).

**Код**:

```python
def twotermswithsumx(nums, x):
    prevnums = set()
    for nownum in nums:
        if x - nownum in prevnums:
            return nownum, x - nownum
        prevnums.add(nownum)
    return 0, 0
```
________________________________________________________________________

> **Задача 2**. Дан словарь из N слов, длина каждого не превосходит K.
В записи каждого из M слов текста (каждое длиной до K) может быть
пропущена одна буква (опечатка). Для каждого слова сказать, входит ли
оно (возможно, с опечаткой) в словарь.

**Решение**:

Выбросим из каждого слова словаря по одной букве всеми возможными
способами за O(NK\*\*2) и положим получившиеся слова в множество. Для
каждого слова из текста проверим, есть ли оно в множестве, за O(1).

> **ЗАМЕТКА!** Итого решается за O(NK\*\*2 + M).

**Код**:

```python
def wordsindict(dictionary, text):
    goodwords = set(dictionary)
    for word in dictionary:
        for delpos in range(len(word)):
            goodwords.add(word[:delpos] + word[delpos + 1:])
    ans = []
    for word in text:
        ans.append(word in goodwords)
    return ans
```
________________________________________________________________________

### <u> Хеш-таблицы в Python </u> ###
<a id="anchor_set_python"></a>

Использует немного другую структуру хранения:

1. Вместо создания связного списка под индексом хеша при коллизии
    использует смещение на 1 индекс вперед, пока не найдет пустую
    ячейку. При попытке проверки наличия значения линейным поиском идет
    от индекса хеша, пока значение не совпадет. Кроме того, в ячейке
    кроме значения хранится хеш, чтобы не перевычислять его при каждом
    расширении.

2. Для сохранения порядка в реализации п.1 используется константа
    DKIX_DUMMY, которая считается пустой ячейкой при добавлении и
    занятой при поиске. Т.о. поиск не ошибется, если вдруг где-то был
    удален эл-т между индексом, на который указывает хеш-ф-ция, и местом
    непосредственного хранения эл-та с таким ключом/значением.

3. Для сохранения памяти используют дополнительную фичу. Рассмотрим на
    примере словаря. Используется 2 списка: один - indices формата
    `list[int | None]`, другой - entries формата
    `list[list[hash, key, value]]`. В первом списке хранится None,
    DKIX_DUMMY или индекс значения во втором списке, а второй список
    хранит непосредственно хеш, ключ и значение. Хеш и ключ хранятся по
    причинам, указанным в п.1. По сути сам хеш-таблица олицетворяется
    списком indices, и все механики хеш-таблиц работают с ним. А вот
    наполнение таблицы хранится отдельно в расширяемом списке entries.
    Это сделано для того, чтобы словарь занимал минимум места при
    инициализации.

Подробнее см. [ссылка](https://habr.com/ru/articles/432996/).
________________________________________________________________________

### СВЯЗНЫЕ СПИСКИ ###
<a id="anchor_linked_list"></a>

*Односвязный список* - список эл-тов, состоящих из 2 полей: ключ и
ссылка на следующий (или предыдущий) элемент. Содержит также указатели
на head и tail, и опционально может содержать указатель на текущий эл-т
(для последующего удаления/вставки не в конец или начало или других
целей).

*Двусвязный список* - список элементов, состоящих из 3 полей: ключ,
ссылка на следующий элемент, ссылка на предыдущий эл-т. Содержит также
указатели на head и tail, и опционально может содержать указатель на
текущий эл-т (для последующего удаления/вставки не в конец или начало
или других целей).

Преимущества: быстрая вставка и удаление эл-тов в любое место (но чаще
всего в конец или начало) за O(1); динамическая расширяемость в пределах
структуры данных, на которой реализуется.

Недостатки: долгое обращение по индексу за O(N).

Реализация: на стандартном массиве/списке. Пример похожей реализации
можно увидеть в предварительной информации для бинарного дерева поиска,
а также среди информации о стеке, очередях, деке.
________________________________________________________________________

Очередь и стек (см. соответствующие структуры данных) реализуются на
односвязном списке. Дек (см. соотв. структуру данных) реализуется на
двусвязном списке.

На самом деле работают медленнее на связном списке, чем на стандартном
массиве/списке, т.к. связные списки реализуются также на стандартных
массивах/списках, и получается в итоге просто больше вычислений
(ухудшение константы), чем сделать прямую реализацию. Тем не менее,
связные списки бывают полезны в ряде задач. В частности, в улучшении
константы или функционала некоторых структур данных или в идее
персистентных структур данных.
________________________________________________________________________

Реализация односвязного списка с LeetCode:

```python
from __future__ import annotations
from typing import *

class ListNode:
    def __init__(self, val: Any = 0, next: ListNode | None = None) -> None:
        self.val = val
        self.next = next
```

С такой реализацией весь связный список задается одним экземляром класса
\- head (голова, заголовок), т.е. первый эл-т в связном списке.
________________________________________________________________________

Один из способов решения задач при проблеме с нумерацией или
родственными связями между узлами: создать узел dummy, дочерним эл-том
которого будет заголовок заданного связного списка.

Хороший метод при решении задач: создать 2 указателя, которые движутся с
разной скоростью по связному списку.

Пример на 2 указателя показан в задаче ниже.
________________________________________________________________________

> **Задача 1**. *(LeetCode: Задача 876)* Дан заголовок head односвязного
списка. Найти серединный узел. Если узлов четное число, вернуть второй
из двух серединных узлов.

**Решение**:

Создадим указатели slow и fast. Изначально пусть указывают на head.
Затем fast будет двигаться на 2 потомка вперед, в то время как slow - на
одного. Как только fast или fast.next становится None - возвращаем slow,
т.к. он будет указываеть ровно на серединный узел.

**Код**:

```python
def middleNode(head: ListNode) -> ListNode:
    slow = fast = head

    while fast and fast.next:
        fast = fast.next.next
        slow = slow.next
    
    return slow
```
________________________________________________________________________

### <u> Особые использования </u> ###
<a id="anchor_linked_special"></a>

Данная подтема посвящена использованию ссылочных типов данных как идеи
для улучшения функционала или ассимтотики сложности использования ряда
структур данных, а также особых структур данных.

> **ЗАМЕТКА!** Данная тема скорее дополнительная, чем основная, и читать
ее стоит только по необходимости или личному интересу.
________________________________________________________________________

*Деревья со ссылками* - идея реализации деревьев (например, дерева
отрезков) на ссылочных типах данных. Это может пригодиться, когда
индексы эл-тов в дереве большие (например, слой листьев занимает
10\*\*9), но операции производятся на относительно небольшом наборе из
них.

Рассмотрим пример с деревом отрезков. Идея, если изначально дерево
заполнено нулями: создавать только те узлы, которые вызываются при
операции и не создавать остальные до тех пор, пока не вызовутся. Т.е.
будут создаваться элементы только по мере углубления в 1 ветвь до тех
пор, пока очередной дочерний эл-т полностью не накроется отрезком, в
котором изменяем эл-ты.

Более конкретные примеры внутри этого примера: если меняется не отрезок,
а 1 эл-т, будет создано (или задействовано, если они уже были) ровно
logN эл-тов, по 1 на каждый слой. Если меняется левая половина
начального отрезка, и вовсе будет создан всего 1 эл-т.

Таким образом достигается экономия пространства, что может быть
критично, особенно для случаев, когда обрабатываемая структура в полной
своей реализации занимала бы больше места, чем вообще доступно.
________________________________________________________________________

Такая же идея создания по востребованности может иметь место быть в
реализации словарей в виде бора. Понадобятся метки в вершинах о конце
слова, но в остальном идея та же: добавление слова = добавление
побуквенно вершин в бор, создавая цепочку из вершин, и являющихся
словом в сумме, а в последней вершине слова (необязательно это лист)
будет метка конца слова.

При проверке наличия слова в боре побуквенно будем двигаться вглубь,
пока либо не найдем очередную вершину (слова нет в боре), либо найдем
последнюю вершину слова (слово есть, если есть метка конца слова, и
слова нет, если нет метки слова).

Пример:

```
A - буква без метки конца слова
Ax - буква с меткой конца слова

Бор:

    +---start---+
    |     |     |
+---A     Bx    Cx
|   |
Bx  A---+
|   |   |
Dx  Ax  Gx
```

В боре есть слова (слева направо): \
`AB, ABD, AAA, AAG, B, C` \
Других слов нет.

Например:

- Слова "AG" нет, т.к.: от старта смотрим, буква A есть, идем в нее; у
    буквы A нет сына G => слова нет.
- Слова "AA" нет, т.к.: от старта смотрим, буква A есть, идем в нее; у
    буквы A есть сын A, идем в него. Искомое слово закончилось, но в
    данной вершине нет метки конца слова => слова нет.

Допустим, мы хотим добавить слово "CAD". Тогда бор:

```
    +---start---+
    |     |     |
+---A     Bx    Cx
|   |           |
Bx  A---+       A
|   |   |       |
Dx  Ax  Gx      Dx
```

Добавим слово "AA":

```
    +---start---+
    |     |     |
+---A     Bx    Cx
|   |           |
Bx  Ax--+       A
|   |   |       |
Dx  Ax  Gx      Dx
```

Такая реализация словарей алгоритмически эффективнее прочих реализаций.
________________________________________________________________________

*Система непересекающихся мн-в* - система мн-в, где эл-т может
принадлежать только одному мн-ву.

Пусть надо реализовать на этой системе 2 операции: проверка, лежат ли 2
эл-та в одном мн-ве; и объединение двух мн-в.

Идеи реализаций:

1. Реализация на массиве, где индекс - это эл-т, а содержимое - это
    номер мн-ва. Проверка тогда за O(1), но объединение мн-в - за O(N).
2. Реализация на списке связных списков, где внешний индекс списка -
    номер мн-ва, а список внутри содержит элементы, принадлежащие
    данному мн-ву. Тогда проверка за O(N), но объединение - за O(1).
3. Можно использовать надстройку, к 1-ой реализации или ко 2-ой, но не
    списке связных списков, а на списке массивов, и при объединении
    перетягивать меньшее мн-во в большее для меньшего числа перезаписей.

Тогда, например, используя 3ий вариант на массиве массивов, можно
добиться сложности O(N logN) для объединения всех эл-тов в одно мн-во.
________________________________________________________________________

Но суммарно есть более оптимальное решение - *корневые деревья*.

Каждое мн-во будет представлять корневое дерево, т.е. дерево, где
дочерние эл-ты указывают на родительские, а не наоборот, и где корень
указывает сам на себя.

Тогда объединение двух мн-в есть перекидывание указателя в корне
меньшего дерева с себя на корень большего дерева. Таким образом
объединение происходит за O(1), при этом за счет присоединения меньшего
по глубине дерева к большему дерево объединенного мн-ва не углубляется.
Единственный случай углубления дерева - когда объединяются деревья
одинаковой глубины, тогда общая глубина увеличивается на 1.

Это неуглубление поможет в дальнейшем при проверке, лежат ли 2 эл-та в
одном мн-ве. Данная проверка производится следующим образом: для обоих
эл-тов по корневому дереву идем до корня, и если корни одинаковы, то и
эл-ты лежат в одном и том же мн-ве. Иначе - нет.

> **ЗАМЕТКА!** Стоит напомнить, что мы рассматриваем систему
непересекающихся мн-в, и ситуации, когда корни одинаковые у разных мн-в,
быть не может.

Неуглубление в итоге минимизирует число шагов при проходке для поиска
корня. Но для этого в представительском эл-те - корне - следует также
хранить глубину дерева и инкрементировать в случае, если объединяются
два мн-ва одинаковой глубины, или удалять, если мн-во стало подмн-вом
другого мн-ва.

Проверку можно также улучшить на долгой дистанции: идя от какого-то
эл-та и найдя корень, перекидывать его указатель с родителя на корень.
Тогда при следующем обращении к тому же эл-ту будет сделано не logN
действий по проходке, а всего 1.

Сложной операции объединения всех эл-тов в 1 мн-во тоже O(N logN), но в
остальном оно быстрее. Достигается в сумме сложность O(log\*N).

log\*N - это с одной стороны логарифмическая сложность, но по какому-то
приницпу (в данном случае с помощью улучшения константы и со временем
замены при проверке сложности O(logN) на O(1)) меньше O(logN) и
стремится к O(1). Т.о. сложность O(log\*N) лучше O(logN), но хуже O(1).
________________________________________________________________________

### СТЕК ###
<a id="anchor_stack"></a>

### <u> Описание </u> ###
<a id="anchor_stack_desc"></a>

*Стек* - "стопка" - складывается сверху и сверху же достается, т.е.
достается последний добавленный эл-т. В простейшем виде должна
поддерживать 2 операции - положить в стек (`push(smth)`) и забрать
(`pop()`).

"Первый пришел - последний вышел", "First In - Last Out (FILO)", "Last
in - First Out (LIFO)".
________________________________________________________________________

Интересный способ использования - расчет арифметических выражений. Для
этого представим выражение в постфиксной записи (записи, где сначала
записываются операнды, а затем - операции. Например:
`6 + 3 * (1 + 4 * 5) * 2` - это `6 3 1 4 5 * + * 2 * +`. По аналогии с
привычной префиксная запись, как с функциями в программировании, но
порядок обратный. Становится понятнее, если читать задом наперед и
относиться к операциям как к функциям с 2 параметрами, где первый из
них - число, а второй - выражение). Тогда по строке с выражением можно
пробежаться и заполнять стек, если встречаем число, и выполнять
операцию с вторым и первым числом в стеке (порядок важен для разницы и
деления), если встречаем операцию.

Для преобразования инфиксной (классической) записи выражений в
постфиксную также используется стек (промежуточный для операций) и
некоторая строка или список как ответ. По следующему принципу:

- Операнд сразу попадает в ответ.
- Операция выталкивает в ответ все подряд идущие ближайшие операции с
    большим либо равным приоритетом и кладется в стек. Скобки не
    считаются за операцию и прерывают "подрядность".
- Открывающая скобка кладется в стек.
- Закрывающая скобка выталкивает в ответ все операции до открывающей
    скобки, затем удаляет открывающую скобку.
- В конце все операции выписываются в ответ.
________________________________________________________________________

С помощью стека можно заменить рекурсию. Это может понадобиться при
ограничениях, например, на глубину рекурсии, а также из-за того, что
запуск функции есть ресурсоемкая операция.

Например, подсчет факториала числа:

```python
# рекурсия
def factorial(n):
    if n == 1:
        return 1
    prevfac = factorial(n - 1)
    return n * prevfac

# стек
def factorial_via_stack(n):
    stack = []
    stack.append({'n': 4, 'prevfac': '?', 'labelfrom': 0})
    while len(stack) > 0:
        localvars = stack[-1]
        labelfrom = localvars['labelfrom']
        if labelfrom <= 0:
            if localvars['n'] == 1:
                returnedvalue = 1
                stack.pop()
                continue
            localvars['labelfrom'] = 1
            stack.append({'n': localvars['n'] - 1, 'prevfac' = '?', 'labelfrom': 0})
            continue
        if labelfrom <= 1:
            localvars['prevfac'] = returnedvalue
            returnedvalue = localvars['n'] * localvars['prevfac']
            stack.pop()
            continue
    return returnedvalue
```

Такое решение через стек не самое эффективное, но довольно читаемое. Да,
оно менее лаконичное, нежели через рекурсию, но за счет всего одного
вызова функции может быть быстрее.

Идея в ручном выделении локальной памяти в словаре в стеке с
запоминанием, до или после рекурсивного вызова мы находимся.
________________________________________________________________________

### <u> Задачи </u> ###
<a id="anchor_stack_tasks"></a>

> **Задача 1.1**. Проверить правильность скобочной пос-ти, состоящей из
одного вида скобок. 

> **ЗАМЕТКА!** Для правильной пос-ти не должны закрываться неоткрытые
скобки, а все открытые скобки должны закрываться.

**Решение**:

Считать "баланс": октрытая скобка +1, закрытая -1. Баланс всегда >= 0, а
в конце == 0. Решение таким образом без стека.
________________________________________________________________________

> **Задача 1.2**. Проверить правильность скобочной пос-ти, состоящей из
нескольких видов скобок. 

> **ЗАМЕТКА!** Для правильной пос-ти не должны закрываться неоткрытые
скобки, а все открытые скобки должны закрываться.

**Решение**:

Открывающие скобки кладем в стек. Встретили закрывающую - проверили, что
стек не пуст и в вершине лежит соответствующая открывающая, убрали. В
конце стек должен оказаться пуст.

> **ЗАМЕТКА!** Решение завести несколько "балансов" - по одному на вид
скобки - не работает, т.к. есть случаи, когда все работает в >= 0 и
оканчивается в 0 для каждого из балансов, но в общем и целом для пос-ти
это неправильно. Например: `(()[[])]`.
________________________________________________________________________

> **Задача 2**. Для каждого элемента списка найти индекс ближайшего
меньшего числа справа. Для тех, у кого нет, записать значение длины
списка.

**Решение**:

Тривиальное решение за O(N\*\*2).

Сбалансированное дерево - за O(N logN).

Стек - за O(N). Будем хранить в стеке пары из значения и индекса эл-та,
для которых ответ еще не найден. Проходим по пос-ти. Очередной эл-т
выталкивает из стека все эл-ты с большим значением - для них он является
ответом. После этого ложится в стек сам. Т.о. стек хранит все время
возрастающую пос-ть.

Это решение за O(N), т.к. какой бы случай ни упал, каждый эл-т пос-ти
будет один раз записан в стек и один раз изъят и не более того, т.е.
2\*N операций.

> **ЗАМЕТКА!** Для меньшего слева надо делать обход справа налево. Для
большего справа/слева - аналогично меньшему, но в другим знаком
сравнения.
________________________________________________________________________

### ОЧЕРЕДЬ ###
<a id="anchor_queue"></a>

*Очередь* - складывается в конец, достается же из начала, т.е. достается
первый добавленный эл-т из имеющихся. В простейшем виде должна
поддерживать 2 операции - положить в конец очереди (`push(smth)`) и
забрать из начала очереди (`pop`).

"Первый пришел - первый вышел", "First In - First Out (FIFO)".
________________________________________________________________________

Строение - список + указатель на начало очереди + указатель на конец
очереди. Реализация с ограничением длины списка, чтобы при большом
кол-ве операций список не разрастался и не занимал слишком много памяти.
Получается *кольцевой буфер*, где при выходе за последний эл-т списка
указатель перескакивает на начало.

Добавление - смещение конца очереди на 1 (с учетом кольцевого буфера),
добавление эл-та по указателю на конец очереди.

Удаление - смещение указателя на начало очереди на 1 (с учетом
кольцевого буфера). Мб перед этим очистка содержимого удаляемой ячейки,
если необходимо. Кольцевой буфер и указатели как раз нужны для быстрого
удаления, т.к. удаление производится из начала и в классическом виде
было бы нужно совершить O(N) перезаписей, что долго. В случае кольца же
получаеся O(1).

Перескок через круг на индекс 0 лучше реализовывать через % K, где K -
размер кольцевого буфера. Так быстрее, чем через if, и при этом имеется
возможность сохранять реальное значение указателей, даже больше K, что
позволит отслеживать длину очереди.

Можно реализовать и на динамически расширяемом списке, но есть указанные
выше проблемы с удалением, а также проблемы с выделением памяти.

Можно на двусвязном списке.
________________________________________________________________________

### ДЕК ###
<a id="anchor_deque"></a>

*Дек* - очередь с двумя концами - **d**ouble **e**nded **que**ue -
то же, что и очередь, но работает в оба конца (добавляет и забирает как
из начала, так и с конца (`push_front`, `push_back`, `pop_front`,
`pop_back`)).
________________________________________________________________________

Может быть реализован на динамчески расширяемом массиве. Есть проблема с
ситуацией, когда добавляется эл-т вперед и выходит за пределы индекса 0,
но тогда можно выделить больше памяти в новом месте, перекопировать все
в середину нового массива (с запасом места по обеим сторонам) и
переназначить указатели на начало и конец.

Решение лучше - реализация на двусвязном списке с указателями на начало
и конец. Но есть проблема с большими объемами памяти и не самыми
быстрыми операциями.

Еще одна идея - реализация с помощью блоков. Блок тут - это массив
фиксированной длины, и несколько таких образуют дек. Блоки между собой
связаны либо по двусвязному списку, либо в динамически расширяемом
массиве указателей на блоки.
________________________________________________________________________

### КУЧА ###
<a id="anchor_heap"></a>

*Куча* - структура данных, которая позволяет добавить что-то в мн-во
(`add`) и удалить из мн-ва минимальный или максимальный эл-т (`pop`).
Используется в т.ч. для реализации приоритетной очереди.

Куча есть бинарное дерево, для которого работают следующие правила:

- Родитель всегда меньше своих детей (или больше, но рассм. для случая
    меньше).
- Заполняется послойно: пока один из слоев не заполнен, следующий
    заполняться не будет. Заполняется при этом неполный слой строго
    слева направо.

Реализуется за счет своей заполненности на обычном динамически
расширяемом массиве нумерацией подряд эл-тов по слоям (0 - корень,
1 и 2 - дети, 3, 4, 5, 6 - внуки, и т.д.).

Для i-ого эл-та дети будут под индексами 2i + 1 и 2i + 2, а родитель
будет под индексом (i - 1) // 2.

Добавление эл-та:

- Добавляем эл-т на первый незаполненный слой самую левую незанятую
    позицию.
- Просеиваем вверх, если правило 1 кучи нарушено. Просеивание происходит
    так: если родитель больше добавленного потомка - свапаем. Продолжаем
    с добавленным (и уже смещенным выше) эл-том в том же духе, пока не
    выполнится правило 1 кучи.

```python
def push_heap(heap_list, x):
    heap_list.append(x)
    pos = len(heap_list) - 1
    while pos > 0 and heap_list[pos] < heap_list[(pos - 1) // 2]:
        heap_list[pos], heap_list[(pos - 1) // 2] = \
            heap_list[(pos - 1) // 2], heap_list[pos]
        pos = (pos - 1) // 2
```

Удаление минимального эл-та:

- Минимальный всегда в корне дерева. Его и извлекаем.
- Берем самый последний эл-т (самый правый в последнем слое), копируем
    его в корень.
- Просеиваем вниз, меняя с минимальным из сыновей до тех пор, пока
    правило 1 кучи не будет восстановлено (меньший из сыновей не меньше
    родителя).
- Удаляем оригинал просеянного эл-та. Сохраняется до конца для некоторой
    небольшой оптимизации. В промышленном коде лучше удалять его на
    втором пункте и делать лишнюю проверку на одного сына, но в общем и
    целом удаление в конце позволяет укоротить и слегка опимизировать
    процесс, убирая необходимость в проверке на ситуацию на одного сына
    в конце просеивания.

```python
def pop_heap(heap_list):
    ans = heap_list[0]
    heap_list[0] = heap_list[-1]
    pos = 0
    while pos * 2 + 2 < len(heap_list):
        min_son_index = pos * 2 + 1
        if heap_list[pos * 2 + 2] < heap_list[min_son_index]:
            min_son_index = pos * 2 + 2
        if heap_list[pos] > heap_list[min_son_index]:
            heap_list[pos], heap_list[min_son_index] = \
                heap_list[min_son_index], heap_list[pos]
            pos = min_son_index
        else:
            break
    heap_list.pop()
    return ans
```

Добавление и удаление за O(logN).
________________________________________________________________________

Одним из примеров может быть LRU (Last Recent Used) кэширование -
кэширование самых недавно использованных значений, удаление самого
давно использованного значения. Для этого понадобится словарь для
сохранения значений и куча для времени.
________________________________________________________________________

Другим примером является получение медианы в окне (медианный фильтр).

Для этого используется 2 кучи размером K // 2, где K - размер окна. В
одной куче маленькие эл-ты, в другой - большие. По ним и распределяем
новые и из них удаляем старые значения при движении окна.

Для понимания, куда кидать, сравниваем максимум из маленькой кучи и
минимум из большой кучи. Т.о. для маленьких надо использовать кучу с
максимумом в корне, а для больших - с минимумом. Также если происходит
такая ситуация, что эл-тов в одной из куч становится больше, чем в
другой, то перемещаем эл-т из одной в другую, опять же максимум из
маленьких или минимум из больших.

Медиана - минимум кучи больших чисел.
________________________________________________________________________

Также см. Сортировка -> Пирамидальная сортировка.
________________________________________________________________________

### БИНАРНОЕ ДЕРЕВО (ПОИСКА) ###
<a id="anchor_bintree"></a>

### <u> Предварительная информация </u> ###
<a id="anchor_bintree_prelim"></a>

Прежде чем разговаривать о бинарном дереве, для упрощения входа в тему
стоит рассмотреть так называемый *менеджер памяти* для бинарного дерева.

Пусть у нас есть заранее неизвестное кол-во структур с двумя ссылками на
другие структуры. При этом мы знаем, какое максимальное кол-во структур
может существовать одновременно (N). Надо научиться выделять и
освобождать память.

Создадим массив с элементами из 3 полей: ключ и две ссылки на другие
структуры (в терминах деревьев - сыновья). При инициализации в первую
ссылку будем складывать индекс следующего эл-та массива. Кроме того,
оставим указатель на первый свободный эл-т. Получится следующая
структура:

```python
firstvacant = 0
memorymanager = ( [None, 1, None],
                  [None, 2, None],
                  ...,
                  [None, N + 1, None] )
```

Получается по сути говоря односвязный список, но с сохранением структуры
бинарного дерева (или двусвязного списка) для дальнейшего рассмотрения
темы.

Критерий последнего эл-та данной структуры - ссылка в сыне на эл-т,
равный длине массива.
________________________________________________________________________

При заполнении менеджера памяти данными онные сложатся в эл-т по ссылке
firstvacant, а firstvacant станет равен сыну этого эл-та. Например, при
первых двух добавлениях эл-та в менеджер памяти получится следующая
картина:

```python
firstvacant = 2
memorymanager = ( [smth, 1, smth],
                  [smth, 2, smth],
                  [None, 3, None],
                  ...,
                  [None, N + 1, None] )
```

Таким образом что-то хранится в первой ячейке структуры, но она как бы
выпадает из ростера вакантных, т.к. на нее нет ссылки ни в firstvacant,
ни в свободных сыновьях ячеек. То же самое и со вторым.

Попробуем теперь освободить первую ячейку (захотели удалить ее
содержимое). Для этого мы могли бы по ссылочной логике поместить ее в
конец, заставив последний ныне эл-т ссылаться на нее, а ее саму - на
N + 1. Но это займет O(N), т.к. придется перебирать эл-ты в поисках
эл-та с сыном N + 1 (при постоянных перезаписях он потеряется где-то
среди всех эл-тов). Легче сделать иначе: освободить и сделать ячейку
первым вакантным эл-том. Для этого в сына освобождаемой ячейки записать
firstvacant, а сам firstvacant изменить на индекс освобождаемой ячейки.
Таким образом получится:

```python
firstvacant = 0
memorymanager = ( [None, 2, None],
                  [smth, 2, smth],
                  [None, 3, None],
                  ...,
                  [None, N + 1, None] )
```

**Код реализации такой структуры**:

```python
def initmemory(maxn):
    memory = []
    for i in range(maxn):
        memory.append([0, i + 1, 0])
    return [memory, 0]

def newnode(memstruct):
    memory, firstfree = memstruct
    memstruct[1] = memory[firstfree][1]
    return firstfree

def delnode(memstruct, index):
    memory, firstfree = memstruct
    memory[index][1] = firstfree
    memstruct[1] = index
```
________________________________________________________________________

### <u> Описание </u> ###
<a id="anchor_bintree_desc"></a>

*Бинарное дерево* - структура, представляющая собой набор узлов, которые
связаны друг с другом по следующим правилам:

- У каждого узла есть поля: ключ и два сына - левый и правый. Сыновей у
    узла может быть меньше 2, тогда какие-то поля будут не заполнены.
    Поле сына содержит ссылку на следующий эл-т по аналогии с менеджером
    памяти.
- В общем смысле предоставляет набор правил наследования (см. Дерево
    отрезков, Куча), но в пределах данной подтемы конспекта имеется в
    виду *бинарное дерево поиска*, для которого правило следующее: в
    левом поддереве любого узла все ключи меньше, чем в данном узле, а в
    правом - больше.

Корнем называется самая первая добавленная ячейка, а от нее дерево будет
разветвляться далее. Листком называется узел дерева, не имеющий ни
одного сына.

**Свойства**:

1. Из одного и того же набора эл-тов могут получиться разные деревья, в
    зав-ти от порядка поступления эл-тов.

    Если ключи поступают "хорошо", то глубина дерева будет logN.
    "Хорошо" в данном случае - это в случайном порядке ключа. Тогда в
    основном у узлов будет по 2 сына, кроме листочков, что и называется
    "хорошим" случаем для дерева.

    Например, "плохо" будет, если ключи поступают упорядоченно по
    возрастанию, ибо тогда дерево выродится в менеджер памяти,
    превращаясь в одну прямую правую ветку.

1. Любое поддерево также является деревом, что позволяет рекурсивно
    обрабатывать деревья.
________________________________________________________________________

### <u> Основные операции </u> ###
<a id="anchor_bintree_operations"></a>

Возьмем структуру менеджера памяти и весь его функционал:

```python
memstruct = [memory, firstfree]
memory = ( [key, leftson, rightson], 
           ... )
```
________________________________________________________________________

**Поиск**: Сравнить искомый ключ с узлом. Меньше - в левое поддерево,
больше - в правое, равно - элемент нашелся. Рекурсивно повторить с
полученным поддеревом, либо выйти, если элемент нашелся.

```python
def find(memstruct, root, x):
    key = memstruct[0][root][0]
    if x == key:
        return root
    elif x < key:
        left = memstruct[0][root][1]
        # -1 - отсутсвие сына. Мб и None, если удобнее
        if left == -1:
            return -1
        else:
            return find(memstruct, left, x)
    elif x > key:
        right = memstruct[0][root][2]
        if right == -1:
            return -1
        else:
            return find(memstruct, right, x)
```
________________________________________________________________________

**Добавление элемента**: Аналогично поиску, но окончанием процесса
является ситуация, если у узла, с которым сравниваем, в нужном
направлении нет сына - там и помещаем.

```python
def createandfillnode(memstruct, key):
    index = newnode(memstruct)
    memstruct[0][index][0] = key
    memstruct[0][index][0] = -1
    memstruct[0][index][0] = -1
    return index

def add(memstruct, root, x):
    key = memstruct[0][root][0]
    elif x < key:
        left = memstruct[0][root][1]
        if left == -1:
            memstruct[0][root][1] = createandfillnode(memstruct, x)
        else:
            return add(memstruct, left, x)
    elif x > key:
        right = memstruct[0][root][2]
        if right == -1:
            memstruct[0][root][2] = createandfillnode(memstruct, x)
        else:
            return add(memstruct, right, x)
```
________________________________________________________________________

**Удаление элемента**: Поиск с сохранением родителя текущего узла (либо
каждый узел дерева должен хранить еще одно поле: ссылку на родителя).
Теперь есть 3 случая:

1. *Лист*. Тогда у родителя удаляем соответствующего сына.

2. *Потомок 1*. Тогда у родителя меняем соответсвующего сына на этого
    потомка.

3. *Потомка 2*. Тогда ищем самое наименьшего потомка среди всех
    поколений потомков правой ветви (т.е. идем один раз направо, а потом
    налево до упора), и его встраиваем на место удаляемого узла. Этот
    встриваемый узел может не иметь сына или иметь одного правого (иначе
    он бы не был минмальным), и в обоих случаях действие аналогично
    удалению листа или узла с 1 потомком.
    
    Можно было поступить симметрично и взять самого правого в левой
    ветви, действия тогда симметричны.
________________________________________________________________________

**Обход**: Рекурсивно начинаем с корня. Если есть левый сын - запуск
рекурсии для него. Добавить в результат. Добавить в результат себя. Если
есть правый сын - запуск рекурсии для него. Добавить в результат.
Вернуть результат. Таким образом получится весь набор элементов, причем
отсортированный по возрастанию. Можно симметрично поступить для
получения результата по убыванию.
________________________________________________________________________

### <u> Балансировка </u> ###
<a id="anchor_bintree_balance"></a>

Отдельная крупная тема, дополнить по необходимости. Ключевые слова для
поиска: АВЛ-дерево, красно-черное дерево, более экзотические:
декартово дерево, сплей-дерево.
________________________________________________________________________

### <u> Дополнительно </u> ###
<a id="anchor_bintree_extra"></a>

Представление дерева в Python: \
`[key, [<left_branch>], [<right_branch>]]`

Здесь `<left_branch>` и `<right_branch>` описываются аналогично, т.к.
сами являются деревьями. Отсутсвие сына обозначается None.

Таким образом в Python необязательно иметь менеджер памяти, можно и,
вероятно, удобнее обрабатывать все в таком виде.
________________________________________________________________________

Кроме того, есть представление бинарного дерева через узлы с LeetCode:

```python
from __future__ import annotations
from typing import *

class TreeNode:
    def __init__(self, val: Any = 0, left: TreeNode | None = None,
                 right: TreeNode | None = None) -> None:
        self.val = val
        self.left = left
        self.right = right
```

Т.о. дерево задается узлом корня root, который ссылается на корни левого
и правого поддерева, и более ничего. Поверх такой реализации можно уже
накручивать остальные ф-ции, указанные выше.
________________________________________________________________________

Небинарные деревья также иногда используются. В более общем понимании
небинарное дерево есть много где, например, каталог папок, файлов и
подпапок. Или дерево классов/других эл-тов в программе. Более
неочевидный пример - html-документ.

Если реализуется небинарное дерево программно, то сыновья хранятся
списком. Обходим аналогично бинарному, просто запуская рекурсивную ф-цию
для всех сыновей.
________________________________________________________________________

**Описание структуры дерева** возможно с помощью строки. Такая запись
называется *сериализованной*.

1. L - влево, R - вправо, U - вверх.
2. D - в наиболее левого непосещенного ребенка, U - вверх (только для
    деревьев, где либо 2, 0 сыновей у каждого узла).
3. D - в наиболее левого непосещенного ребенка, U - вверх, пока не
    приходим из правого ребенка. Если пришли из левого - сразу переход
    в правого (только для деревьев, где либо 2, 0 сыновей у каждого
    узла).

Таким образом пример из алгоритма Хаффамана:

```
    0---None---1
    |          |
    а      0--None--1
           |        |
        0-None-1    б
        |      |
        в      г
```

Или в Python:

```python
[None,
    ['а', None, None],
    [None, 
        [None, 
            ['в', None, None],
            ['г', None, None]],
        ['б', None, None]]]
```

Описывается как LURLLURUURUU, DDDDUDUUDUU или DUDDUU соответственно.
________________________________________________________________________

### ДРУГИЕ ДЕРЕВЬЯ ###
<a id="anchor_other_trees"></a>

В общем смысле дерево есть граф (см. Граф) без циклов. В таком ключе
можно придумать множество различных деревьев. Но среди них выделяются:

- Бинарные деревья - ориентированные от родителя к дочерним эл-там
    деревья с не более чем 2 дочерними эл-тами у любого эл-та. Среди
    них:
    - Бинарное дерево поиска (см. Бинарное дерево поиска).
    - Бинарная куча (см. Куча).
    - Дерево отрезков (см. Дерево отрезков).

- Бор - дерево с подписанными ребрами (см. использование в Алгоритмах
    Хаффмана, Лемпела-Зива-Велча, а также в особых использованиях
    Связных списков).

- Корневое дерево - дерево, ориентированное от дочерних эл-тов к
    родителям (см. использование в особых использованиях Связных
    списков).
________________________________________________________________________

### ГРАФ ###
<a id="anchor_graph"></a>

### <u> Описание </u> ###
<a id="anchor_graph_desc"></a>

*Граф* - структура данных, состоящая из вершин и ребер, связывающих
пары вершин. Бинарное дерево - частный пример графа, с ограничениями на
связи между элементами (родители-дети, не более 2 детей). В графе в
общем смысле таких ограничений нет, могут возникать циклы, могут быть
разные виды связи по ребрам, нет родителей и детей.

В общем смысле эта структура состоит из:

- V (vertexes) - массива с набором вершин.
- E (edges) - упорядоченного массива с ребрами - парами вершин (u, v).

Терминология:

- *Смежность* - вершины смежные, если между ними есть ребро.
- *Путь* - набор уникальных ребер, с помощью которого можно добраться
    из одной вершины в другую.
- *Цикл* - это путь, который ведет из вершины в нее же.
- *Связность* - граф связный, если из любой вершины есть хотя бы 1 путь
    до любой другой.
- *Ориентированность* - граф ориентированный, если в нем в ребрах есть
    направление движения. Тогда ребра (u, v) и (v, u) есть разные ребра,
    а наличие только (u, v) означает, что по этому ребру из v в u пройти
    нельзя.
- *Взвешенность* - наличие масс на ребрах (или вершинах).
- *Полнота* - характеризует кол-во связей (или заполненность графа
    ребрами). Граф полный, если все вершины связаны со всеми, тогда
    число ребер (для неориентированного графа) равно `V * (V - 1) / 2`.
    Чем ближе число ребер к данному числу, тем полнее граф.
- *Разреженность* - антоним полноте. Минимальное число ребер для
    связности графа: `V - 1`. Условно можно разделить заполненные и
    разреженные матрицы по кол-ву связей: если их больше порядка V**1.5,
    то заполненные, а если нет, то разреженные. Очень натянутая граница.

Частный случай - дерево - связный граф, в котором ребер на 1 меньше,
чем вершин. В нем нет циклов.
________________________________________________________________________

Хранение графа:

1. Матрица смежности - матрица V x V, где V - число вершин. В ней
    вертикаль и горизонталь соответствуют номерам вершин, а в полях
    на пересечении i и j указан 0, если вершины не смежны, и 1, если
    смежны; на главной диагонали все поля равны 0, т.к. соответствуют
    пересечению вершины с самой собой.

    Для ориентированного графа матрица несимметричная, для
    неориентированного - симметричная.

    Хорошо для сильно заполненных графов, малоэффективно для
    разреженных.

2. Список смежности - список длины V с массивами смежных эл-тов для
    соответствующей вершины.

    Хорошо для разреженных графов, менее эффективно для заполненных.

    Более часто используется, т.к. чаще графы разреженные, нежели
    полные, и задачи более подходящие. Далее рассматриваем именно такой
    вариант хранения.
________________________________________________________________________

### <u> Обход в глубину </u> ###
<a id="anchor_graph_depth"></a>

DFS - depth-first search - поиск (обход) в глубину. Нужен для того,
чтобы понять структуру графа.

Оказавшись в вершине (для неориентированного графа):

- Есть непосещенные смежные вершины?
    - Да: идем в них, записываем обратную стрелочку (как бы сохраняя
        обратный путь).
    - Нет: возвращаемся на одну вершину назад по стрелочке.

Это решение схоже с поиском выхода из лабиринта с пометкой каждой
развилки. В коде это реализуется рекурсивно.

**Код**:

```python
def dfs(graph, visited, now):
    visited[now] = True
    for neig in graph[now]:
        if not visited[neig]:
            dfs(graph, visited, neig)
```
________________________________________________________________________

Используя DFS, можно, например:

- Проверить граф на связность: если после проходки остались False в
    visited, то несвязный. Более оптимальное решение - завести счетчик,
    после DFS сверить с длиной списка связности.

- Найти компоненты связности: проверка на связность + в DFS несем еще
    один параметр, означающий номер несвязной части графа, и присваиваем
    его при проходке. При выходе из DFS переходим к следующей части
    графа.

```python
comp = 1
for i in range(V):
    if not visited[i]:
        dfs(graph, visited, i, comp)
        comp += 1
```

> **ЗАМЕТКА!** Последнее бывает полезно, стоит обратить внимание.

> **ВАЖНО!** Такое работает для неориентированного графа. Для
ориентированного могут быть ситуации, когда мы начали с неудачного
места, что мы "раскрасили" в несколько цветов (параметров групп) разные
вершины внутри одного компонента связности. Пример такой ситуации -
лучи, ведущие в единый центр, или даже в простой ветке начать с
середины. Чтобы этого избежать - проверять цвет соседей, перекрашиваться
в новый цвет или цвет соседей и выкидывать свой цвет наверх по рекурсии.

- Найти "мосты" - такие ребра, при удалении которых связная компонента
    распадется на 2.

- Найти "точки сочленения" - такие вершины, при удалении которых связная
    компонента распадется на 2.
________________________________________________________________________

Поиск цикла в графе.

- Для неориентированного графа достаточно встретиться при очередном
    осмотре соседей в DFS с уже посещенным узлом, чтобы сказать, что
    цикл есть, и вернуть его по необходимости, восстановив ответ по мере
    выход из рекурсии.

    Но есть нюанс - неориент. граф по сути в списке связности одно ребро
    превращает в 2 - по 1 в каждую сторону. Тогда в любом неориент.
    графе длиной больше 1 есть цикл. Но это не так. Для избежания этой
    проблемы важно в DFS ф-ции передавать и номер узла, из которого мы
    идем в следующий, и не обрабатывать его при пробежке по смежным.

- Для ориентированного графа такое решение не подходит, т.к. в зав-ти от
    направления стрелок это может быть как цикл, так и 2 альтернативных
    пути без цикла. Для решения такой ситуации в DFS используется
    запись не True/False в visited, а:

    - По умолчанию - 0 ("белый цвет").
    - Зашли по DFS в узел, но не вышли из него обратно - 1 ("серый
        цвет").
    - Вышли из него, обработав всех смежных - 2 ("черный цвет").

    Тогда, если мы при очередном просмотре смежных узлов наткнулись на
    значение 2 - тогда это не цикл, если на 1 - тогда цикл, если на 0 -
    туда можно по DFS пойти.

> **ВАЖНО!** Не забывать, что граф может состоять из нескольких
компонент связности, тогда см. выше.
________________________________________________________________________

Проверка графа на двудольность - можно разложить граф на 2 доли так, что
ребра будут проходить из одной доли в другую и не будет ребер между
вершинами одной и той же доли.

Решается попеременным "раскрашиванием" вершин в 2 цвета в ходе DFS. Если
наткнулись на уже раскрашенный - проверяем, разные ли цвета. Да -
продолжаем по DFS, нет - граф не двудольный, завершаем DFS.

> **ВАЖНО!** Не забывать, что граф может состоять из нескольких
компонент связности, тогда см. выше.
________________________________________________________________________

*Топологическая сортировка* - перенумерация вершин так, чтобы все ребра
вели из вершин с меньшим номером в вершины с большим номером.

Наивно можно сделать так:

- Нумеруем вершину, в которое не входит ни одно ребро, и псевдоудаляем
    ее и ребра из нее. Повторять, пока не останется вершин.

> **ВАЖНО!** Есть графы, которые нельзя топологически отсортировать, а
именно графы, содержащие циклы. Это надо отрабатывать.

Для хорошей реализации наивного решения:

- На этапе считывания графа поддерживаем счетчик входящих ребер. При
    последующем удалении ребер уменьшать счетчики у вершин, в которые
    эти ребра ведут. Вершины для удаления выделяются лин. поиском,
    сложность - O(V\*\*2).
- Можно ускорить. Самая слабая часть - лин. поиск. Для исправления -
    надстроить кучу со значениями счетчика и чем-то для сохранения
    нумерации вершин, использовать быструю сортировку по счетчикам, тоже
    с сохранением нумерации, или что-то еще, в зав-ти от задачи.

Решение с помощью DFS:

- DFS, если красим вершину в черный - выписываем в отдельный список.
    Тогда после всех DFS (для учета, что не все всегда достижимо)
    перевернуть полученный список и перенумеровать эл-ты в нем по
    возрастанию.

    Это работает, т.к. каждый раз для нового добавленного в список
    черного элемента будет верно, что мы уже обработали эл-ты левее и,
    следовательно, из них мы в текущий эл-т попасть не можем.

    Не забывать обрабатывать ситуацию, когда встречается цикл и
    построить топологически отсортированный граф нельзя. Именно для
    этого и нужна покраска в белый-серый-черный.
________________________________________________________________________

### <u> Обход в ширину </u> ###
<a id="anchor_graph_width"></a>

BFS - breadth-first search - поиск (обход) в ширину. В отличие от DFS,
ищет не по путям, а по слоям от начальной вершины.

Позволяет найти наименьший путь в невзвешенном графе от одной вершины до
всех остальных.

Базовая идея обхода в ширину:

Для объяснения стоит рассмотреть другой спопособ представления графов -
таблица-лабиринт с проходимыми и непроходимыми клетками. Клетка -
вершина, а соседство по стороне ячейки таблицы - ребро.

Алгоритм (возьмем связный граф для простоты):

- Пометим все непроходимые клетки как -2, непосещенные клетки как -1, а
    в точку старта поместим 0. Номер итерации приравняем 0.
- Ищем по всем клеткам ячейки с значением, равным номеру итерации, и
    всем соседям с -1 поменяем значение на номер итерации + 1. Увеличим
    номер итерации на 1. Продолжаем, пока есть клетки с -1 внутри.

После выполнения в клетках будет содержаться длина кратчайшего пути от
начальной точки до данной клетки. Восстанавливается путь через обратный
ход от текущей клетки до начальной.

> **ВАЖНО!** Это базовая идея, но не сам алгоритм обхода графа в ширину.
Как видно из пункта пробежки по всей таблице, сложность будет большая
(O(VE), кроме того с не лучшей константой). Тем не менее, данная базовая
идея хорошо описывает сам принцип, логику и смысл обхода в ширину.
________________________________________________________________________

Теперь улучшим данный алгоритм.

- Сохранение вершин.
    - Заведем список списков, где по индексу i хранятся все клетки с
        содержимым i (т.е. с кратчайшим путем, равным i). При разметке
        клеток будем сохранять в него координаты клетки, затем при
        поиске клеток с содержимым j будем обращаться по индексу j к
        данному списку вершин.

        Список вершин по длине либо динамически расширяемый, либо по
        кол-ву клеток в таблице.

        Конец обхода - конец осмотра списка вершин.

        Такой обход занимает O(V + E).

- Сохранение вершин через очередь.
    - Обсловлено отсутствием динамически расширяемых массивов в прошлом.
        В отличие от предыдущего, сохраняем вершины не в список, а в
        конец очереди, а обрабатываются точки и их соседи по вершине в
        начале очереди (ф-ция `pop` очереди). Тогда все вершины на
        расстоянии k будут обрабатываться подряд, т.к. добавлялись
        подряд, и логика алгоритма не меняется и не ломается.

        Конец обхода - очередь опустела.

        Более традиционное и более эффективное по памяти решение, при
        этом такое же по скорости. Но при аккуратном исполнении на самом
        деле решение и через список вершин будет столь же эффективен по
        памяти, так что на самом деле решение через очередь просто
        хранит в себе традиционное решение и ничего более.

        Для большей информации по очередям см. Структуры данных ->
        Очередь.
________________________________________________________________________

Обход в ширину для нескольких концов:

- Тот же алгоритм, но после завершения алгоритма обхода выбираем среди
    концов с наименьшим значением внутри.

Обход в ширину для нескольких начал:

- Обозначаем все начала за 0 и произведем тот же алгоритм. Алгоритм
    обхода в ширину не боится нескольких начал и никак не меняется с их
    появлением.

Обход в ширину для нескольких начал и концов:

- Объединяем две предыдущие задачи.
________________________________________________________________________

Обход в ширину графа в классическом (нетабличном, нелабиринтном)
представлении:

- Тот же, но сохранение не координат, а номеров вершин.

- Различия начинаются на восстановлении ответа, т.к. предыдущая логика
    не работает, т.к. в классическом исполнении ячейка графа не хранит
    номер предыдущей ячейки, и если в неориентированном графе это еще
    решается по аналогии с соседями в табличном представлении, то в
    ориентированном не решается так просто.

    Поэтому для восстановления ответа по мере обхода надо в вершину
    сохранять не только путь, но и номер вершины, из которой данный путь
    ведет, и тогда все просто восстанавливается. Для начальной номер
    предыдущего поставим -1 и сделаем это сигналом для конца
    восстановления ответа.
________________________________________________________________________

Обход в ширину для поиска кратчайшего пути между фиксированными
вершинами A и B, как рассказано выше, строго говоря далеко не самый
оптимальный, т.к. расчитывает много ненужных вершин и путей. Для
небольших графов это может быть некритично, но для больших графов это
становится проблемой.

Для оптимизации просто считаем пути от A и B по очереди по 1 шагу:
сначала все вершины длиной пути 1 для A, потом - для B, потом все
вершины длиной пути 2 для A, потом - для B, и т.д. до пересечения. От
вершины пересечения восстанавливаем путь до A и до B, аккуратно
склеиваем и получаем кратчайший путь от A до B.

Еще раз упомянем, что такое решение стоит того чаще всего только на
больших графах, особенно где получение соседней вершины занимает много
времени. В маленьких графах это чаще всего не рационально со стороны
отношения времени разработки к получаемому профиту, не считая редких
случаев, а то и вовсе может замедлить работу. Но знать все равно важно.
________________________________________________________________________

> **Задача 0.1**. Для каждой вершины и ребра сказать, находится ли оно
на каком-либо из кратчайших путей от A до B.

**Решение**:

*Вершины*:

Проведем обход в ширину сначала от A до B, а затем от B до A. Таким
образои, каждой вершине графа будет соответствовать 2 числа. Если сумма
этих чисел равна длине кратчайшего пути, то вершина лежит на каком-то
кратчайшем пути.

Для ориентированного графа при втором обходе нужно все ребра развернуть.

*Ребра*:

Пользуясь результатами обходов для вершин, смотрим на вершины, между
которыми проходит ребро. Если 2 вершины лежат на кратчайшем пути и
некоторая дополнительная проверка, варианты которой укажем позже, то и
ребро лежит на кратчайшем пути.

Во-первых, условия с 2 вершинами на кратчайшем пути недостаточно, т.к.
можно придумать контрпример с ребром между двумя кратчайшими путями,
которое само ни к одному из них не подходит.

Во-вторых, какие дополнительные проверки могут быть, чтобы избежать
случая, указанного выше? Например, проверить также, что для первых (или
вторых) чисел в вершине выполняется равенство их разницы единице (по
аналогии с тем, как восстанавливается кратчайший путь, был бы переход
от одной вершины к другой при восстановлении). Либо, более понятный
вариант, пусть x - первое число левой вершины, а y - второе число
правой, k - длина кратчайшего пути. Тогда должно выполняться равенство 
`x + y = k - 1`, если ребро лежит на кратчайшем пути. Если брать числа
наоборот: x - второе число левой вершины, y - первое число правой, тогда
`x + y = k + 1`.
________________________________________________________________________

Теперь рассмотрим *взвешенные графы* в контексте BFS.

Для начала рассмотрим *0-1 графы* - графы с 0 или 1 на ребрах.

На самом деле мало что меняется, но в ходе выполнения программы важно
быть аккуратным, т.к. в очередь теперь могут заходить и посреди нее, что
призывает аккуратнее использовать очередь как потенциальное решение. Это
происходит из-за того, что смежная вершина может принести как +1
расстояния, как раньше, так и +0, помещая смежную вершину в ту же группу
по расстоянию. В случае использования списка списков вершин, а не
очереди, тоже надо быть осторожным, чтобы обработать и новые добавляемые
эл-ты. Универсально будет использовать `while substring` с ручным
ведением индекса вместо `for i in range(len(substring))`, т.к. во втором
случае все новые эл-ты не обработаются.

Это влечет также и проблемы с потенциальной обновлением минимального
расстояния в смежной вершине: по одному пути мы могли прийти за 1, а
потом через несколько смежных за 0 смогли найти путь за 0. Такие случаи
надо проверять при очередном взятии вершины из списка списков по
расстояниям: если у нее записано расстояние, меньшее, чем сейчас
обрабатывается (индекс подсписка в списке больше, чем записанное число),
то просто игнорируем данную вершину.

Как вариант исполнения - вместо очереди использовать дек.
________________________________________________________________________

Для *0-k графов* методология та же самая, но на 0-1 графе было легче
объяснять особенности взвешенных графов в контексте BFS.

Задается длина списка вершин тогда как (V - 1) \* k, или более удобной
аппроксимацией, если это возможно.

Единственная особенность, которую стоит обговорить отдельно для 0-k
графов - это случай, когда все ребра имеют значения порядка k. В таком
случае при реализации через список списков будет много пустых
подсписков - высокая разреженность. Чтобы этого избежать, достаточно
вести словарь, а не список. А чтобы обрабатывать это быстрее, будет
лучше использовать не словарь, а кучу минимумов.
________________________________________________________________________

### <u> Агоритм Дейкстры </u> ###
<a id="anchor_graph_dijkstra"></a>

Для начала оговоримся о способе хранения взвешенных графов.

Матрица смежности - запись вместо 0/1 или True/False весов, а где нет
пути - соответствующий маркер, например, -1. Но, помним, в реальности
достаточно полных графов крайне мало, чаще разреженные.

Список смежности - вместо списка вершин используем список кортежей вида
(номер, масса) или другие модификации.
________________________________________________________________________

Алгоритм Дейкстры предназначен для поиска кратчайшего пути во взвешенном
графе. К этому алгоритму постепенно подходили размышления выше, в 0-k
графах в контексте BFS.

> **ВАЖНО!** Работает только для неотрицательных весов на ребрах. В
таком случае считаю док-во работоспособности достаточно тривиальным. В
случае отрицательных весов в целом не работает и требует модификаций,
значительно ухудшающих алгоритмическую сложность. Поэтому далее будет
подразумеваться, что веса на ребрах неотрицательные.

Идея алгоритма:

1. Создать место для хранения флага посещенности и минимального
    расстояния для каждого узла графа. Например, 2 массива - visited и
    dist. Учитывая то, что нумерация узлов обычно идет с 1, будем вести
    ее так же. Кроме того, пусть по задаче надо найти минимальный путь
    из 1-ого узла, тогда dist[1] = 0, а остальные эл-ты массива dist
    приравняем к inf. Все значения массива visited - False.
2. Итерационно выбираем непосещенную вершину с минимальным значением
    dist (в первой итерации это всегда будет точка отправления), меняем
    флаг в visited и смотрим все пути из нее, обновляя значения dist по
    необх-ти. Повторяем, пока visited будет содержать только True или
    пока visited конечной точки не станет True.

Пример:

```
Визуальное представление:

+--1--+
|  |  |
2  |  3
|  |  |
+--4--+
   |
   5

Пути ведут сугубо из меньшего номера в больший. Массы на ребрах:

1 -> 2: 1
1 -> 3: 2
1 -> 4: 5
2 -> 4: 2
3 -> 4: 2
4 -> 5: 1

Надо найти минимальный путь из 1 в 4.

n       1  2   3   4   5
visted  F  F   F   F   F
dist    0 inf inf inf inf

1-ая итерация: минимальный по dist непосещенный - 1-ый. Пути из него 3.
Сравниваем: inf > 0 + 1 => dist[2] = 1,
            inf > 0 + 2 => dist[3] = 2,
            inf > 0 + 5 => dist[4] = 5.

Итого:

n       1  2  3  4  5
visted  T  F  F  F  F
dist    0  1  2  5 inf

2-ая итерация: минимум в 2-ом узле. Сравниваем:
5 > 1 + 2 => dist[4] = 3.

Итого:

n       1  2  3  4  5
visted  T  T  F  F  F
dist    0  1  2  3 inf

3-я итерация: минимум в 3-ем узле. Сравниваем:
3 < 2 + 2 => dist[4] не меняем.

Итого:

n       1  2  3  4  5
visted  T  T  T  F  F
dist    0  1  2  3 inf

4-я итерация: минимум в 4-ом узле, можно остановиться. Либо можно
продолжить, в зав-ти от задачи, и дорешать до конца. В данной задаче
можно остановиться и дать ответ.

Ответ: 3.
```
________________________________________________________________________

Отдельно отметим, что в случае несвязного графа и задачи, при которой
надо попасть из одной компоненты связности в другой (т.е. по сути случай
недостижимости), на какой-то из итераций получится, что минимальное
расстояние из непомеченных будет равно inf, и это будет сигналом, что
добраться из точки начала в конец нельзя.

Другой случай, когда на очередной итерации при сравнении нового
расстояния и уже записанного в dist получается равенство, также значение
в dist не изменяем.
________________________________________________________________________

В таком виде алгоритм Дейкстры позволяет узнать минимальное расстояние,
но не сам маршрут. Для восстановления ответа следует завести
дополнительный массив prev для хранения номера узла, из которого пришли
в текущий в том самом записанном в dist минимальном случае. Тогда
обратной пробежкой (с конца в начало) ответ восстановится после
нахождения минимального пути. prev[1] = -1 или 0, как удобнее в
реализации.

Т.о. в примере выше:

```
В конце имеем:

n      1  2  3  4   5
prev  -1  1  1  2  -1

Восстанавливаем: 4 <- 2
                 2 <- 1
                 1 <- -1
-1 как сигнал окончания восстановления. Получили 4 2 1.

Ответ есть развернутый путь из конца в начало: 1 -> 2 -> 4.
```
________________________________________________________________________

Сложность алгоритма Дейкстры: внешний цикл "пока есть непосещенные
вершины" или "пока не посещена целевая точка" выполняется за V, найти
минимальную непосещенную за V, а просмотр соседей займет в сумме E
действий, т.к. каждое ребро будет рассмотрено всего 1 раз. E, как мы
помним из рассуждений выше, вне мультиграфа составляет не более V\*\*2.
Т.о. сложность составляет O(V\*\*2 + E) = O(V\*\*2).

Получается довольно медленно, особенно если рассматривать в навигации по
картам и выстраивании наиболее короткого маршрута. Поэтому требуется
ускорение.
________________________________________________________________________

Сначала оговоримся о тех методах ускорения, которые используются на
практике в крупных задачах - например, навигация по картам, - но не
используются на мелких задачах или тем более алгоритмической секции
собеседования.

Метод предподсчета и кэширования. Рассмотрим ситуацию, когда надо
составить маршрут из одного города в другой через множество других
городов. В таком случае чистыми маршрутами по дорогам, где узлы -
перекрестки, а ребра - дороги, расчет алгоритма может занять крайне
нереальное кол-во времени. Поэтому одним из используемых методов
является кэширование. Города становятся сложными узлами, где есть
ограниченное кол-во въездов и выездов. Сохраняется самый быстрый путь
от каждой точки въезда до каждой точки выезда. При расчете пути эти
данные подтягиваются и используются, и т.о. сокращаются расчеты проезда
по городам, особенно учитывая то, что в них плотность перекрестков выше,
чем в "пустом поле".

Для более быстрого поиска кратчайшего пути до одной точки широко исп-ся
алгоритм А*. Больше информации - см. Специальные алгоритмы.
________________________________________________________________________

Теперь перейдем к улучшению алгоритма в частности.

Внешний цикл "пока есть непосещенные вершины" или "пока не посещена
целевая точка" не улучшается в контексте логики алгоритма Дейкстры.

А вот поиск минимального непосещенного узла можно ускорить с помощью
кучи до O(1) (вопрос спорный, может свестись до logV). Но тогда просмотр
всех соседей вершины и обновление расстояний замедляется, т.к. нужно
удалять по индексу. Вообще это возможно, см. Куча, но это нестандартная
ф-ция и требует написания своей структуры, что однозначно будет
медленнее на интерпретируемом языке, чем стандартная реализация, та же
heapq для Python.

Решение этого - КЧ-дерево или другое сбалансированное бинарное дерево
поиска. Оно тоже за порядка O(1) находит минимальный эл-т, но и удаляет
в стандартной реализации по индексу за O(logV). В C++ так реализован
set, а также можно использовать map. В Python в свободном доступе
соответствующей библиотеки с самобалансирующимся деревом не нашел. Тогда
сначала удаляем старое, поменять в массиве dist, потом добавить новое.
Лучшая общая сложность: O(E logV). Видно, что в случае неразреженного
графа такая сложность хуже: E ~ V\*\*2. Но в подавляющем большинстве
случаев такая сложность лучше.

Можно решить по-другому: куча без удаления. Тогда вынется первым самый
маленький эл-т для данного узла, а потом в visited будет уже значение
True для данного узла и при вытаскивании следующего по величине значения
для него просто проигнорируем его и перейдем к следующему. Но проблема с
памятью - вместо O(V) доп.памяти становится в худшем случае O(E), что в
своем худшем случае ~ V\*\*2. Сложность: O(E logE) = O(E logV). С точки
зрения константы вроде бы хуже, но при этом за счет реализации через
стандартную кучу может быть быстрее КЧ-дерева. Для Python это особенно
актуально. И проблема для неразреженных графов со скоростью та же, что и
в случае КЧ-дерева.
________________________________________________________________________

С помощью алгоритма Дейкстры можно искать вершины и ребра, находящиеся
на кратчайших путях, по аналогии с такой же задачей для BFS.
________________________________________________________________________

> **Задача 1**. Есть информация о возможных маршрутах с пересадками из
города А в город Б и их стоимостях. Кроме того, есть купон на один
бесплатный перелет, который можно использовать для любого рейса среди
имеющихся маршрутов. Минимизировать стоимость перелета из А в Б.

**Решение 1**:

Провести алгоритм Дейстры из начала в конец и из конца в начало, а затем
перебрать все ребра и применить к ним купон. Тогда сумма затрат на левом
конце ребра по первому запуску алгоритма Дейстры и на правом конце ребра
по второму дадут суммарную стоимость.

**Решение 2**:

Как будто можно по алгоритму Дейстры тянуть не один параметр
минимального пути, а параметр минимального пути без использования ранее
купона и параметр минимального с использованием. Или через раздваивание
вершин на "с купоном" и "без купона".
________________________________________________________________________

> **Задача 2**. Есть карта дорог и максимальные веса грузовиков, которые
разрешены на этих дорогах. Какой максимальный вес можно перевезти из
пункта А в пункт Б?

**Решение**:

Задача не совсем на алгоритм Дейкстры, но использует его идеи. Тут на
самом деле относительно оригинального алгоритма меняется только минимум
на максимум (и все сопутствующее). Храним максимальный вес для точек,
инициализация нулями, выбираем максимальный на данный момент. При этом
выбираем записываемое число осторожно: минимум из числа, записанного в
узле, рассматриваемом в данный момент, и значения на ребре.
________________________________________________________________________

> **Задача 3**. Найти второй минимальный путь.

**Решение**:

Найти минимальный путь и все ребра на нем. Затем удалять по одному ребра
с минимального пути и находить алгоритмом Дейкстры минимальный путь.
Это крайне долго, но в чистом виде алгоритмом Дейкстры иначе это не
решить.

Важное уточнение: удаление не в чистом виде, чтобы не перестраивать
граф, а запоминание, какое ребро в этот раз игнорируется.

Существует алгоритм Йена для поиска K минимальных путей от начальной до
конечной точки. Долгий и относительно сложный алгоритм, но можно
посмотреть для общего ознакомления.
________________________________________________________________________

### <u> Граф состояний </u> ###
<a id="anchor_graph_states"></a>

Для объяснения воспользуемся задачей о регулировке проезда двух машин.
Есть граф, описывающий дорогу. Есть две машины в двух разных вершинах,
машины на одной вершине находиться не могут. Машины могут перемещаться
в смежные вершины. Нужно поменять машины местами.

Для этого построим возьмем за элементарное действие переезд какого-либо
одного автомобиля в смежную вершину и построим граф состояний.

*Граф состояний* - граф, описывающий состояния системы, где в первой
вершине начальное состояние, в смежных с ним - возможные состояния
системы после одного элементарного действия, в следующем слое смежных
вершин - после 2 элементарных действий, и т.д.

В данном случае состояния описываются парой чисел - положениями двух
машин. Нулевая вершина - начальное положение. Смежные с ним - состояния
системы после смещения одной из машин в любом возможном для этого
направлении, и т.д. Это граф, а не дерево, т.к. могут (и чаще всего
будут) образовываться циклы, где в одно состояние можно попасть
несколькими способами.

Чтобы не получать большие неэффективные циклы, помечаем уже посещенные
состояния. Строго говоря, в таком случае, если помечать при каждом шаге
посещенные состояния, то граф точно будет деревом. Но если помечать уже
посещенные состояния после заполнения каждого слоя (или нескольких), то
могут образовываться небольшие циклы из альтернативных эффективных (или
эффективных и околоэффективных) путей. В ряде реальных задач сохранение
альтернативных путей может быть полезно или необходимо (навигация,
управление движением, и т.д.), поэтому вырождать граф в дерево не всегда
правильно.

В общем и целом хранить ребра в графе состояний в явном виде
необязательно, можно ориентироваться по начальному графу.

Кроме того, в данном графе будет уместно применить логику, описанную
выше (Граф -> Обход в ширину) для поиска кратчайшего пути в больших
графах.

Таким образом, используя граф состояний и описав начальное состояние и
требуемое как (x, y) и (y, x) соответственно, можно найти маршрут из
элементарных действий, чтобы прийти из начального состояния в требуемое,
решив т.о. задачу.
________________________________________________________________________

Несмотря на то, что граф состояний по сути говоря является подтемой
обхода графа в ширину, выделил его в отдельную часть конспекта. Это
вызвано тем, что концепция описания графа через другой граф несколько
отдельна. Но еще более веской причиной выделить граф состояний в
отдельную тему является новая парадигма решения задач, т.к. в грубом
представлении графом состояний можно описать любой алгоритм.

Беря состояние ряда переменных и элементарным действием по каким-либо
правилам изменяя их можно получать различные состояния данного набора
переменных, и последующим обходом в ширину искать путь от начального
состояния переменных к требуемому в задаче. Непосредственно алгоритмы
тогда превращаются в правила для перехода от одного состояния переменных
к другому.

Это не говорит о том, что нужно бросить другие алгоритмы в топку или
сменить направленность обучения с непосредственно алгоритмов на правила
для дерева состояний. Скорее это дает вариант для решения задач, для
которых в голове не подбирается подходящего алгоритма, вариант "на
крайний случай". Да и в ряде случаев это может быть эффективнее прочих
решений. В иных случаях разбор задачи на графы состояний может помочь
подобрать необходимый алгоритм по подбору правил для перехода от
состояния к состоянию, а не заменить его.

В общем и целом, парадигма решения через графы состояний очень полезна
для решения алгоритмических задач. Структур данных и алгоритмов это не
заменит, но может стать отличным подспорьем при ступоре в решении, а
где-то является лучшим решением, как в примере выше.
________________________________________________________________________

### ПЕРСИСТЕНТНЫЕ СТРУКТУРЫ ###
<a id="anchor_persist"></a>

> **ЗАМЕТКИ!** Данный подраздел малополезен вне специфических
направлений в программировании, см. этот раздел по необх-ти или по
личному интересу.

В контексте данного конспекта подтема является продолжением тем
ссылочных типов данных (см. Связные списки) и особых случаев в них.

*Персистентность* - сохранение доступа к предыдущим состояниям системы
(например, персистентные структуры данных, git, ф-ция undo-redo в
редакторах). Персистентность называется полной, если доступ сохраняется
ко всем предыдущим состояниям, и при этом во все эти состояния можно
вносить изменения.

Для любых персистентных структур данных создается отдельный массив, с
версиями, указывающими на представительский эл-т данного экземпляра
структуры.

Далее рассмотрим частные случаи таких структур.
________________________________________________________________________

**Персистентный стек**.

0-ой эл-т массива версий указывает на пустой эл-т.

При наличии j версий помимо 0-ой и добавлении к i-ой версии эл-та x:
j+1-ый эл-т массива версий указывает на эл-т X, содержащий в себе x и
указатель на эл-т, на который указывает i-ый эл-т массива версий.

При наличии j версий помимо 0-ой и удалении из i-ой версии эл-та: j+1-ый
эл-т массива версий указывает на эл-т, на который указывал эл-т, на
который указывал i-ый эл-т массива версий.

Для упрощения восприятия возьмем пример:

```
Синтаксис: push(x, n_version), pop(n_version).
p<number> - укзатель на число number.

Версии:
i     0  1  2  3  4  5  6
x     N
prev  -

push(3, 0)

Версии:
i     0  1  2  3  4  5  6
x     N  3
prev  -  pN

push(5, 1)

Версии:
i     0  1  2  3  4  5  6
x     N  3  5
prev  -  pN p3

pop(2)

Версии:
i     0  1  2  3  4  5  6
x     pN p3 p5 p3
prev  -  pN p3 pN

push(7, 2)

Версии:
i     0  1  2  3  4  5  6
x     pN p3 p5 p3 p7
prev  -  pN p3 pN p5

push(8, 3)

Версии:
i     0  1  2  3  4  5  6
x     pN p3 p5 p3 p7 p8
prev  -  pN p3 pN p5 p3

pop(4)

Версии:
i     0  1  2  3  4  5  6
x     pN p3 p5 p3 p7 p8 p5
prev  -  pN p3 pN p5 p3 p3
```

Этот способ описания может быть все еще непонятным, стоит попробовать
изобразить или см. Яндекс Тренировки 7.0 Лекция 4 или поиск в Интернете.
________________________________________________________________________

**Персистентное бинарное дерево поиска**.

Идея реализации на указателях, и при добавлении элемента в новую версию
добавлять только эл-ты по пути добавления эл-та; если же эл-т при
добавлении не затрагивается, то вместо него новое дерево ссылается на
этот же эл-т в предыдущей версии.

Например:

```
Начальное дерево:

      +-------8-------+
      |               |
  +---3---+           10--+
  |       |               |
  1     +-6-+           +-14
        |   |           |
        4   7           13

push(9)

Новая версия (p<number> - укзатель на число number из прошлой версии):

      +-------8-------+
      |               |
      p3           +--10--+
                   |      |
                   9     p14
```

Учитывая общее ссылочное строение дерева, по сути не теряются неизменные
в новой версии эл-ты, а берутся из старой. Новые созданные в новой
версии эл-ты: 8, 10, 9.

Этот способ описания может быть все еще непонятным, стоит попробовать
изобразить или см. Яндекс Тренировки 7.0 Лекция 4 или поиск в Интернете.
________________________________________________________________________

# ИСТОЧНИКИ И ДОП. МАТЕРИАЛЫ #
<a id="anchor_materials"></a>

1. [Литература] **Кнут Д. - Искусство программирования**.
1. [Сайт, тренажер] **leetcode - задачи**:
    [ссылка](https://leetcode.com/).
1. [Сайт, тренажер] **codeforces - задачи**:
    [ссылка](https://codeforces.com/).
1. [Сайт, тренажер] **CodeRun от Яндекса - задачи**:
    [ссылка](https://coderun.yandex.ru/).
1. [Сайт, YT Плейлист] **Тренировки по алгоритмам от Яндекса**:
    - **1.0**:
        [ссылка](https://yandex.ru/yaintern/algorithm-training_2021).
    - **2.0**:
        [ссылка](https://yandex.ru/yaintern/algorithm-training_june_2021).
    - **3.0**:
        [ссылка](https://yandex.ru/yaintern/training/algorithm-training_feb_2023).
    - **4.0**:
        [ссылка](https://yandex.ru/yaintern/training/algorithm-training_oct_2023).
    - **5.0**:
        [ссылка](https://yandex.ru/yaintern/training/algorithm-training_march_2024).
    - **6.0**:
        [ссылка](https://yandex.ru/yaintern/training/algorithm-training-october-2024).
    - **7.0**:
        [ссылка](https://yandex.ru/yaintern/training/algorithm-training).
1. [Сайт, литература] **Документация algorithms (Антонов)**:
    [ссылка](https://python-algorithms-doc.readthedocs.io/_/downloads/en/latest/pdf/).
1. [Сайт, литература] **Документация algorithms (Хассан)**:
    [ссылка](https://readthedocs.org/projects/python-algorithms/downloads/pdf/latest/).
1. [Сайт] **О модуле collections**:
    [ссылка](https://proglib.io/p/ne-izobretat-velosiped-ili-obzor-modulya-collections-v-python-2019-12-15).
1. [Сайт] **GitHub заброшенного модуля с алгоритмами**:
    [ссылка](https://github.com/MicBrain/Python-algo-Module).
1. [Сайт] **Python DSA (data structures and algorithms) modules**:
    [ссылка](https://www.geeksforgeeks.org/python-dsa-libraries/).
1. [Сайты] **Метод скользящего окна**:
    [ссылка](https://apptractor.ru/info/techhype/sliding-window.html) и
    [ссылка](https://habr.com/ru/articles/347378/).
1. [Сайт] **Небинарные методы поиска делением отрезка**:
    - **Тернарный**: 
        [ссылка](https://astra-lucentes.github.io/search/ternary).
    - **Сравнение тернарного с бинарным**:
        [ссылка](https://www.techiedelight.com/ru/ternary-search-vs-binary-search/).
    - **"Золотой" поиск**:
        [ссылка](https://neerc.ifmo.ru/wiki/index.php?title=Поиск_с_помощью_золотого_сечения).
    - **Квадратный поиск**:
        [ссылка](https://habr.com/ru/articles/92591/).
1. [Сайт] **Структуры данных в Python**:
    [ссылка](https://www.geeksforgeeks.org/python-data-structures/).
1. [Сайт] **Описание алгоритмов сортировки и сравнение их производительности**:
    [ссылка](https://habr.com/ru/articles/335920/).
1. [Сайт] **Алгоритм сортировки Timsort**:
    [ссылка](https://habr.com/ru/companies/infopulse/articles/133303/).
1. [Сайт] **Алгоритм backtracking**:
    [ссылка](https://habr.com/ru/companies/otus/articles/746408/).
1. [Сайт] **Внутренности словаря в CPython**:
    [ссылка](https://habr.com/ru/articles/432996/).
1. [Сайт] **Адгоритм "Разделяй и властвуй"**:
    [ссылка](https://habr.com/ru/companies/otus/articles/599309/).
________________________________________________________________________
